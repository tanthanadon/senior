 import log from log import debug import os , re , filesystem from settings import * import urllib from movieapi import * import operator KB = 1024 MB = KB * KB GB = KB * MB def lower ( s ) : 	 s = s . lower ( ) _s = unicode ( ) for ch in s : 		 if ord ( ch ) >= ord ( <str> ) and ord ( ch ) <= ord ( <str> ) : 			 ofs = ord ( <str> ) - ord ( <str> ) _s += unichr ( ord ( ch ) + ofs )  else : 			 _s += ch   return _s  def make_fullpath ( title , ext ) : 	 if filesystem . _is_abs_path ( title ) : 		 dir_path = filesystem . dirname ( title ) filename = filesystem . basename ( title ) pass  else : 		 dir_path = None filename = title  if <str> in title : 		 pass  result = unicode ( filename . replace ( <str> , <str> ) . replace ( <str> , <str> ) . replace ( <str> , <str> ) . replace ( <str> , <str> ) + ext ) if dir_path : 		 result = filesystem . join ( dir_path , result )  return result  def skipped ( item ) : 	 debug ( item . title . encode ( <str> ) + <str> )  def remove_script_tags ( file ) : 	 pattern = re . compile ( <str> ) subst = <str> return re . sub ( pattern , subst , file )  def clean_html ( page ) : 	 page = remove_script_tags ( page ) return page . replace ( <str> , <str> ) . replace ( <str> , <str> ) . replace ( <str> , <str> )  def striphtml ( data ) : 	 p = re . compile ( <str> ) return p . sub ( <str> , data )  def detect_mpg ( str_detect ) : 	 try : 		 str_detect = str_detect . lower ( ) return <str> in str_detect or <str> in str_detect or <str> in str_detect or <str> in str_detect  except : 		 return False   def detect_h264 ( str_detect ) : 	 try : 		 str_detect = str_detect . lower ( ) return <str> in str_detect or <str> in str_detect or <str> in str_detect  except : 		 return False   def detect_h265 ( str_detect ) : 	 try : 		 str_detect = str_detect . lower ( ) return <str> in str_detect or <str> in str_detect or <str> in str_detect  except : 		 return False   def is_torrent_remembed ( parser , settings ) : 	 from downloader import TorrentDownloader import urllib link = parser . get ( <str> ) . split ( <str> ) [ - 1 ] if link : 		 torr_downloader = TorrentDownloader ( urllib . unquote ( link ) , None , settings ) path = filesystem . join ( settings . torrents_path ( ) , torr_downloader . get_subdir_name ( ) , torr_downloader . get_post_index ( ) + <str> ) return filesystem . exists ( path )  return False  def get_rank ( full_title , parser , settings ) : 	 preffered_resolution_v = 1080 try : 		 if settings . preffered_type == QulityType . Q720 : 			 preffered_resolution_v = 720  elif settings . preffered_type == QulityType . Q2160 : 			 preffered_resolution_v = 2160   except BaseException as e : 		 log . print_tb ( e )  preffered_bitrate = settings . preffered_bitrate rank = 0.0 conditions = 0 mults = [ ] if <str> in full_title . lower ( ) : 		 mults . append ( 1.1 )  if <str> in parser : 		 seeds = parser [ <str> ] if seeds == 0 : 			 mults . append ( 10 )  else : 			 v = 1.0 + 0.25 / seeds mults . append ( v )   else : 		 mults . append ( 1.25 )  res_v = 1080 if <str> in full_title : 		 res_v = 720  if <str> in full_title : 		 res_v = 2160  video = parser . get ( <str> , <str> ) if video : 		 parts = video . split ( <str> )  else : 		 parts = [ ]  for part in parts : 		 multiplier = 0 if <str> in part or <str> in part or <str> in part or <str> in part or <str> in part or <str> in part : 				 multiplier = 1  if <str> in part or <str> in part or <str> in part or <str> in part or <str> in part or <str> in part or <str> in part or <str> in part : 				 multiplier = 1000  if multiplier != 0 : 			 find = re . findall ( <str> , part . split ( <str> ) [ 0 ] ) bitrate = <str> . join ( find ) . replace ( <str> , <str> ) try : 				 if bitrate != <str> and float ( bitrate ) != 0 and float ( bitrate ) < 50000 : 					 debug ( <str> % int ( float ( bitrate ) * multiplier ) ) if float ( bitrate ) * multiplier > preffered_bitrate : 						 rank += ( float ( bitrate ) * multiplier ) / preffered_bitrate  else : 						 rank += preffered_bitrate / ( float ( bitrate ) * multiplier )  conditions += 1  else : 					 mults . append ( 1.5 ) debug ( <str> )   except : 				 mults . append ( 1.5 ) debug ( <str> )   if <str> in part or <str> in part : 			 res_v = 2160  if <str> in part or <str> in part : 			 res_v = 1080  if <str> in part or <str> in part : 			 res_v = 720  if <str> in part or <str> in part : 			 res_v = 540   if abs ( preffered_resolution_v - res_v ) > 360 : 		 rank += 5 conditions += 1  elif abs ( preffered_resolution_v - res_v ) > 0 : 		 rank += 2 conditions += 1  detect_codec = None if detect_h264 ( full_title ) : 		 detect_codec = CodecType . MPGHD  elif detect_h265 ( full_title ) : 		 detect_codec = CodecType . MPGUHD  elif detect_mpg ( full_title ) : 		 detect_codec = CodecType . MPGSD  if detect_codec is None : 		 for part in parts : 			 if detect_h264 ( part ) : 				 detect_codec = CodecType . MPGHD  elif detect_h265 ( part ) : 				 detect_codec = CodecType . MPGUHD  elif detect_mpg ( part ) : 				 detect_codec = CodecType . MPGSD    if detect_codec : 		 if settings . preffered_codec == CodecType . MPGSD : 			 if settings . preffered_codec != detect_codec : 				 rank += 10 conditions += 1   elif settings . preffered_codec == CodecType . MPGHD : 			 if detect_codec == CodecType . MPGUHD : 				 rank += 10 conditions += 1  if detect_codec == CodecType . MPGSD : 				 rank += 2 conditions += 1   elif settings . preffered_codec == CodecType . MPGUHD : 			 if settings . preffered_codec != detect_codec : 				 rank += 2 conditions += 1    if <str> in parser . get ( <str> , <str> ) : 		 rank += 100 conditions += 1  if conditions != 0 : 		 rank /= conditions  else : 		 rank = 1.0  for m in mults : 		 rank *= m  if is_torrent_remembed ( parser , settings ) : 		 rank /= 1000  return rank  def make_utf8 ( s ) : 	 if isinstance ( s , unicode ) : 		 return s . encode ( <str> )  return s  def scrape_now ( fn ) : 	 debug ( fn ) with filesystem . fopen ( fn , <str> ) as fin : 		 from bencode import BTFailure try : 			 from bencode import bdecode decoded = bdecode ( fin . read ( ) )  except BTFailure : 			 debug ( <str> ) return { }  info = decoded [ <str> ] import hashlib from bencode import bencode info_hash = hashlib . sha1 ( bencode ( info ) ) . hexdigest ( ) hashes = [ info_hash ] import scraper result = [ ] threads = [ ] def start_scrape ( announce ) : 			 def do_scrape ( ) : 				 try : 					 res = scraper . scrape ( announce , hashes , 0.25 ) result . append ( res [ info_hash ] )  except : 					 debug ( announce + <str> ) pass   import threading t = threading . Thread ( target = do_scrape ) threads . append ( t ) t . start ( )  if <str> in decoded : 			 for announce in decoded [ <str> ] : 				 start_scrape ( announce [ 0 ] )  alive = True while not result and alive : 				 alive = False for t in threads : 					 if t . is_alive ( ) : 						 alive = True break     elif <str> in decoded : 			 res = scraper . scrape ( decoded [ <str> ] , hashes ) return res [ info_hash ]  if result : 			 return result [ 0 ]   return { }  def seeds_peers ( item ) : 	 res = { } try : 		 link = urllib . unquote ( item [ <str> ] ) try : 			 import player settings = player . load_settings ( )  except : 			 settings = Settings . current_settings  if <str> in link : 			 debug ( <str> + link ) t_id = re . search ( <str> , link ) . group ( 1 ) fn = filesystem . join ( settings . torrents_path ( ) , <str> , t_id + <str> ) debug ( fn ) with filesystem . fopen ( fn , <str> ) as stat_file : 				 import json res = json . load ( stat_file ) debug ( str ( res ) )   elif <str> in link : 			 t_id = re . search ( <str> , link ) . group ( 1 ) fn = filesystem . join ( settings . torrents_path ( ) , <str> , t_id + <str> ) return scrape_now ( fn )  elif <str> in link : 			 t_id = re . search ( <str> , link ) . group ( 1 ) fn = filesystem . join ( settings . torrents_path ( ) , <str> , t_id + <str> ) if not filesystem . exists ( fn ) : 				 import bluebird bluebird . download_torrent ( link , fn , settings )  return scrape_now ( fn )  elif <str> in link : 			 t_id = re . search ( <str> , link ) . group ( 1 ) fn = filesystem . join ( settings . torrents_path ( ) , <str> , t_id + <str> ) return scrape_now ( fn )   except BaseException as e : 		 debug ( str ( e ) )  return res  class STRMWriterBase ( object ) : 	 def make_alternative ( self , strmFilename , link , parser ) : 		 strmFilename_alt = strmFilename + <str> s_alt = <str> if filesystem . isfile ( strmFilename_alt ) : 			 with filesystem . fopen ( strmFilename_alt , <str> ) as alternative : 				 s_alt = alternative . read ( ) . decode ( <str> )   if not ( link in s_alt ) : 			 try : 				 with filesystem . fopen ( strmFilename_alt , <str> ) as alternative : 					 for key , value in parser . Dict ( ) . iteritems ( ) : 						 if key in [ <str> , <str> , <str> , <str> , <str> , <str> , <str> ] : 							 continue  alternative . write ( <str> % ( make_utf8 ( key ) , make_utf8 ( value ) ) )  alternative . write ( link . encode ( <str> ) + <str> )   except : 				 pass    @ staticmethod def get_links_with_ranks ( strmFilename , settings , use_scrape_info = False ) : 		 strmFilename_alt = strmFilename + <str> items = [ ] saved_dict = { } if filesystem . isfile ( strmFilename_alt ) : 			 with filesystem . fopen ( strmFilename_alt , <str> ) as alternative : 				 curr_rank = 1 while True : 					 line = alternative . readline ( ) if not line : 						 break  line = line . decode ( <str> ) if line . startswith ( <str> ) : 						 line = line . lstrip ( <str> ) parts = line . split ( <str> ) if len ( parts ) > 1 : 							 saved_dict [ parts [ 0 ] ] = parts [ 1 ] . strip ( <str> )   elif line . startswith ( <str> ) : 						 try : 							 saved_dict [ <str> ] = line . strip ( <str> ) if use_scrape_info : 								 sp = seeds_peers ( saved_dict ) saved_dict = dict ( saved_dict , ** sp )  if <str> in saved_dict : 								 curr_rank = float ( saved_dict [ <str> ] )  else : 								 curr_rank = get_rank ( saved_dict . get ( <str> , <str> ) , saved_dict , settings )   except BaseException as e : 							 import log log . print_tb ( e ) curr_rank = 1  item = { <str> : curr_rank , <str> : line . strip ( <str> ) } items . append ( dict ( item , ** saved_dict ) ) saved_dict . clear ( )     items . sort ( key = operator . itemgetter ( <str> ) ) return items  @ staticmethod def get_link_with_min_rank ( strmFilename , settings ) : 		 items = STRMWriterBase . get_links_with_ranks ( strmFilename , settings ) if len ( items ) == 0 : 			 return None  else : 			 return items [ 0 ] [ <str> ]   @ staticmethod def has_link ( strmFilename , link ) : 		 strmFilename_alt = strmFilename + <str> if filesystem . isfile ( strmFilename_alt ) : 			 with filesystem . fopen ( strmFilename_alt , <str> ) as alternative : 				 for line in alternative : 					 if line . startswith ( <str> ) : 						 if link in urllib . unquote ( line ) : 							 return True      return False  @ staticmethod def write_alternative ( strmFilename , links_with_ranks ) : 		 strmFilename_alt = strmFilename + <str> with filesystem . fopen ( strmFilename_alt , <str> ) as alternative : 			 for variant in links_with_ranks : 				 if <str> in variant : 					 for k , v in variant . iteritems ( ) : 						 if k != <str> : 							 alternative . write ( <str> % ( make_utf8 ( k ) , make_utf8 ( v ) ) )   alternative . write ( make_utf8 ( variant [ <str> ] ) + <str> )      class EmptyMovieApi ( object ) : 	 def get ( self , key , default = None ) : 		 return default  def __getitem__ ( self , key ) : 		 raise AttributeError   class Informer ( object ) : 	 def __init__ ( self ) : 		 self . __movie_api = EmptyMovieApi ( )  def make_movie_api ( self , imdb_id , kp_id , settings ) : 		 orig = None year = None if not imdb_id : 			 if <str> in self . Dict ( ) : 				 orig = self . Dict ( ) [ <str> ]  if <str> in self . Dict ( ) : 				 year = self . Dict ( ) [ <str> ]   from movieapi import MovieAPI self . __movie_api , imdb_id = MovieAPI . get_by ( imdb_id = imdb_id , kinopoisk_url = kp_id , orig = orig , year = year , settings = settings ) if imdb_id : 			 self . Dict ( ) [ <str> ] = imdb_id   def movie_api ( self ) : 		 return self . __movie_api  def filename_with ( self , title , originaltitle , year ) : 		 if title == originaltitle : 			 filename = title  elif title == <str> and originaltitle != <str> : 			 filename = originaltitle  elif title != <str> and originaltitle == <str> : 			 filename = title  else : 			 filename = originaltitle  if year != None or year != <str> or year != 0 : 			 filename += <str> + str ( year ) + <str>  return filename  def make_filename_imdb ( self ) : 		 if self . __movie_api : 			 title = self . __movie_api . imdbapi . title ( ) originaltitle = self . __movie_api . imdbapi . originaltitle ( ) try : 				 year = self . __movie_api [ <str> ]  except AttributeError : 				 year = None  return self . filename_with ( title , originaltitle , year )  return None   class DescriptionParserBase ( Informer ) : 	 _dict = { } def Dump ( self ) : 		 debug ( <str> ) for key , value in self . _dict . iteritems ( ) : 			 debug ( key + <str> + value )   def Dict ( self ) : 		 return self . _dict  def get_value ( self , tag , def_value = <str> ) : 		 try : 			 return self . _dict [ tag ]  except : 			 return def_value   def get ( self , tag , def_value ) : 		 return self . _dict . get ( tag , def_value )  def parsed ( self ) : 		 return self . OK  def parse ( self ) : 		 raise NotImplementedError ( <str> )  def fanart ( self ) : 		 if <str> in self . _dict : 			 return self . _dict [ <str> ]  else : 			 return None   def parse_country_studio ( self ) : 		 import countries if <str> in self . _dict : 			 parse_string = self . _dict [ <str> ] items = re . split ( <str> , parse_string . replace ( <str> , <str> ) ) cntry = [ ] stdio = [ ] for s in items : 				 s = s . strip ( ) if len ( s ) == 0 : 					 continue  cntry . append ( s ) if countries . isCountry ( s ) else stdio . append ( s )  self . _dict [ <str> ] = <str> . join ( cntry ) self . _dict [ <str> ] = <str> . join ( stdio )   def __init__ ( self , full_title , content , settings = None ) : 		 Informer . __init__ ( self ) from bs4 import BeautifulSoup self . _dict = dict ( ) self . _dict [ <str> ] = full_title self . content = content html_doc = <str> + content . encode ( <str> ) + <str> self . soup = BeautifulSoup ( clean_html ( html_doc ) , <str> ) self . settings = settings self . OK = self . parse ( )  def make_filename ( self ) : 		 try : 			 if <str> in self . _dict : 				 return self . make_filename_imdb ( )   except : 			 pass  title = self . _dict . get ( <str> , <str> ) originaltitle = self . _dict . get ( <str> , <str> ) year = self . _dict . get ( <str> , <str> ) return self . filename_with ( title , originaltitle , year )  def need_skipped ( self , full_title ) : 		 for phrase in [ <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> ] : 			 if phrase in full_title : 				 debug ( <str> + phrase . encode ( <str> ) ) return True  if re . search ( <str> , full_title . encode ( <str> ) ) : 				 debug ( <str> ) return True   return False   class TorrentPlayer ( object ) : 	 def __init__ ( self ) : 		 self . _decoded = None self . _info_hash = None  @ property def decoded ( self ) : 		 if not self . _decoded : 			 data = None with filesystem . fopen ( self . path , <str> ) as torr : 				 data = torr . read ( )  if data is None : 				 return None  from bencode import BTFailure try : 				 from bencode import bdecode self . _decoded = bdecode ( data )  except BTFailure : 				 debug ( <str> ) return None   return self . _decoded  @ property def info_hash ( self ) : 		 if not self . _info_hash : 			 try : 				 import hashlib from bencode import bencode info = self . decoded [ <str> ] self . _info_hash = hashlib . sha1 ( bencode ( info ) ) . hexdigest ( )  except : 				 return None   return self . _info_hash  @ staticmethod def is_playable ( name ) : 		 filename , file_extension = os . path . splitext ( name ) return file_extension in [ <str> , <str> , <str> , <str> , <str> , <str> ]  def AddTorrent ( self , path ) : 		 self . path = path  def CheckTorrentAdded ( self ) : 		 return filesystem . exists ( self . path )  def updateCheckingProgress ( self , progressBar ) : 		 pass  @ staticmethod def Name ( name ) : 		 try : 			 return name . decode ( <str> )  except UnicodeDecodeError : 			 try : 				 import chardet enc = chardet . detect ( name ) log . debug ( <str> . format ( enc [ <str> ] ) ) log . debug ( <str> . format ( enc [ <str> ] ) ) if enc [ <str> ] > 0.5 : 					 try : 						 name = name . decode ( enc [ <str> ] )  except UnicodeDecodeError : 						 pass   else : 					 import vsdbg log . print_tb ( )   except BaseException as e : 				 import vsdbg log . print_tb ( )   return name  def GetLastTorrentData ( self ) : 		 decoded = self . decoded info = decoded [ <str> ] def info_name ( ) : 			 if <str> in info : 				 return info [ <str> ]  else : 				 return info [ <str> ]   def f_path ( f ) : 			 if <str> in f : 				 return f [ <str> ]  else : 				 return f [ <str> ]   name = <str> playable_items = [ ] try : 			 if <str> in info : 				 for i , f in enumerate ( info [ <str> ] ) : 					 name = os . sep . join ( f_path ( f ) ) size = f [ <str> ] if TorrentPlayer . is_playable ( name ) : 						 playable_items . append ( { <str> : i , <str> : TorrentPlayer . Name ( name ) , <str> : size } )  name = TorrentPlayer . Name ( info_name ( ) )   else : 				 playable_items = [ { <str> : 0 , <str> : TorrentPlayer . Name ( info_name ( ) ) , <str> : info [ <str> ] } ]   except UnicodeDecodeError : 			 return None  return { <str> : self . info_hash , <str> : decoded [ <str> ] , <str> : playable_items , <str> : name }  def GetTorrentInfo ( self ) : 		 try : 			 return { <str> : 100 , <str> : 100 , <str> : 1 , <str> : 0 , <str> : 1 , <str> : 0 }  except : 			 pass  return None  def StartBufferFile ( self , fileIndex ) : 		 pass  def CheckBufferComplete ( self ) : 		 pass  def GetBufferingProgress ( self ) : 		 pass  def GetStreamURL ( self , playable_item ) : 		 pass  def updateDialogInfo ( self , progress , progressBar ) : 		 pass  def GetBufferingProgress ( self ) : 		 return 100  def CheckBufferComplete ( self ) : 		 return True  def loop ( self ) : 		 pass   def save_hashes ( torrent_path ) : 	 hashes_path = torrent_path + <str> if filesystem . exists ( torrent_path ) : 		 tp = TorrentPlayer ( ) tp . AddTorrent ( torrent_path ) td = tp . GetLastTorrentData ( ) if td : 			 info_hash = td [ <str> ] if filesystem . exists ( hashes_path ) : 				 with filesystem . fopen ( hashes_path , <str> ) as rf : 					 if info_hash in rf . read ( ) : 						 return    with filesystem . fopen ( hashes_path , <str> ) as wf : 				 wf . write ( info_hash + <str> )      