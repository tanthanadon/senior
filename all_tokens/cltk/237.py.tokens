__author__ = [ <str> ] __license__ = <str> from abc import abstractmethod from collections import Counter from cltk . utils . cltk_logger import logger class Stoplist ( ) :      def __init__ ( self , language = None ) :          if language :              self . language = language . lower ( )  self . numpy_installed = True self . sklearn_installed = True try :              import numpy as np self . np = np  except ImportError :              self . numpy_installed = False  try :              from sklearn . feature_extraction . text import CountVectorizer , TfidfVectorizer  except ImportError :              self . sklearn_installed = False   @ abstractmethod def build_stoplist ( self , text , size = 100 ) :           def _remove_punctuation ( self , texts , punctuation ) :          if not punctuation :              punctuation = <str>  translator = str . maketrans ( { key : <str> for key in punctuation } ) texts = [ text . translate ( translator ) for text in texts ] return texts   class BaseCorpusStoplist ( Stoplist ) :      def __init__ ( self , language = None ) :          Stoplist . __init__ ( self , language ) self . punctuation = None if not self . numpy_installed or not self . sklearn_installed :              print ( <str> ) raise ImportError  else :              pass   def _make_dtm_vocab ( self , texts ) :          dtm = self . vectorizer . fit_transform ( texts ) dtm = dtm . toarray ( ) vocab = self . vectorizer . get_feature_names ( ) vocab = self . np . array ( vocab ) return dtm , vocab  def _make_tfidf_vocab ( self , texts ) :          tfidf = self . tfidf_vectorizer . fit_transform ( texts ) tfidf = tfidf . toarray ( ) vocab = self . tfidf_vectorizer . get_feature_names ( ) vocab = self . np . array ( vocab ) return tfidf , vocab  def _get_raw_lengths ( self , texts ) :          return [ len ( tokens . split ( ) ) for tokens in texts ]  def _get_length_array ( self , raw_lengths ) :          length_array = self . np . array ( raw_lengths ) length_array = length_array . reshape ( len ( length_array ) , 1 ) return length_array  def _get_probabilities ( self , dtm , length_array ) :          return dtm / length_array  def _get_mean_probabilities ( self , P , N ) :          probability_sum = self . np . ravel ( P . sum ( axis = 0 ) ) return probability_sum / N  def _get_variance_probabilities ( self , bP , P , N ) :          variance = ( P - bP ) ** 2 variance_sum = self . np . ravel ( variance . sum ( axis = 0 ) ) return variance_sum / N  def _get_entropies ( self , P ) :          with self . np . errstate ( divide = <str> , invalid = <str> ) :              logprobs = self . np . where ( P != 0 , self . np . log10 ( 1 / P ) , 0 ) ent = P * logprobs return self . np . ravel ( ent . sum ( axis = 0 ) )   def _combine_vocabulary ( self , vocab , measure ) :          temp = list ( zip ( vocab , measure ) ) temp = sorted ( temp , key = lambda x : x [ 1 ] , reverse = True ) return temp  def _borda_sort ( self , lists ) :          scores = { } for l in lists :              for idx , elem in enumerate ( reversed ( l ) ) :                  if not elem in scores :                      scores [ elem ] = 0  scores [ elem ] += idx   return sorted ( scores . keys ( ) , key = lambda elem : scores [ elem ] , reverse = True )  def build_stoplist ( self , texts , basis = <str> , size = 100 , sort_words = True , inc_values = False , lower = True , remove_punctuation = True , remove_numbers = True , include = [ ] , exclude = [ ] ) :          if isinstance ( texts , str ) :              texts = [ texts ]  if lower :              texts = [ text . lower ( ) for text in texts ]  if remove_punctuation :              texts = self . _remove_punctuation ( texts , self . punctuation )  if remove_numbers :              translator = str . maketrans ( { key : <str> for key in <str> } ) texts = [ text . translate ( translator ) for text in texts ]  dtm , vocab = self . _make_dtm_vocab ( texts ) tfidf , _ = self . _make_tfidf_vocab ( texts ) M = len ( vocab ) N = len ( texts ) raw_lengths = self . _get_raw_lengths ( texts ) l = self . _get_length_array ( raw_lengths ) P = self . _get_probabilities ( dtm , l ) if basis == <str> :              freq = self . np . ravel ( dtm . sum ( axis = 0 ) ) freq_list = self . _combine_vocabulary ( vocab , freq ) [ : size ] stops = freq_list  elif basis == <str> :              tfidf = self . np . ravel ( tfidf . sum ( axis = 0 ) ) tfidf_list = self . _combine_vocabulary ( vocab , tfidf ) [ : size ] stops = tfidf_list  elif basis == <str> :              MP = self . _get_mean_probabilities ( P , N ) mp_list = self . _combine_vocabulary ( vocab , MP ) [ : size ] stops = mp_list  elif basis == <str> :              bP = dtm / sum ( raw_lengths ) VP = self . _get_variance_probabilities ( bP , P , N ) vp_list = self . _combine_vocabulary ( vocab , VP ) [ : size ] stops = vp_list  elif basis == <str> :              ent = self . _get_entropies ( P ) ent_list = self . _combine_vocabulary ( vocab , ent ) [ : size ] stops = set ( ent_list )  elif basis == <str> :              MP = self . _get_mean_probabilities ( P , N ) mp_list = self . _combine_vocabulary ( vocab , MP ) mp_list = [ item [ 0 ] for item in mp_list ] bP = dtm / sum ( raw_lengths ) VP = self . _get_variance_probabilities ( bP , P , N ) vp_list = self . _combine_vocabulary ( vocab , VP ) vp_list = [ item [ 0 ] for item in vp_list ] ent = self . _get_entropies ( P ) ent_list = self . _combine_vocabulary ( vocab , ent ) ent_list = [ item [ 0 ] for item in ent_list ] lists = [ mp_list , vp_list , ent_list ] stops = self . _borda_sort ( lists ) [ : size ] stops = [ ( stop , rank ) for rank , stop in enumerate ( stops ) ]  else :              raise ValueError ( <str> . format ( basis ) )  if exclude :              stops = [ item for item in stops if item [ 0 ] not in exclude ]  if include :              stops . extend ( ( item , None ) for item in include if item not in stops )  if sort_words :              stops = sorted ( stops )  if inc_values :              return stops  else :              return [ item [ 0 ] for item in stops ]    if __name__ == <str> :      pass    