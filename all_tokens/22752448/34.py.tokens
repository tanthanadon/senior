import cjson import copy import datetime import hashlib import logging import optparse import os import re import shutil import sys import tempfile import time from lib . python import common_constants from lib . python import configuration from lib . python import opencsw from lib . python import overrides from lib . python import pkgmap from lib . python import rest from lib . python import sharedlib_utils from lib . python import shell from lib . python import util from lib . python import representations ADMIN_FILE_CONTENT = BAD_CONTENT_REGEXES = ( <str> <str> , <str> <str> , <str> <str> , <str> <str> , <str> <str> , ) class Error ( Exception ) :     class ShellCommandError ( Error ) :     class Unpacker ( object ) :    STATS_VERSION = 13 L def __init__ ( self , pkg_path , debug ) :      self . debug = debug self . pkg_path = pkg_path self . _work_dir = None self . _admin_file = None self . _gunzipped_path = None self . _md5_sum = None self . _stat = None self . _mtime = None self . _transformed = False self . _pkgname = None self . _pkginfo_dict = None self . _dir_format_base_dir = None self . _files_metadata = None self . _binaries = None self . _file_paths = None self . config = configuration . GetConfig ( ) username , password = rest . GetUsernameAndPassword ( ) self . rest_client = rest . RestClient ( pkgdb_url = self . config . get ( <str> , <str> ) , releases_url = self . config . get ( <str> , <str> ) , username = username , password = password )  def __del__ ( self ) :      self . Cleanup ( )  def __repr__ ( self ) :      return <str> % repr ( self . pkg_path )  def Cleanup ( self ) :      if self . _work_dir and shutil :        logging . debug ( <str> , self . _work_dir ) shutil . rmtree ( self . _work_dir ) self . _work_dir = None   @ property def work_dir ( self ) :      if not self . _work_dir :        self . _work_dir = tempfile . mkdtemp ( prefix = <str> , dir = <str> )  return self . _work_dir  @ property def admin_file_path ( self ) :      if self . _admin_file is None :        self . _admin_file = os . path . join ( self . work_dir , <str> ) with open ( self . _admin_file , <str> ) as fd :          fd . write ( ADMIN_FILE_CONTENT )   return self . _admin_file  @ property def md5_sum ( self ) :      if self . _md5_sum is None :        logging . debug ( <str> , self . pkg_path ) md5_hash = hashlib . md5 ( ) with open ( self . pkg_path ) as fp :          chunk_size = 2 * 1024 * 1024 data = fp . read ( chunk_size ) while data :            md5_hash . update ( data ) data = fp . read ( chunk_size )   self . _md5_sum = md5_hash . hexdigest ( )  return self . _md5_sum  @ property def stat ( self ) :      if self . _stat is None :        self . _stat = os . stat ( self . pkg_path )  return self . _stat  @ property def size ( self ) :      return self . stat . st_size  @ property def mtime ( self ) :      if self . _mtime is None :        s = self . stat t = time . gmtime ( s . st_mtime ) self . _mtime = datetime . datetime ( * t [ : 6 ] )  return self . _mtime  def _Gunzip ( self ) :      gzip_suffix = <str> pkg_suffix = <str> if self . pkg_path . endswith ( <str> % ( pkg_suffix , gzip_suffix ) ) :        self . mtime self . md5_sum base_name = os . path . split ( self . pkg_path ) [ 1 ] [ : ( - len ( gzip_suffix ) ) ] self . _gunzipped_path = os . path . join ( self . work_dir , base_name ) with open ( self . _gunzipped_path , <str> ) as gunzipped_file :          args = [ <str> , <str> , <str> , self . pkg_path ] unused_ret_code , _ , _ = shell . ShellCommand ( args , stdout = gunzipped_file )   elif self . pkg_path . endswith ( pkg_suffix ) :        self . _gunzipped_path = self . pkg_path  else :        raise Error ( <str> <str> % ( gzip_suffix , pkg_suffix , repr ( self . pkg_path ) ) )   @ property def gunzipped_path ( self ) :      if self . _gunzipped_path is None :        self . _Gunzip ( )  return self . _gunzipped_path  @ property def pkgname ( self ) :      if self . _pkgname is None :        gunzipped_path = self . gunzipped_path args = [ <str> , <str> , gunzipped_path ] ret_code , stdout , stderr = shell . ShellCommand ( args ) self . _pkgname = stdout . strip ( ) logging . debug ( <str> , repr ( self . pkgname ) )  return self . _pkgname  def DirsInWorkdir ( self ) :      paths = os . listdir ( self . work_dir ) dirs = [ ] for p in paths :        abspath = os . path . join ( self . work_dir , p ) if os . path . isdir ( abspath ) :          dirs . append ( abspath )   return dirs  def _TransformToDir ( self ) :      if not self . _transformed :        gunzipped_path = self . gunzipped_path pkgname = self . pkgname args = [ os . path . join ( os . path . dirname ( __file__ ) , <str> , <str> , <str> , <str> ) , gunzipped_path , self . work_dir , pkgname ] shell . ShellCommand ( args , allow_error = False ) dirs = self . DirsInWorkdir ( ) if len ( dirs ) != 1 :          raise Error ( <str> <str> % ( dirs ) )  self . _transformed = True self . _dir_format_base_dir = os . path . join ( self . work_dir , pkgname )   def GetPkginfoFilename ( self ) :      return os . path . join ( self . _dir_format_base_dir , <str> )  def GetParsedPkginfo ( self ) :      if self . _pkginfo_dict is None :        with open ( self . GetPkginfoFilename ( ) , <str> ) as pkginfo_fd :          self . _pkginfo_dict = opencsw . ParsePkginfo ( pkginfo_fd )   return self . _pkginfo_dict  def GetBasedir ( self ) :      basedir_id = <str> pkginfo = self . GetParsedPkginfo ( ) if basedir_id in pkginfo :        basedir = pkginfo [ basedir_id ]  else :        basedir = <str>  basedir = basedir . lstrip ( <str> ) return basedir  def GetCatalogname ( self ) :      pkginfo = self . GetParsedPkginfo ( ) words = re . split ( configuration . WS_RE , pkginfo [ <str> ] ) return words [ 0 ]  def GetBasicStats ( self ) :      basic_stats = { } basic_stats [ <str> ] = self . STATS_VERSION basic_stats [ <str> ] = self . pkg_path basic_stats [ <str> ] = os . path . basename ( self . pkg_path ) basic_stats [ <str> ] = opencsw . ParsePackageFileName ( basic_stats [ <str> ] ) basic_stats [ <str> ] = self . pkgname basic_stats [ <str> ] = self . GetCatalogname ( ) basic_stats [ <str> ] = self . md5_sum basic_stats [ <str> ] = self . size return basic_stats  def _GetOverridesStream ( self , file_path ) :      if os . path . isfile ( file_path ) :        logging . debug ( <str> % repr ( file_path ) ) return open ( file_path , <str> )  else :        logging . debug ( <str> % repr ( file_path ) ) return None   def _ParseOverridesStream ( self , stream ) :      override_list = [ ] for line in stream :        if line . startswith ( <str> ) :          continue  override_list . append ( overrides . ParseOverrideLine ( line ) )  return override_list  def GetOverrides ( self ) :      override_list = [ ] catalogname = self . GetCatalogname ( ) override_paths = ( [ self . _dir_format_base_dir , <str> , <str> , catalogname ] , [ self . _dir_format_base_dir , <str> , <str> ] , ) for override_path in override_paths :        file_path = os . path . join ( * override_path ) try :          with open ( file_path , <str> ) as stream :            override_list . extend ( self . _ParseOverridesStream ( stream ) )   except IOError as e :          logging . debug ( <str> % ( file_path , e ) )   def OverrideToDict ( override ) :        return { <str> : override . pkgname , <str> : override . tag_name , <str> : override . tag_info , }  overrides_simple = [ OverrideToDict ( x ) for x in override_list ] return overrides_simple  def GetDependencies ( self ) :      depends = [ ] i_depends = [ ] depend_file_path = os . path . join ( self . _dir_format_base_dir , <str> , <str> ) try :        with open ( depend_file_path , <str> ) as fd :          for line in fd :            fields = re . split ( configuration . WS_RE , line ) if len ( fields ) < 2 :              logging . warning ( <str> , line )  if fields [ 0 ] == <str> :              pkgname = fields [ 1 ] pkg_desc = <str> . join ( fields [ 1 : ] ) depends . append ( ( pkgname , pkg_desc ) )  if fields [ 0 ] == <str> :              pkgname = fields [ 1 ] i_depends . append ( pkgname )     except IOError as e :        logging . debug ( <str> % ( depend_file_path , e ) )  return depends , i_depends  def CheckPkgpathExists ( self ) :      if not os . path . isdir ( self . _dir_format_base_dir ) :        raise PackageError ( <str> % self . _dir_format_base_dir )   def GetPathsInSubdir ( self , remove_prefix , subdir ) :      file_paths = [ ] for root , dirs , files in os . walk ( os . path . join ( self . _dir_format_base_dir , subdir ) ) :        full_paths = [ os . path . join ( root , f ) for f in files ] file_paths . extend ( [ f . replace ( remove_prefix , <str> ) for f in full_paths ] )  return file_paths  def GetAllFilePaths ( self ) :      if self . _file_paths is None :        basedir = self . GetBasedir ( ) self . CheckPkgpathExists ( ) remove_prefix = <str> % self . _dir_format_base_dir self . _file_paths = self . GetPathsInSubdir ( remove_prefix , <str> ) if self . RelocPresent ( ) :          self . _file_paths += self . GetPathsInSubdir ( remove_prefix , <str> )   return self . _file_paths  def GetFilesMetadata ( self ) :      if not self . _files_metadata :        self . CheckPkgpathExists ( ) self . _files_metadata = [ ] files_root = self . GetFilesDir ( ) all_files = self . GetAllFilePaths ( ) file_magic = util . FileMagic ( ) basedir = self . GetBasedir ( ) for file_path in all_files :          full_path = unicode ( self . MakeAbsolutePath ( file_path ) ) file_info = util . GetFileMetadata ( file_magic , self . _dir_format_base_dir , full_path ) file_info_dict = file_info . _asdict ( ) file_info_dict [ <str> ] = util . StripRe ( file_path , util . ROOT_RE ) file_info = representations . FileMetadata ( ** file_info_dict ) self . _files_metadata . append ( file_info )  file_magic . Close ( )  return self . _files_metadata  def RelocPresent ( self ) :      return os . path . exists ( os . path . join ( self . _dir_format_base_dir , <str> ) )  def GetFilesDir ( self ) :      if self . RelocPresent ( ) :        return <str>  else :        return <str>   def MakeAbsolutePath ( self , p ) :      return os . path . join ( self . _dir_format_base_dir , p )  def ListBinaries ( self ) :      if self . _binaries is None :        self . CheckPkgpathExists ( ) files_metadata = self . GetFilesMetadata ( ) self . _binaries = [ ] for file_info in files_metadata :          if sharedlib_utils . IsBinary ( file_info . _asdict ( ) ) :            self . _binaries . append ( file_info . path )   self . _binaries . sort ( )  return self . _binaries  def GetBinaryDumpInfo ( self ) :      basedir = self . GetBasedir ( ) binaries_dump_info = [ ] for binary in self . ListBinaries ( ) :        binary_abs_path = os . path . join ( self . _dir_format_base_dir , self . GetFilesDir ( ) , binary ) if basedir :          binary = os . path . join ( basedir , binary )  binaries_dump_info . append ( util . GetBinaryDumpInfo ( binary_abs_path , binary ) )  return binaries_dump_info  def GetObsoletedBy ( self ) :      has_obsolete_info = False obsoleted_syntax_ok = True obsoleted_by = [ ] obsoleted_by_path = os . path . join ( self . _dir_format_base_dir , <str> , <str> ) if os . path . exists ( obsoleted_by_path ) :        has_obsolete_info = True with open ( obsoleted_by_path , <str> ) as fd :          for line in fd :            fields = re . split ( configuration . WS_RE , line ) if len ( fields ) < 2 :              obsoleted_syntax_ok = False logging . warning ( <str> , repr ( line ) ) continue  pkgname , catalogname = fields [ 0 : 2 ] obsoleted_by . append ( ( pkgname , catalogname ) )    return { <str> : obsoleted_syntax_ok , <str> : obsoleted_by , <str> : has_obsolete_info , }  def GetPkgmap ( self , analyze_permissions = False , strip = None ) :      fd = open ( os . path . join ( self . _dir_format_base_dir , <str> ) , <str> ) basedir = self . GetBasedir ( ) return pkgmap . Pkgmap ( fd , analyze_permissions , strip , basedir )  def GetPkgchkOutput ( self ) :      if not self . _transformed :          self . _TransformToDir ( )  args = [ <str> , <str> , self . work_dir , self . pkgname ] return shell . ShellCommand ( args )  def GetPkgchkData ( self ) :      ret , stdout , stderr = self . GetPkgchkOutput ( ) data = { <str> : ret , <str> : stdout . splitlines ( ) , <str> : stderr . splitlines ( ) , } return data  def GetFilesContaining ( self , regex_list ) :      full_paths = self . GetAllFilePaths ( ) files_by_pattern = { } for full_path in full_paths :        content = open ( self . MakeAbsolutePath ( full_path ) , <str> ) . read ( ) for regex in regex_list :          if re . search ( regex , content ) :            if regex not in files_by_pattern :              files_by_pattern [ regex ] = [ ]  files_by_pattern [ regex ] . append ( full_path )    return files_by_pattern  def GetMainStatsStruct ( self , binary_md5_sums ) :      basic_stats = self . GetBasicStats ( ) depends , i_depends = self . GetDependencies ( ) arch = basic_stats [ <str> ] [ <str> ] pkg_stats = { <str> : basic_stats , <str> : depends , <str> : i_depends , <str> : self . GetOverrides ( ) , <str> : self . GetParsedPkginfo ( ) , <str> : list ( sharedlib_utils . GetIsalist ( arch ) ) , <str> : self . mtime . isoformat ( ) , <str> : self . GetFilesMetadata ( ) , <str> : self . ListBinaries ( ) , <str> : self . GetBinaryDumpInfo ( ) , <str> : self . GetObsoletedBy ( ) , <str> : self . GetPkgmap ( ) . entries , <str> : self . GetPkgchkData ( ) , <str> : self . GetFilesContaining ( BAD_CONTENT_REGEXES ) , <str> : binary_md5_sums , } return pkg_stats  def _CollectElfdumpData ( self ) :      logging . debug ( <str> ) binary_md5_sums = [ ] for binary in self . ListBinaries ( ) :        binary_abs_path = os . path . join ( self . _dir_format_base_dir , self . GetFilesDir ( ) , binary ) args = [ os . path . join ( os . path . dirname ( __file__ ) , <str> ) , <str> , binary_abs_path ] se = None if self . debug :          args . append ( <str> ) se = sys . stderr  ret_code , stdout , stderr = shell . ShellCommand ( args , stderr = se ) if ret_code :          raise ShellCommandError ( stderr )  binary_data = cjson . decode ( stdout ) binary_md5_sums . append ( ( binary , binary_data [ <str> ] ) )  return binary_md5_sums  def CollectStats ( self , force_unpack ) :      if force_unpack or not self . rest_client . BlobExists ( <str> , self . md5_sum ) :        self . _Gunzip ( ) self . _TransformToDir ( ) binary_md5_sums = self . _CollectElfdumpData ( ) main_struct = self . GetMainStatsStruct ( binary_md5_sums ) self . rest_client . SaveBlob ( <str> , self . md5_sum , main_struct ) return True  return False   if __name__ == <str> :    parser = optparse . OptionParser ( ) parser . add_option ( <str> , <str> , dest = <str> , help = <str> ) parser . add_option ( <str> , dest = <str> , action = <str> , default = False ) parser . add_option ( <str> , dest = <str> , action = <str> , default = False ) options , args = parser . parse_args ( ) if not options . input_file :      sys . stdout . write ( <str> ) sys . exit ( 1 )  logging_level = logging . INFO if options . debug :      logging_level = logging . DEBUG  fmt = <str> logging . basicConfig ( format = fmt , level = logging_level ) unpacker = Unpacker ( options . input_file , debug = options . debug ) unpacked = unpacker . CollectStats ( force_unpack = options . force_unpack ) unpacker . Cleanup ( ) data_back = { <str> : unpacker . md5_sum , <str> : bool ( unpacked ) , } print ( cjson . encode ( data_back ) )   