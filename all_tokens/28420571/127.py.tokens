from __future__ import print_function , division , absolute_import import numpy as np __all__ = ( <str> , <str> ) def proximal_gradient ( x , f , g , gamma , niter , callback = None , ** kwargs ) :      if x not in f . domain :          raise TypeError ( <str> <str> . format ( x , f . domain ) )  if x not in g . domain :          raise TypeError ( <str> <str> . format ( x , g . domain ) )  gamma , gamma_in = float ( gamma ) , gamma if gamma <= 0 :          raise ValueError ( <str> . format ( gamma_in ) )  if int ( niter ) != niter :          raise ValueError ( <str> . format ( niter ) )  lam_in = kwargs . pop ( <str> , 1.0 ) lam = lam_in if callable ( lam_in ) else lambda _ : float ( lam_in ) f_prox = f . proximal ( gamma ) g_grad = g . gradient tmp = x . space . element ( ) for k in range ( niter ) :          lam_k = lam ( k ) tmp . lincomb ( 1 , x , - gamma , g_grad ( x ) ) x . lincomb ( 1 - lam_k , x , lam_k , f_prox ( tmp ) ) if callback is not None :              callback ( x )    def accelerated_proximal_gradient ( x , f , g , gamma , niter , callback = None , ** kwargs ) :      if x not in f . domain :          raise TypeError ( <str> <str> . format ( x , f . domain ) )  if x not in g . domain :          raise TypeError ( <str> <str> . format ( x , g . domain ) )  gamma , gamma_in = float ( gamma ) , gamma if gamma <= 0 :          raise ValueError ( <str> . format ( gamma_in ) )  if int ( niter ) != niter :          raise ValueError ( <str> . format ( niter ) )  f_prox = f . proximal ( gamma ) g_grad = g . gradient tmp = x . space . element ( ) y = x . copy ( ) t = 1 for k in range ( niter ) :          t , t_old = ( 1 + np . sqrt ( 1 + 4 * t ** 2 ) ) / 2 , t alpha = ( t_old - 1 ) / t tmp . lincomb ( 1 , y , - gamma , g_grad ( y ) ) y . assign ( x ) f_prox ( tmp , out = x ) y . lincomb ( 1 + alpha , x , - alpha , y ) if callback is not None :              callback ( x )    if __name__ == <str> :      from odl . util . testutils import run_doctests run_doctests ( )   