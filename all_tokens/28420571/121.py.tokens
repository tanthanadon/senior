from __future__ import print_function , division , absolute_import from builtins import object import numpy as np __all__ = ( <str> , <str> , <str> , <str> ) class LineSearch ( object ) :      def __call__ ( self , x , direction , dir_derivative ) :          raise NotImplementedError ( <str> )   class BacktrackingLineSearch ( LineSearch ) :      def __init__ ( self , function , tau = 0.5 , discount = 0.01 , alpha = 1.0 , max_num_iter = None , estimate_step = False ) :          self . function = function self . tau = float ( tau ) self . discount = float ( discount ) self . estimate_step = bool ( estimate_step ) self . alpha = float ( alpha ) self . total_num_iter = 0 if max_num_iter is None :              try :                  dtype = self . function . domain . dtype  except AttributeError :                  dtype = float  eps = 10 * np . finfo ( dtype ) . resolution self . max_num_iter = int ( np . ceil ( np . log ( eps ) / np . log ( self . tau ) ) )  else :              self . max_num_iter = int ( max_num_iter )   def __call__ ( self , x , direction , dir_derivative = None ) :          fx = self . function ( x ) if dir_derivative is None :              try :                  gradient = self . function . gradient  except AttributeError :                  raise ValueError ( <str> <str> )  else :                  dir_derivative = gradient ( x ) . inner ( direction )   else :              dir_derivative = float ( dir_derivative )  if dir_derivative == 0 :              raise ValueError ( <str> )  if not self . estimate_step :              alpha = 1.0  else :              alpha = self . alpha  if dir_derivative > 0 :              alpha *= - 1  if not np . isfinite ( fx ) :              raise ValueError ( <str> <str> . format ( fx , x ) )  point = x . copy ( ) num_iter = 0 while True :              if num_iter > self . max_num_iter :                  raise ValueError ( <str> <str> <str> <str> . format ( self . max_num_iter , alpha ) )  point . lincomb ( 1 , x , alpha , direction ) fval = self . function ( point ) if np . isnan ( fval ) :                  raise ValueError ( <str> <str> . format ( point ) )  expected_decrease = np . abs ( alpha * dir_derivative * self . discount ) if ( fval <= fx - expected_decrease ) :                  break  num_iter += 1 alpha *= self . tau  assert fval < fx self . total_num_iter += num_iter self . alpha = np . abs ( alpha ) return alpha   class ConstantLineSearch ( LineSearch ) :      def __init__ ( self , constant ) :          self . constant = float ( constant )  def __call__ ( self , x , direction , dir_derivative ) :          return self . constant   class LineSearchFromIterNum ( LineSearch ) :      def __init__ ( self , func ) :          if not callable ( func ) :              raise TypeError ( <str> )  self . func = func self . iter_count = 0  def __call__ ( self , x , direction , dir_derivative ) :          step = self . func ( self . iter_count ) self . iter_count += 1 return step   if __name__ == <str> :      from odl . util . testutils import run_doctests run_doctests ( )   