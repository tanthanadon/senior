import numpy as np import odl import torch from torch import autograd , nn from odl . contrib import torch as odl_torch matrix = np . array ( [ [ 1 , 0 , 0 ] , [ 0 , 1 , 1 ] ] , dtype = <str> ) odl_op = odl . MatrixOperator ( matrix ) op_layer = odl_torch . operator . OperatorAsModule ( odl_op ) inp = autograd . Variable ( torch . ones ( 3 ) ) [ None , ... ] print ( <str> ) print ( op_layer ( inp ) ) inp = autograd . Variable ( torch . ones ( 3 ) ) [ None , None , ... ] print ( <str> ) print ( op_layer ( inp ) ) layer_before = nn . Linear ( 3 , 3 ) layer_after = nn . Linear ( 2 , 2 ) model1 = nn . Sequential ( layer_before , op_layer , layer_after ) print ( <str> ) print ( model1 ) print ( <str> ) inp = autograd . Variable ( torch . ones ( 3 ) ) [ None , ... ] print ( <str> ) print ( model1 ( inp ) ) layer_before = nn . Conv1d ( 1 , 2 , 2 ) layer_after = nn . Conv1d ( 2 , 1 , 2 ) model2 = nn . Sequential ( layer_before , op_layer , layer_after ) print ( <str> ) print ( model2 ) print ( <str> ) inp = autograd . Variable ( torch . ones ( 4 ) ) [ None , None , ... ] print ( <str> ) print ( model2 ( inp ) ) loss_fun = nn . MSELoss ( ) model = model1 inp = autograd . Variable ( torch . ones ( 3 ) ) [ None , ... ] target = autograd . Variable ( torch . zeros ( 2 ) ) [ None , ... ] loss = loss_fun ( model ( inp ) , target ) print ( <str> , loss . data [ 0 ] ) print ( <str> ) loss . backward ( ) print ( <str> ) for p in model . named_parameters ( ) :      name , value = p print ( <str> . format ( name ) ) print ( value )   