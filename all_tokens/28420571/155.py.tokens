from __future__ import print_function , division , absolute_import import numpy as np from odl . discr import DiscreteLp , uniform_partition from odl . operator import Operator from odl . set import IntervalProd from odl . space import FunctionSpace , tensor_space from odl . util import ( normalized_scalar_param_list , safe_int_conv , writable_array , resize_array ) from odl . util . numerics import _SUPPORTED_RESIZE_PAD_MODES __all__ = ( <str> , <str> ) class Resampling ( Operator ) :      def __init__ ( self , domain , range ) :          if domain . fspace != range . fspace :              raise ValueError ( <str> <str> <str> . format ( domain . fspace , range . fspace ) )  super ( Resampling , self ) . __init__ ( domain = domain , range = range , linear = True )  def _call ( self , x , out = None ) :          if out is None :              return x . interpolation  else :              out . sampling ( x . interpolation )   @ property def inverse ( self ) :          return Resampling ( self . range , self . domain )  @ property def adjoint ( self ) :          return self . inverse   class ResizingOperatorBase ( Operator ) :      def __init__ ( self , domain , range = None , ran_shp = None , ** kwargs ) :          import builtins ran , range = range , builtins . range if not isinstance ( domain , DiscreteLp ) :              raise TypeError ( <str> <str> . format ( domain ) )  offset = kwargs . pop ( <str> , None ) discr_kwargs = kwargs . pop ( <str> , { } ) if ran is None :              if ran_shp is None :                  raise ValueError ( <str> <str> )  offset = normalized_scalar_param_list ( offset , domain . ndim , param_conv = safe_int_conv , keep_none = True ) ran = _resize_discr ( domain , ran_shp , offset , discr_kwargs ) self . __offset = tuple ( _offset_from_spaces ( domain , ran ) )  elif ran_shp is None :              if offset is not None :                  raise ValueError ( <str> <str> )  for i in range ( domain . ndim ) :                  if ( ran . is_uniform_byaxis [ i ] and domain . is_uniform_byaxis [ i ] and not np . isclose ( ran . cell_sides [ i ] , domain . cell_sides [ i ] ) ) :                      raise ValueError ( <str> <str> <str> . format ( i , ran . cell_sides [ i ] - domain . cell_sides [ i ] ) )   self . __offset = _offset_from_spaces ( domain , ran )  else :              raise ValueError ( <str> )  pad_mode = kwargs . pop ( <str> , <str> ) pad_mode , pad_mode_in = str ( pad_mode ) . lower ( ) , pad_mode if pad_mode not in _SUPPORTED_RESIZE_PAD_MODES :              raise ValueError ( <str> <str> . format ( pad_mode_in ) )  self . __pad_mode = pad_mode self . __pad_const = np . array ( kwargs . pop ( <str> , 0 ) , dtype = ran . dtype ) linear = ( self . pad_mode != <str> or self . pad_const == 0.0 ) super ( ResizingOperatorBase , self ) . __init__ ( domain , ran , linear = linear )  @ property def offset ( self ) :          return self . __offset  @ property def pad_mode ( self ) :          return self . __pad_mode  @ property def pad_const ( self ) :          return self . __pad_const  @ property def axes ( self ) :          return tuple ( i for i in range ( self . domain . ndim ) if self . domain . shape [ i ] != self . range . shape [ i ] )   class ResizingOperator ( ResizingOperatorBase ) :      def _call ( self , x , out ) :          with writable_array ( out ) as out_arr :              resize_array ( x . asarray ( ) , self . range . shape , offset = self . offset , pad_mode = self . pad_mode , pad_const = self . pad_const , direction = <str> , out = out_arr )   def derivative ( self , point ) :          if self . pad_mode == <str> and self . pad_const != 0 :              return ResizingOperator ( domain = self . domain , range = self . range , pad_mode = <str> , pad_const = 0.0 )  else :              return self   @ property def adjoint ( self ) :          if not self . is_linear :              raise NotImplementedError ( <str> <str> )  forward_op = self class ResizingOperatorAdjoint ( ResizingOperatorBase ) :              def _call ( self , x , out ) :                  with writable_array ( out ) as out_arr :                      resize_array ( x . asarray ( ) , self . range . shape , offset = self . offset , pad_mode = self . pad_mode , pad_const = 0 , direction = <str> , out = out_arr )   @ property def adjoint ( self ) :                  return forward_op  @ property def inverse ( self ) :                  return ResizingOperatorAdjoint ( domain = self . range , range = self . domain , pad_mode = self . pad_mode )   return ResizingOperatorAdjoint ( domain = self . range , range = self . domain , pad_mode = self . pad_mode )  @ property def inverse ( self ) :          return ResizingOperator ( domain = self . range , range = self . domain , pad_mode = self . pad_mode , pad_const = self . pad_const )   def _offset_from_spaces ( dom , ran ) :      affected = np . not_equal ( dom . shape , ran . shape ) diff_l = np . abs ( ran . grid . min ( ) - dom . grid . min ( ) ) offset_float = diff_l / dom . cell_sides offset = np . around ( offset_float ) . astype ( int ) for i in range ( dom . ndim ) :          if affected [ i ] and not np . isclose ( offset [ i ] , offset_float [ i ] ) :              raise ValueError ( <str> <str> <str> . format ( i , offset_float [ i ] - offset [ i ] ) )   offset [ ~ affected ] = 0 return tuple ( offset )  def _resize_discr ( discr , newshp , offset , discr_kwargs ) :      nodes_on_bdry = discr_kwargs . get ( <str> , False ) if np . shape ( nodes_on_bdry ) == ( ) :          nodes_on_bdry = ( [ ( bool ( nodes_on_bdry ) , bool ( nodes_on_bdry ) ) ] * discr . ndim )  elif discr . ndim == 1 and len ( nodes_on_bdry ) == 2 :          nodes_on_bdry = [ nodes_on_bdry ]  elif len ( nodes_on_bdry ) != discr . ndim :          raise ValueError ( <str> <str> . format ( len ( nodes_on_bdry ) , discr . ndim ) )  dtype = discr_kwargs . pop ( <str> , discr . dtype ) impl = discr_kwargs . pop ( <str> , discr . impl ) exponent = discr_kwargs . pop ( <str> , discr . exponent ) interp = discr_kwargs . pop ( <str> , discr . interp ) weighting = discr_kwargs . pop ( <str> , discr . weighting ) affected = np . not_equal ( newshp , discr . shape ) ndim = discr . ndim for i in range ( ndim ) :          if affected [ i ] and not discr . is_uniform_byaxis [ i ] :              raise ValueError ( <str> <str> . format ( i ) )   grid_min , grid_max = discr . grid . min ( ) , discr . grid . max ( ) cell_size = discr . cell_sides new_minpt , new_maxpt = [ ] , [ ] for axis , ( n_orig , n_new , off , on_bdry ) in enumerate ( zip ( discr . shape , newshp , offset , nodes_on_bdry ) ) :          if not affected [ axis ] :              new_minpt . append ( discr . min_pt [ axis ] ) new_maxpt . append ( discr . max_pt [ axis ] ) continue  n_diff = n_new - n_orig if off is None :              num_r = n_diff // 2 num_l = n_diff - num_r  else :              num_r = n_diff - off num_l = off  try :              on_bdry_l , on_bdry_r = on_bdry  except TypeError :              on_bdry_l = on_bdry on_bdry_r = on_bdry  if on_bdry_l :              new_minpt . append ( grid_min [ axis ] - num_l * cell_size [ axis ] )  else :              new_minpt . append ( grid_min [ axis ] - ( num_l + 0.5 ) * cell_size [ axis ] )  if on_bdry_r :              new_maxpt . append ( grid_max [ axis ] + num_r * cell_size [ axis ] )  else :              new_maxpt . append ( grid_max [ axis ] + ( num_r + 0.5 ) * cell_size [ axis ] )   fspace = FunctionSpace ( IntervalProd ( new_minpt , new_maxpt ) , out_dtype = dtype ) tspace = tensor_space ( newshp , dtype = dtype , impl = impl , exponent = exponent , weighting = weighting ) part = uniform_partition ( [ ] , [ ] , ( ) ) for i in range ( ndim ) :          if discr . is_uniform_byaxis [ i ] :              part = part . append ( uniform_partition ( new_minpt [ i ] , new_maxpt [ i ] , newshp [ i ] , nodes_on_bdry = nodes_on_bdry [ i ] ) )  else :              part = part . append ( discr . partition . byaxis [ i ] )   return DiscreteLp ( fspace , part , tspace , interp = interp )  if __name__ == <str> :      from odl . util . testutils import run_doctests run_doctests ( )   