from __future__ import print_function , division , absolute_import from odl . solvers . util import ConstantLineSearch __all__ = ( <str> , ) def conjugate_gradient_nonlinear ( f , x , line_search = 1.0 , maxiter = 1000 , nreset = 0 , tol = 1e-16 , beta_method = <str> , callback = None ) :      <str> if x not in f . domain :          raise TypeError ( <str> <str> . format ( x , f . domain ) )  if not callable ( line_search ) :          line_search = ConstantLineSearch ( line_search )  if beta_method not in [ <str> , <str> , <str> , <str> ] :          raise ValueError ( <str> )  for _ in range ( nreset + 1 ) :          dx = - f . gradient ( x ) dir_derivative = - dx . inner ( dx ) if abs ( dir_derivative ) < tol :              return  a = line_search ( x , dx , dir_derivative ) x . lincomb ( 1 , x , a , dx ) s = dx for _ in range ( maxiter // ( nreset + 1 ) ) :              dx , dx_old = - f . gradient ( x ) , dx if beta_method == <str> :                  beta = dx . inner ( dx ) / dx_old . inner ( dx_old )  elif beta_method == <str> :                  beta = dx . inner ( dx - dx_old ) / dx_old . inner ( dx_old )  elif beta_method == <str> :                  beta = - dx . inner ( dx - dx_old ) / s . inner ( dx - dx_old )  elif beta_method == <str> :                  beta = - dx . inner ( dx ) / s . inner ( dx - dx_old )  else :                  raise RuntimeError ( <str> )  beta = max ( 0 , beta ) s . lincomb ( 1 , dx , beta , s ) dir_derivative = - dx . inner ( s ) if abs ( dir_derivative ) <= tol :                  return  a = line_search ( x , s , dir_derivative ) x . lincomb ( 1 , x , a , s ) if callback is not None :                  callback ( x )      