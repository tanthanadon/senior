from __future__ import division , print_function import odl class MyFunctional ( odl . solvers . Functional ) :      def __init__ ( self , space , y ) :          super ( MyFunctional , self ) . __init__ ( space = space , linear = False , grad_lipschitz = 2 ) if y not in space :              raise TypeError ( <str> )  self . y = y  def _call ( self , x ) :          return x . norm ( ) ** 2 + x . inner ( self . y )  @ property def gradient ( self ) :          functional = self class MyGradientOperator ( odl . Operator ) :              def __init__ ( self ) :                  super ( MyGradientOperator , self ) . __init__ ( domain = functional . domain , range = functional . domain )  def _call ( self , x ) :                  return 2.0 * x + functional . y   return MyGradientOperator ( )  @ property def convex_conj ( self ) :          return MyFunctionalConjugate ( space = self . domain , y = self . y )   class MyFunctionalConjugate ( odl . solvers . Functional ) :      def __init__ ( self , space , y ) :          super ( MyFunctionalConjugate , self ) . __init__ ( space = space , linear = False , grad_lipschitz = 2 ) if y not in space :              raise TypeError ( <str> )  self . y = y  def _call ( self , x ) :          return ( x - self . y ) . norm ( ) ** 2 / 4.0   space = odl . uniform_discr ( 0 , 1 , 3 ) linear_term = space . element ( [ 1 , - 4 , 7 ] ) my_func = MyFunctional ( space = space , y = linear_term ) point = odl . util . testutils . noise_element ( space ) print ( <str> <str> . format ( my_func ( point ) ) ) x = space . one ( ) line_search = odl . solvers . BacktrackingLineSearch ( my_func , max_num_iter = 10 ) odl . solvers . steepest_descent ( my_func , x , maxiter = 10 , line_search = line_search ) print ( <str> . format ( ( - 1.0 / 2 ) * linear_term ) ) print ( <str> . format ( x ) ) scalar = 3.2 translation = space . one ( ) scal_trans_cc_func = ( scalar * my_func ) . translated ( translation ) . convex_conj print ( <str> <str> . format ( scal_trans_cc_func ( point ) ) )  