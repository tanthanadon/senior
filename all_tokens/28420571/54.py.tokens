from __future__ import division import odl from odl . util . testutils import all_almost_equal import pytest import numpy as np @ pytest . fixture ( scope = <str> , params = [ <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> ] ) def iterative_solver ( request ) :      solver_name = request . param if solver_name == <str> :          def solver ( op , x , rhs ) :              norm2 = op . adjoint ( op ( x ) ) . norm ( ) / x . norm ( ) func = odl . solvers . L2NormSquared ( op . domain ) * ( op - rhs ) odl . solvers . steepest_descent ( func , x , line_search = 0.5 / norm2 )   elif solver_name == <str> :          def solver ( op , x , rhs ) :              norm2 = op . adjoint ( op ( x ) ) . norm ( ) / x . norm ( ) func = odl . solvers . L2NormSquared ( op . domain ) * ( op - rhs ) odl . solvers . adam ( func , x , learning_rate = 4.0 / norm2 , maxiter = 150 )   elif solver_name == <str> :          def solver ( op , x , rhs ) :              norm2 = op . adjoint ( op ( x ) ) . norm ( ) / x . norm ( ) odl . solvers . landweber ( op , x , rhs , niter = 50 , omega = 0.5 / norm2 )   elif solver_name == <str> :          def solver ( op , x , rhs ) :              odl . solvers . conjugate_gradient ( op , x , rhs , niter = 10 )   elif solver_name == <str> :          def solver ( op , x , rhs ) :              odl . solvers . conjugate_gradient_normal ( op , x , rhs , niter = 10 )   elif solver_name == <str> :          def solver ( op , x , rhs ) :              odl . solvers . mlem ( op , x , rhs , niter = 10 )   elif solver_name == <str> :          def solver ( op , x , rhs ) :              odl . solvers . osmlem ( [ op , op ] , x , [ rhs , rhs ] , niter = 10 )   elif solver_name == <str> :          def solver ( op , x , rhs ) :              norm2 = op . adjoint ( op ( x ) ) . norm ( ) / x . norm ( ) odl . solvers . kaczmarz ( [ op , op ] , x , [ rhs , rhs ] , niter = 20 , omega = 0.5 / norm2 )   else :          raise ValueError ( <str> )  return solver  @ pytest . fixture ( scope = <str> , params = [ <str> , <str> ] ) def optimization_problem ( request ) :      problem_name = request . param if problem_name == <str> :          op_arr = np . eye ( 5 ) * 5 + np . ones ( [ 5 , 5 ] ) op = odl . MatrixOperator ( op_arr ) rhs = op . range . one ( ) x = op . domain . element ( [ 0.6 , 0.8 , 1.0 , 1.2 , 1.4 ] ) return op , x , rhs  elif problem_name == <str> :          space = odl . uniform_discr ( 0 , 1 , 5 ) op = odl . IdentityOperator ( space ) rhs = op . range . element ( [ 0 , 0 , 1 , 0 , 0 ] ) x = op . domain . element ( [ 0.6 , 0.8 , 1.0 , 1.2 , 1.4 ] ) return op , x , rhs  else :          raise ValueError ( <str> )   def test_solver ( optimization_problem , iterative_solver ) :      op , x , rhs = optimization_problem iterative_solver ( op , x , rhs ) assert all_almost_equal ( op ( x ) , rhs , ndigits = 2 )  def test_steepst_descent ( ) :      space = odl . rn ( 3 ) scale = 1 rosenbrock = odl . solvers . RosenbrockFunctional ( space , scale ) line_search = odl . solvers . BacktrackingLineSearch ( rosenbrock , 0.1 , 0.01 ) x = rosenbrock . domain . zero ( ) odl . solvers . steepest_descent ( rosenbrock , x , maxiter = 40 , line_search = line_search ) assert all_almost_equal ( x , [ 1 , 1 , 1 ] , ndigits = 2 )  if __name__ == <str> :      odl . util . test_file ( __file__ )   