import os import unittest from unittest . mock import patch from cltk . stem . latin . j_v import JVReplacer from cltk . tokenize . word import WordTokenizer from cltk . corpus . utils . importer import CorpusImporter from cltk . lemmatize . backoff import DefaultLemmatizer from cltk . lemmatize . backoff import IdentityLemmatizer from cltk . lemmatize . backoff import UnigramLemmatizer from cltk . lemmatize . backoff import DictLemmatizer from cltk . lemmatize . backoff import RegexpLemmatizer from cltk . lemmatize . latin . backoff import BackoffLatinLemmatizer from cltk . lemmatize . latin . backoff import RomanNumeralLemmatizer from cltk . lemmatize . greek . backoff import BackoffGreekLemmatizer from cltk . lemmatize . french . lemma import LemmaReplacer __author__ = [ <str> , <str> ] __license__ = <str> class TestSequenceFunctions ( unittest . TestCase ) :      def setUp ( self ) :          corpus_importer = CorpusImporter ( <str> ) corpus_importer . import_corpus ( <str> ) file_rel = os . path . join ( get_cltk_data_dir ( ) + <str> ) file = os . path . expanduser ( file_rel ) file_exists = os . path . isfile ( file ) self . assertTrue ( file_exists )  def test_default_lemmatizer ( self ) :          lemmatizer = DefaultLemmatizer ( <str> ) test_str = <str> target = [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] jv_replacer = JVReplacer ( ) tokenizer = WordTokenizer ( <str> ) test_str = test_str . lower ( ) test_str = jv_replacer . replace ( test_str ) tokens = tokenizer . tokenize ( test_str ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_identity_lemmatizer ( self ) :          lemmatizer = IdentityLemmatizer ( ) test_str = <str> target = [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] jv_replacer = JVReplacer ( ) tokenizer = WordTokenizer ( <str> ) test_str = test_str . lower ( ) test_str = jv_replacer . replace ( test_str ) tokens = tokenizer . tokenize ( test_str ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_dict_lemmatizer ( self ) :          lemmas = { <str> : <str> , <str> : <str> , <str> : <str> , <str> : <str> } lemmatizer = DictLemmatizer ( lemmas = lemmas ) test_str = <str> target = [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] jv_replacer = JVReplacer ( ) tokenizer = WordTokenizer ( <str> ) test_str = test_str . lower ( ) test_str = jv_replacer . replace ( test_str ) tokens = tokenizer . tokenize ( test_str ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_unigram_lemmatizer ( self ) :          train = [ [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] ] lemmatizer = UnigramLemmatizer ( train = train ) test_str = target = [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] jv_replacer = JVReplacer ( ) tokenizer = WordTokenizer ( <str> ) test_str = test_str . lower ( ) test_str = jv_replacer . replace ( test_str ) tokens = tokenizer . tokenize ( test_str ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_regex_lemmatizer ( self ) :          sub = [ ( <str> , <str> ) ] lemmatizer = RegexpLemmatizer ( sub ) test_str = <str> target = [ ( <str> , <str> ) ] jv_replacer = JVReplacer ( ) tokenizer = WordTokenizer ( <str> ) test_str = test_str . lower ( ) test_str = jv_replacer . replace ( test_str ) tokens = tokenizer . tokenize ( test_str ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_roman_numeral_lemmatizer ( self ) :          lemmatizer = RomanNumeralLemmatizer ( ) test_str = <str> target = [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] jv_replacer = JVReplacer ( ) test_str = test_str . lower ( ) test_str = jv_replacer . replace ( test_str ) tokens = test_str . split ( ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_roman_numeral_lemmatizer_default ( self ) :          lemmatizer = RomanNumeralLemmatizer ( default = <str> ) test_str = <str> target = [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] tokens = test_str . split ( ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_backoff_latin_lemmatizer ( self ) :          train = [ [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] ] lemmatizer = BackoffLatinLemmatizer ( ) test_str = target = [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] jv_replacer = JVReplacer ( ) tokenizer = WordTokenizer ( <str> ) test_str = test_str . lower ( ) test_str = jv_replacer . replace ( test_str ) tokens = tokenizer . tokenize ( test_str ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_backoff_latin_lemmatizer_verbose ( self ) :          train = [ [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] ] lemmatizer = BackoffLatinLemmatizer ( verbose = True ) test_str = target = [ ( <str> , <str> , <str> ) , ( <str> , <str> , <str> ) , ( <str> , <str> , <str> ) , ( <str> , <str> , <str> ) ] jv_replacer = JVReplacer ( ) tokenizer = WordTokenizer ( <str> ) test_str = test_str . lower ( ) test_str = jv_replacer . replace ( test_str ) tokens = tokenizer . tokenize ( test_str ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_backoff_latin_lemmatizer_evaluate ( self ) :          lemmatizer = BackoffLatinLemmatizer ( verbose = False ) accuracy = lemmatizer . evaluate ( ) self . assertTrue ( .85 <= accuracy <= 1 )  def test_backoff_latin_lemmatizer_evaluate_verbose ( self ) :          lemmatizer = BackoffLatinLemmatizer ( verbose = True ) with self . assertRaises ( AssertionError ) :              accuracy = lemmatizer . evaluate ( )   def test_backoff_latin_lemmatizer_models_not_present ( self ) :          with patch . object ( BackoffLatinLemmatizer , <str> , <str> ) :              with self . assertRaises ( FileNotFoundError ) :                  lemmatizer = BackoffLatinLemmatizer ( )    def test_backoff_greek_lemmatizer ( self ) :          train = [ [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] ] lemmatizer = BackoffGreekLemmatizer ( ) test_str = target = [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) ] tokens = test_str . split ( ) lemmas = lemmatizer . lemmatize ( tokens ) self . assertEqual ( lemmas , target )  def test_backoff_greek_lemmatizer_models_not_present ( self ) :          with patch . object ( BackoffGreekLemmatizer , <str> , <str> ) :              with self . assertRaises ( FileNotFoundError ) :                  lemmatizer = BackoffGreekLemmatizer ( )    def test_french_lemmatizer ( self ) :          text = <str> text = str . lower ( text ) tokenizer = WordTokenizer ( <str> ) lemmatizer = LemmaReplacer ( ) tokens = tokenizer . tokenize ( text ) lemmas = lemmatizer . lemmatize ( tokens ) target = [ ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , [ <str> ] ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , [ <str> ] ) , ( <str> , <str> ) , ( <str> , [ <str> ] ) , ( <str> , <str> ) , ( <str> , [ <str> ] ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , [ <str> ] ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , [ <str> ] ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , [ <str> ] ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , <str> ) , ( <str> , [ <str> ] ) ] self . assertEqual ( lemmas , target )   if __name__ == <str> :      unittest . main ( )   