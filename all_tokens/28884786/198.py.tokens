from collections import defaultdict import os from typing import Any from typing import DefaultDict from typing import IO from typing import List from typing import Set from typing import Union from nltk . tokenize . punkt import PunktLanguageVars import pyuca from cltk . utils . cltk_logger import logger __author__ = [ <str> , <str> , <str> ] __license__ = <str> def read_file ( filepath : str ) -> str :      filepath = os . path . expanduser ( filepath ) with open ( filepath ) as opened_file :          file_read = opened_file . read ( ) return file_read   def build_concordance ( text_str : str ) -> List [ List [ str ] ] :      punkt_vars = PunktLanguageVars ( ) orig_tokens = punkt_vars . word_tokenize ( text_str ) concordance_index = ConcordanceIndex ( orig_tokens ) tokens_set = set ( orig_tokens ) punct_list = [ <str> , <str> , <str> , <str> , <str> , <str> , <str> , <str> ] tokens = [ x for x in tokens_set if x not in punct_list ] index = concordance_index . return_concordance_all ( tokens ) return index  def write_concordance_from_string ( text : str , name : str ) -> None :      list_of_lists = build_concordance ( text ) user_data_rel = get_cltk_data_dir ( ) + <str> user_data = os . path . expanduser ( user_data_rel ) if not os . path . isdir ( user_data ) :          os . makedirs ( user_data )  file_path = os . path . join ( user_data , <str> + name + <str> ) concordance_output = <str> for word_list in list_of_lists :          for line in word_list :              concordance_output += line + <str>   try :          with open ( file_path , <str> ) as open_file :              open_file . write ( concordance_output ) logger . info ( <str> , file_path )   except IOError as io_error :          logger . error ( <str> , file_path , io_error )   def write_concordance_from_file ( filepaths : Union [ str , List [ str ] ] , name : str ) -> None :      assert isinstance ( filepaths , ( str , list ) ) if isinstance ( filepaths , str ) :          filepath = filepaths text = read_file ( filepath )  elif isinstance ( filepaths , list ) :          text = <str> for filepath in filepaths :              text += read_file ( filepath )   list_of_lists = build_concordance ( text ) user_data_rel = get_cltk_data_dir ( ) + <str> user_data = os . path . expanduser ( user_data_rel ) if not os . path . isdir ( user_data ) :          os . makedirs ( user_data )  file_path = os . path . join ( user_data , <str> + name + <str> ) concordance_output = <str> for word_list in list_of_lists :          for line in word_list :              concordance_output += line + <str>   try :          with open ( file_path , <str> ) as open_file :              open_file . write ( concordance_output ) logger . info ( <str> , file_path )   except IOError as io_error :          logger . error ( <str> , file_path , io_error )   class ConcordanceIndex :      def __init__ ( self , tokens : List [ str ] ) -> None :          self . _tokens = tokens self . _offsets = defaultdict ( list ) for index , word in enumerate ( tokens ) :              self . _offsets [ word ] . append ( index )   def tokens ( self ) -> List [ str ] :          return self . _tokens  def offsets ( self , word : str ) -> List [ int ] :          return self . _offsets [ word ]  def __repr__ ( self ) -> str :          return <str> % ( len ( self . _tokens ) , len ( self . _offsets ) )  def return_concordance_word ( self , word : str , width : int = 150 , lines : int = 1000000 ) -> List [ str ] :          return_list = [ ] half_width = ( width - len ( word ) - 2 ) // 2 context = width // 4 offsets = self . offsets ( word ) if offsets :              lines = min ( lines , len ( offsets ) ) while lines :                  for i in offsets :                      left = ( <str> * half_width + <str> . join ( self . _tokens [ i - context : i ] ) ) right = <str> . join ( self . _tokens [ i + 1 : i + context ] ) left = left [ - half_width : ] right = right [ : half_width ] line_str = left + <str> + self . _tokens [ i ] + <str> + right return_list . append ( line_str ) lines -= 1   return return_list  return list ( )  def return_concordance_all ( self , tokens : List [ str ] ) -> List [ List [ str ] ] :          coll = pyuca . Collator ( ) tokens = sorted ( tokens , key = coll . sort_key ) concordance_list = [ ] for token in tokens :              concordance_list_for_word = self . return_concordance_word ( token ) if concordance_list_for_word :                  concordance_list . append ( concordance_list_for_word )   return concordance_list    