from cltk . tokenize . word import WordTokenizer from cltk . stop . arabic . stops import STOPS_LIST as ARABIC_STOPS import cltk . corpus . arabic . utils . pyarabic . araby as araby def stopwords_filter ( string ) :      text = string text = araby . strip_tashkeel ( text ) word_tokenizer = WordTokenizer ( <str> ) tokens = word_tokenizer . tokenize ( text ) no_stops = [ w for w in tokens if w not in ARABIC_STOPS ] return no_stops   