from __future__ import absolute_import import json import os import re import logging import sys from django . utils import timezone from datetime import time , datetime def tz_now ( ) :      return timezone . make_aware ( datetime . now ( ) , timezone . get_default_timezone ( ) )  def tz_midnight ( date ) :      t = time ( 0 , 0 , 0 , tzinfo = timezone . get_default_timezone ( ) ) return datetime . combine ( date , t )  def apply_default_tz ( dt ) :      if dt is None :          return None  else :          return timezone . make_aware ( dt , timezone . get_default_timezone ( ) )   def version_default ( ) :      return { }  def derive_defaults_from_argo ( argo_yaml ) :      versions = { } try :          versions [ <str> ] = argo_yaml . get ( <str> , { } ) . get ( <str> , { } ) . get ( <str> ) templates = argo_yaml . get ( <str> , { } ) . get ( <str> , [ { } ] ) entrypoints = [ x [ <str> ] for x in templates if <str> in x . keys ( ) ] versions [ <str> ] = entrypoints  except AttributeError :          logging . warning ( <str> )  return versions  def log_progress_parser ( log , container_type ) :      lines = log . splitlines ( ) if container_type == <str> :          for line in lines [ : : - 1 ] :              parsed = delft3d_logparser ( line ) if parsed [ <str> ] is not None :                  return parsed [ <str> ]    else :          for line in lines [ : : - 1 ] :              parsed = python_logparser ( line ) if parsed [ <str> ] is not None :                  return parsed [ <str> ]     def delft3d_logparser ( line ) :      try :          percentage_re = re . compile ( <str> , re . VERBOSE ) match = percentage_re . search ( line ) if match :              match = match . groupdict ( ) match [ <str> ] = line if ( <str> in match and match [ <str> ] is not None and match [ <str> ] != <str> ) :                  match [ <str> ] = float ( match [ <str> ] )  match [ <str> ] = <str> match [ <str> ] = None  else :              match = { <str> : None , <str> : <str> , <str> : None , <str> : None }  return match  except :          e = sys . exc_info ( ) [ 1 ] return { <str> : <str> % ( e . message , line ) , <str> : <str> , <str> : None , <str> : None }   def python_logparser ( line ) :      try :          python_re = re . compile ( <str> , re . VERBOSE ) match = python_re . search ( line ) if match :              match = match . groupdict ( ) if ( <str> in match and match [ <str> ] is not None and match [ <str> ] != <str> ) :                  match [ <str> ] = format ( float ( match [ <str> ] ) / 100 , <str> )   else :              match = { <str> : line , <str> : <str> , <str> : None , <str> : None }  return match  except :          e = sys . exc_info ( ) [ 1 ] return { <str> : <str> % ( e . message , line ) , <str> : <str> , <str> : None , <str> : None }   def scan_output_files ( workingdir , info_dict ) :      processed_files = 0 required_keys = [ <str> , <str> , <str> ] for key , value in info_dict . items ( ) :          if not isinstance ( value , dict ) :              continue  if not all ( [ k in value for k in required_keys ] ) :              continue  foldername = os . path . join ( workingdir , value [ <str> ] ) for root , __ , files in os . walk ( foldername ) :              for fn in sorted ( files ) :                  name , ext = os . path . splitext ( fn ) if ext not in value [ <str> ] :                      continue  if fn in value [ <str> ] :                      continue  processed_files += 1 if <str> in key :                      type_of_image = key . split ( <str> ) [ 0 ] if ( type_of_image in name ) :                          info_dict [ key ] [ <str> ] . append ( fn )   elif <str> in ext :                      with open ( os . path . join ( root , fn ) ) as f :                          try :                              output_dict = json . load ( f ) output_dict = clean ( output_dict ) info_dict [ key ] [ <str> ] [ name ] = output_dict  except ValueError as e :                              logging . error ( <str> . format ( f , e ) )    else :                      info_dict [ key ] [ <str> ] . append ( fn )    if processed_files > 0 :              logging . info ( <str> . format ( processed_files ) )   return info_dict  def clean ( jsondict ) :      for k , v in jsondict . items ( ) :          if isinstance ( v , float ) :              if not ( float ( <str> ) < float ( v ) < float ( <str> ) ) :                  jsondict [ k ] = None    return jsondict  def merge_list_of_dict ( a , b , key = <str> ) :      keys = [ x [ key ] for x in a ] for d in b :          if d [ key ] in keys :              continue  else :              a . append ( d )   return a  def merge_log_unique ( original , update ) :      overlap = False o = original . split ( <str> ) u = update . split ( <str> ) for i , oline in enumerate ( o ) :          if oline == u [ 0 ] :              overlap = True break   if overlap :          new = o [ 0 : i ] new . extend ( u ) return <str> . join ( new )  else :          return original + update    