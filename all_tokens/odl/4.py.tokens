import odl import scipy . signal class Convolution ( odl . Operator ) :      def __init__ ( self , kernel ) :          self . kernel = kernel super ( Convolution , self ) . __init__ ( domain = kernel . space , range = kernel . space , linear = True )  def _call ( self , x ) :          return scipy . signal . fftconvolve ( self . kernel , x , mode = <str> )  @ property def adjoint ( self ) :          return self   space = odl . uniform_discr ( [ - 1 , - 1 ] , [ 1 , 1 ] , [ 100 , 100 ] ) kernel = odl . phantom . cuboid ( space , [ - 0.05 , - 0.05 ] , [ 0.05 , 0.05 ] ) A = Convolution ( kernel ) phantom = odl . phantom . shepp_logan ( space , modified = True ) g = A ( phantom ) kernel . show ( <str> ) phantom . show ( <str> ) g . show ( <str> ) opnorm = odl . power_method_opnorm ( A ) f = space . zero ( ) odl . solvers . landweber ( A , f , g , niter = 100 , omega = 1 / opnorm ** 2 ) f . show ( <str> ) f = space . zero ( ) odl . solvers . conjugate_gradient_normal ( A , f , g , niter = 100 ) f . show ( <str> ) B = odl . IdentityOperator ( space ) a = 0.1 T = A . adjoint * A + a * B . adjoint * B b = A . adjoint ( g ) f = space . zero ( ) odl . solvers . conjugate_gradient ( T , f , b , niter = 100 ) f . show ( <str> ) B = odl . Gradient ( space ) a = 0.0001 T = A . adjoint * A + a * B . adjoint * B b = A . adjoint ( g ) f = space . zero ( ) odl . solvers . conjugate_gradient ( T , f , b , niter = 100 ) f . show ( <str> ) grad = odl . Gradient ( space ) lin_ops = [ A , grad ] a = 0.001 g_funcs = [ odl . solvers . L2NormSquared ( space ) . translated ( g ) , a * odl . solvers . L1Norm ( grad . range ) ] f = odl . solvers . IndicatorBox ( space , 0 , 1 ) opnorm_A = odl . power_method_opnorm ( A , xstart = g ) opnorm_grad = odl . power_method_opnorm ( grad , xstart = g ) sigma = [ 1 / opnorm_A ** 2 , 1 / opnorm_grad ** 2 ] tau = 1.0 x = space . zero ( ) odl . solvers . douglas_rachford_pd ( x , f , g_funcs , lin_ops , tau = tau , sigma = sigma , niter = 100 ) x . show ( <str> , force_show = True )  