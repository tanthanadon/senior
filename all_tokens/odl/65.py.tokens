from __future__ import division import pytest import numpy as np import theano import theano . tensor as T import odl import odl . contrib . theano from odl . util import all_almost_equal def test_theano_operator ( ) :      matrix = np . random . rand ( 3 , 2 ) odl_op = odl . MatrixOperator ( matrix ) x = [ 1. , 2. ] dy = [ 1. , 2. , 3. ] x_theano = T . dvector ( ) dy_theano = T . dvector ( ) odl_op_layer = odl . contrib . theano . TheanoOperator ( odl_op ) y_theano = odl_op_layer ( x_theano ) y_theano_func = theano . function ( [ x_theano ] , y_theano ) dy_theano_func = theano . function ( [ x_theano , dy_theano ] , T . Rop ( y_theano , x_theano , dy_theano ) ) result = y_theano_func ( x ) expected = odl_op ( x ) assert all_almost_equal ( result , expected ) result = dy_theano_func ( x , dy ) expected = odl_op . derivative ( x ) . adjoint ( dy ) assert all_almost_equal ( result , expected )  def test_theano_gradient ( ) :      matrix = np . random . rand ( 3 , 2 ) odl_op = odl . MatrixOperator ( matrix ) x = [ 1. , 2. ] odl_cost = odl . solvers . L2NormSquared ( odl_op . range ) odl_functional = odl_cost * odl_op x_theano = T . dvector ( ) odl_op_layer = odl . contrib . theano . TheanoOperator ( odl_op ) odl_cost_layer = odl . contrib . theano . TheanoOperator ( odl_cost ) y_theano = odl_op_layer ( x_theano ) cost_theano = odl_cost_layer ( y_theano ) cost_theano_func = theano . function ( [ x_theano ] , cost_theano ) cost_grad_theano = T . grad ( cost_theano , x_theano ) cost_grad_theano_func = theano . function ( [ x_theano ] , cost_grad_theano ) result = cost_theano_func ( x ) expected = odl_functional ( x ) assert result == pytest . approx ( expected ) result = cost_grad_theano_func ( x ) expected = odl_functional . gradient ( x ) assert all_almost_equal ( result , expected )  if __name__ == <str> :      odl . util . test_file ( __file__ )   