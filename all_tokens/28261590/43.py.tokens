import argparse import numpy as np from scipy . sparse import coo_matrix , dia_matrix import time from os import unlink import os from io import StringIO import warnings warnings . simplefilter ( action = <str> , category = RuntimeWarning ) warnings . simplefilter ( action = <str> , category = PendingDeprecationWarning ) import pysam from collections import OrderedDict from copy import deepcopy from ctypes import Structure , c_uint , c_ushort from multiprocessing import Process , Queue from multiprocessing . sharedctypes import Array , RawArray from intervaltree import IntervalTree , Interval from Bio . Seq import Seq from Bio . Alphabet import generic_dna from hicmatrix import HiCMatrix as hm from hicexplorer . utilities import getUserRegion , genomicRegion from hicexplorer . _version import __version__ import hicexplorer . hicPrepareQCreport as QC from hicmatrix . lib import MatrixFileHandler from hicexplorer import hicMergeMatrixBins import logging log = logging . getLogger ( __name__ ) class C_Interval ( Structure ) :      _fields_ = [ ( <str> , c_uint ) , ( <str> , c_uint ) , ( <str> , c_uint ) ]  class C_Coverage ( Structure ) :      _fields_ = [ ( <str> , c_uint ) , ( <str> , c_uint ) ]  class ReadPositionMatrix ( object ) :      def __init__ ( self ) :          self . pos_matrix = set ( )  def is_duplicated ( self , chrom1 , start1 , chrom2 , start2 ) :          if chrom1 < chrom2 :              id_string = <str> . format ( chrom1 , chrom2 )  else :              id_string = <str> . format ( chrom2 , chrom1 )  if start1 < start2 :              id_string += <str> . format ( start1 , start2 )  else :              id_string += <str> . format ( start2 , start1 )  if id_string in self . pos_matrix :              return True  else :              self . pos_matrix . add ( id_string ) return False    def parse_arguments ( args = None ) :      parser = argparse . ArgumentParser ( formatter_class = argparse . ArgumentDefaultsHelpFormatter , add_help = False , description = ( <str> <str> <str> <str> <str> ) ) parserRequired = parser . add_argument_group ( <str> ) parserRequired . add_argument ( <str> , <str> , help = <str> , metavar = <str> , nargs = 2 , type = argparse . FileType ( <str> ) , required = True ) parserRequired . add_argument ( <str> , <str> , help = <str> , metavar = <str> , type = argparse . FileType ( <str> ) , required = True ) parserRequired . add_argument ( <str> , help = <str> <str> <str> , metavar = <str> , required = True ) parserOpt = parser . add_argument_group ( <str> ) parserOpt . add_argument ( <str> , <str> , help = <str> <str> <str> <str> <str> <str> , metavar = <str> , type = argparse . FileType ( <str> ) , required = False ) group = parserOpt . add_mutually_exclusive_group ( required = True ) group . add_argument ( <str> , <str> , help = <str> <str> <str> <str> <str> <str> , type = int , nargs = <str> ) group . add_argument ( <str> , <str> , help = ( <str> <str> <str> <str> <str> <str> <str> ) , type = argparse . FileType ( <str> ) , metavar = <str> ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> , type = int , default = 300 , required = False ) parserOpt . add_argument ( <str> , help = <str> , type = int ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> <str> <str> , type = int , default = 1000 , required = False ) parserOpt . add_argument ( <str> , <str> , help = <str> ) parserOpt . add_argument ( <str> , <str> , help = <str> ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> <str> <str> <str> <str> ) parserOpt . add_argument ( <str> , <str> , help = <str> <str> <str> , metavar = <str> , required = False , type = genomicRegion ) parserOpt . add_argument ( <str> , help = argparse . SUPPRESS , required = False , default = True ) parserOpt . add_argument ( <str> , help = <str> <str> , required = False , action = <str> ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> , required = False , default = 15 , type = int ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> <str> <str> <str> <str> , required = False , default = 4 , type = int ) parserOpt . add_argument ( <str> , help = <str> <str> , required = False , default = 400000 , type = int ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> <str> , action = <str> ) parserOpt . add_argument ( <str> , help = <str> , required = False , default = 1000000 , type = int ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> , action = <str> ) parserOpt . add_argument ( <str> , <str> , action = <str> , help = <str> ) parserOpt . add_argument ( <str> , action = <str> , version = <str> . format ( __version__ ) ) return parser  def intervalListToIntervalTree ( interval_list ) :      <str> bin_int_tree = { } for intval_id , intval in enumerate ( interval_list ) :          chrom , start , end = intval [ 0 : 3 ] if chrom not in bin_int_tree :              bin_int_tree [ chrom ] = IntervalTree ( )  bin_int_tree [ chrom ] . add ( Interval ( start , end , intval_id ) )  return bin_int_tree  def get_bins ( bin_size , chrom_size , region = None ) :      <str> bin_intvals = [ ] start = 0 if region :          chrom_size , start , _ , _ = getUserRegion ( chrom_size , region )  for chrom , size in chrom_size :          for interval in range ( start , size , bin_size ) :              bin_intvals . append ( ( chrom , interval , min ( size , interval + bin_size ) ) )   return bin_intvals  def bed2interval_list ( bed_file_handler ) :      <str> count = 0 interval_list = [ ] for line in bed_file_handler :          count += 1 fields = line . strip ( ) . split ( ) try :              chrom , start , end = fields [ 0 ] , int ( fields [ 1 ] ) , int ( fields [ 2 ] )  except IndexError :              log . error ( <str> . format ( count ) )  interval_list . append ( ( chrom , start , end ) )  return interval_list  def get_rf_bins ( rf_cut_intervals , min_distance = 200 , max_distance = 800 ) :      <str> log . info ( <str> <str> <str> . format ( min_distance , max_distance ) ) chrom , start , end = list ( zip ( * rf_cut_intervals ) ) rest_site_len = end [ 0 ] - start [ 0 ] to_merge = np . flatnonzero ( np . diff ( start ) - rest_site_len <= min_distance ) to_merge += 1 merge_idx = 0 start = np . array ( start ) - max_distance end = np . array ( end ) + max_distance new_start = [ max ( 0 , start [ 0 ] ) ] new_end = [ ] new_chrom = [ chrom [ 0 ] ] for idx in range ( 1 , len ( start ) ) :          if chrom [ idx ] != chrom [ idx - 1 ] :              new_start . append ( max ( 0 , start [ idx ] ) ) new_end . append ( end [ idx - 1 ] ) new_chrom . append ( chrom [ idx ] ) merge_idx += 1 continue  if merge_idx < len ( to_merge ) and idx == to_merge [ merge_idx ] :              merge_idx += 1 continue  if chrom [ idx ] == chrom [ idx - 1 ] and end [ idx - 1 ] > start [ idx ] :              middle = start [ idx ] + int ( ( end [ idx - 1 ] - start [ idx ] ) / 2 ) new_start . append ( middle ) new_end . append ( middle )  else :              new_start . append ( start [ idx ] ) new_end . append ( end [ idx - 1 ] )  new_chrom . append ( chrom [ idx ] )  new_end . append ( end [ - 1 ] ) assert len ( new_chrom ) == len ( new_start ) , <str> assert len ( new_end ) == len ( new_start ) , <str> intervals = zip ( new_chrom , new_start , new_end ) intervals = [ ( _chrom , _start , _end ) for _chrom , _start , _end in intervals if _end - _start >= min_distance ] return intervals  def get_chrom_sizes ( bam_handle ) :      list_chrom_sizes = OrderedDict ( zip ( bam_handle . references , bam_handle . lengths ) ) return list ( list_chrom_sizes . items ( ) )  def check_dangling_end ( read , dangling_sequences ) :      ds = dangling_sequences if <str> not in ds or <str> not in ds :          return False  if not read . is_reverse and read . seq . upper ( ) . startswith ( ds [ <str> ] ) :          return True  if read . is_reverse and read . seq . upper ( ) . endswith ( ds [ <str> ] ) :          return True  return False  def get_supplementary_alignment ( read , pysam_obj ) :      if read . has_tag ( <str> ) :          other_alignments = read . get_tag ( <str> ) . split ( <str> ) [ 0 : - 1 ] supplementary_alignment = [ ] for i in range ( len ( other_alignments ) ) :              _sup = next ( pysam_obj ) if _sup . qname == read . qname :                  supplementary_alignment . append ( _sup )   return supplementary_alignment  else :          return None   def get_correct_map ( primary , supplement_list ) :      <str> for supplement in supplement_list :          assert primary . qname == supplement . qname , <str> <str> <str> . format ( primary . qname , supplement . qname )  read_list = [ primary ] + supplement_list first_mapped = [ ] for idx , read in enumerate ( read_list ) :          if read . is_reverse :              cigartuples = read . cigartuples [ : : - 1 ]  else :              cigartuples = read . cigartuples [ : ]  match_sum = 0 for op , count in cigartuples :              if op == pysam . CMATCH :                  break  match_sum += count  first_mapped . append ( match_sum )  idx_min = first_mapped . index ( min ( first_mapped ) ) return read_list [ idx_min ]  def enlarge_bins ( bin_intervals , chrom_sizes ) :      <str> chr_start = True chrom_sizes_dict = dict ( chrom_sizes ) for idx in range ( len ( bin_intervals ) - 1 ) :          chrom , start , end = bin_intervals [ idx ] chrom_next , start_next , end_next = bin_intervals [ idx + 1 ] if chr_start is True :              start = 0 chr_start = False  if chrom == chrom_next and end != start_next :              middle = start_next - int ( ( start_next - end ) / 2 ) bin_intervals [ idx ] = ( chrom , start , middle ) bin_intervals [ idx + 1 ] = ( chrom , middle , end_next )  if chrom != chrom_next :              bin_intervals [ idx ] = ( chrom , start , chrom_sizes_dict [ chrom ] ) bin_intervals [ idx + 1 ] = ( chrom_next , 0 , end_next )   chrom , start , end = bin_intervals [ - 1 ] bin_intervals [ - 1 ] = ( chrom , start , chrom_sizes_dict [ chrom ] ) return bin_intervals  def readBamFiles ( pFileOneIterator , pFileTwoIterator , pNumberOfItemsPerBuffer , pSkipDuplicationCheck , pReadPosMatrix , pRefId2name , pMinMappingQuality ) :      buffer_mate1 = [ ] buffer_mate2 = [ ] duplicated_pairs = 0 one_mate_unmapped = 0 one_mate_not_unique = 0 one_mate_low_quality = 0 all_data_read = False j = 0 iter_num = 0 while j < pNumberOfItemsPerBuffer :          try :              mate1 = next ( pFileOneIterator ) mate2 = next ( pFileTwoIterator )  except StopIteration :              all_data_read = True break  iter_num += 1 while mate1 . flag & 256 == 256 :              try :                  mate1 = next ( pFileOneIterator )  except StopIteration :                  all_data_read = True break   while mate2 . flag & 256 == 256 :              try :                  mate2 = next ( pFileTwoIterator )  except StopIteration :                  all_data_read = True break   assert mate1 . qname == mate2 . qname , <str> <str> <str> <str> . format ( mate1 . qname , mate2 . qname ) mate1_supplementary_list = get_supplementary_alignment ( mate1 , pFileOneIterator ) mate2_supplementary_list = get_supplementary_alignment ( mate2 , pFileTwoIterator ) if mate1_supplementary_list :              mate1 = get_correct_map ( mate1 , mate1_supplementary_list )  if mate2_supplementary_list :              mate2 = get_correct_map ( mate2 , mate2_supplementary_list )  if mate1 . flag & 0x4 == 4 or mate2 . flag & 0x4 == 4 :              one_mate_unmapped += 1 continue  if mate1 . mapq < pMinMappingQuality or mate2 . mapq < pMinMappingQuality :              if mate1 . mapq == 0 & mate2 . mapq == 0 :                  one_mate_not_unique += 1 continue  one_mate_low_quality += 1 continue  if pSkipDuplicationCheck is False :              if pReadPosMatrix . is_duplicated ( pRefId2name [ mate1 . rname ] , mate1 . pos , pRefId2name [ mate2 . rname ] , mate2 . pos ) :                  duplicated_pairs += 1 continue   buffer_mate1 . append ( mate1 ) buffer_mate2 . append ( mate2 ) j += 1  if all_data_read and len ( buffer_mate1 ) != 0 and len ( buffer_mate2 ) != 0 :          return buffer_mate1 , buffer_mate2 , True , duplicated_pairs , one_mate_unmapped , one_mate_not_unique , one_mate_low_quality , iter_num - len ( buffer_mate1 )  if all_data_read and len ( buffer_mate1 ) == 0 or len ( buffer_mate2 ) == 0 :          return None , None , True , duplicated_pairs , one_mate_unmapped , one_mate_not_unique , one_mate_low_quality , iter_num - len ( buffer_mate1 )  return buffer_mate1 , buffer_mate2 , False , duplicated_pairs , one_mate_unmapped , one_mate_not_unique , one_mate_low_quality , iter_num - len ( buffer_mate1 )  def process_data ( pMateBuffer1 , pMateBuffer2 , pMinMappingQuality , pKeepSelfCircles , pRestrictionSequence , pRemoveSelfLigation , pMatrixSize , pRfPositions , pRefId2name , pDanglingSequences , pBinsize , pResultIndex , pQueueOut , pTemplate , pOutputBamSet , pCounter , pSharedBinIntvalTree , pDictBinIntervalTreeIndex , pCoverage , pCoverageIndex , pOutputFileBufferDir , pRow , pCol , pData , pMaxInsertSize , pQuickQCMode ) :      one_mate_unmapped = 0 one_mate_low_quality = 0 one_mate_not_unique = 0 dangling_end = 0 self_circle = 0 self_ligation = 0 same_fragment = 0 mate_not_close_to_rf = 0 count_inward = 0 count_outward = 0 count_left = 0 count_right = 0 inter_chromosomal = 0 short_range = 0 long_range = 0 pair_added = 0 iter_num = 0 hic_matrix = None out_bam_index_buffer = [ ] if pMateBuffer1 is None or pMateBuffer2 is None :          pQueueOut . put ( [ hic_matrix , [ one_mate_unmapped , one_mate_low_quality , one_mate_not_unique , dangling_end , self_circle , self_ligation , same_fragment , mate_not_close_to_rf , count_inward , count_outward , count_left , count_right , inter_chromosomal , short_range , long_range , pair_added , iter_num , pResultIndex , out_bam_index_buffer ] ] ) return  while iter_num < len ( pMateBuffer1 ) and iter_num < len ( pMateBuffer2 ) :          mate1 = pMateBuffer1 [ iter_num ] mate2 = pMateBuffer2 [ iter_num ] iter_num += 1 mate_bins = [ ] mate_is_unasigned = False for mate in [ mate1 , mate2 ] :              mate_ref = pRefId2name [ mate . rname ] read_middle = mate . pos + int ( mate . qlen / 2 ) try :                  start , end = pDictBinIntervalTreeIndex [ mate_ref ] middle_pos = int ( ( start + end ) / 2 ) mate_bin = None while not start > end :                      if pSharedBinIntvalTree [ middle_pos ] . begin <= read_middle and read_middle <= pSharedBinIntvalTree [ middle_pos ] . end :                          mate_bin = pSharedBinIntvalTree [ middle_pos ] mate_is_unasigned = False break  elif pSharedBinIntvalTree [ middle_pos ] . begin > read_middle :                          end = middle_pos - 1 middle_pos = int ( ( start + end ) / 2 ) mate_is_unasigned = True  else :                          start = middle_pos + 1 middle_pos = int ( ( start + end ) / 2 ) mate_is_unasigned = True    except KeyError :                  mate_is_unasigned = True break  if mate_bin is None :                  mate_is_unasigned = True break  mate_bin_id = mate_bin . data mate_bins . append ( mate_bin_id )  if mate_is_unasigned is True :              mate_not_close_to_rf += 1 continue  if mate1 . reference_id != mate2 . reference_id :              orientation = <str>  else :              if mate1 . pos < mate2 . pos :                  first_mate = mate1 second_mate = mate2  else :                  first_mate = mate2 second_mate = mate1  if not first_mate . is_reverse and second_mate . is_reverse :                  orientation = <str>  elif first_mate . is_reverse and not second_mate . is_reverse :                  orientation = <str>  elif first_mate . is_reverse and second_mate . is_reverse :                  orientation = <str>  else :                  orientation = <str>  if abs ( mate2 . pos - mate1 . pos ) < 25000 and orientation == <str> :                  if pRfPositions and pRestrictionSequence :                      frag_start = min ( mate1 . pos , mate2 . pos ) + len ( pRestrictionSequence ) frag_end = max ( mate1 . pos + mate1 . qlen , mate2 . pos + mate2 . qlen ) - len ( pRestrictionSequence ) mate_ref = pRefId2name [ mate1 . rname ] has_rf = sorted ( pRfPositions [ mate_ref ] [ frag_start : frag_end ] ) if len ( has_rf ) == 0 :                          self_circle += 1 if not pKeepSelfCircles :                              continue     if abs ( mate2 . pos - mate1 . pos ) < pMaxInsertSize and orientation == <str> :                  if pRestrictionSequence :                      if pDanglingSequences :                          if check_dangling_end ( mate1 , pDanglingSequences ) or check_dangling_end ( mate2 , pDanglingSequences ) :                              dangling_end += 1 continue    has_rf = [ ] if pRfPositions and pRestrictionSequence :                      frag_start = min ( mate1 . pos , mate2 . pos ) + len ( pRestrictionSequence ) frag_end = max ( mate1 . pos + mate1 . qlen , mate2 . pos + mate2 . qlen ) - len ( pRestrictionSequence ) mate_ref = pRefId2name [ mate1 . rname ] has_rf = sorted ( pRfPositions [ mate_ref ] [ frag_start : frag_end ] )  if len ( has_rf ) == 0 :                      same_fragment += 1 continue  self_ligation += 1 if pRemoveSelfLigation :                      continue   mate1 . isize = mate2 . pos - mate1 . pos mate2 . isize = mate1 . pos - mate2 . pos  if len ( mate_bins ) != 2 :              continue  if mate1 . reference_id != mate2 . reference_id :              inter_chromosomal += 1  elif abs ( mate2 . pos - mate1 . pos ) < 20000 :              short_range += 1  else :              long_range += 1  if orientation == <str> :              count_inward += 1  elif orientation == <str> :              count_outward += 1  elif orientation == <str> :              count_left += 1  elif orientation == <str> :              count_right += 1  for mate in [ mate1 , mate2 ] :              vec_start = int ( max ( 0 , mate . pos - mate_bin . begin ) / pBinsize ) length_coverage = pCoverageIndex [ mate_bin_id ] . end - pCoverageIndex [ mate_bin_id ] . begin vec_end = min ( length_coverage , int ( vec_start + len ( mate . seq ) / pBinsize ) ) coverage_index = pCoverageIndex [ mate_bin_id ] . begin + vec_start coverage_end = pCoverageIndex [ mate_bin_id ] . begin + vec_end for i in range ( coverage_index , coverage_end , 1 ) :                  pCoverage [ i ] += 1   if not pQuickQCMode :              pRow [ pair_added ] = mate_bins [ 0 ] pCol [ pair_added ] = mate_bins [ 1 ] pData [ pair_added ] = np . uint8 ( 1 )  pair_added += 1 if pOutputBamSet :              out_bam_index_buffer . append ( iter_num - 1 )   pQueueOut . put ( [ [ one_mate_unmapped , one_mate_low_quality , one_mate_not_unique , dangling_end , self_circle , self_ligation , same_fragment , mate_not_close_to_rf , count_inward , count_outward , count_left , count_right , inter_chromosomal , short_range , long_range , pair_added , len ( pMateBuffer1 ) , pResultIndex , pCounter , out_bam_index_buffer ] ] ) return  def main ( args = None ) :      args = parse_arguments ( ) . parse_args ( args ) if args . maxDistance is not None :          args . maxLibraryInsertSize = args . maxDistance  try :          QC . make_sure_path_exists ( args . QCfolder )  except OSError :          exit ( <str> . format ( args . QCfolder ) )  if args . threads < 2 :          args . threads = 2 warnings . warn ( <str> )  if args . danglingSequence and not args . restrictionSequence :          exit ( <str> )  log . info ( <str> . format ( args . samFiles [ 0 ] . name , args . samFiles [ 1 ] . name ) ) str1 = pysam . Samfile ( args . samFiles [ 0 ] . name , <str> ) str2 = pysam . Samfile ( args . samFiles [ 1 ] . name , <str> ) args . samFiles [ 0 ] . close ( ) args . samFiles [ 1 ] . close ( ) if not args . doTestRun :          if args . outBam :              args . outBam . close ( ) out_bam_file = pysam . Samfile ( args . outBam . name , <str> , template = str1 )   chrom_sizes = get_chrom_sizes ( str1 ) read_pos_matrix = ReadPositionMatrix ( ) rf_positions = None if args . restrictionCutFile :          rf_interval = bed2interval_list ( args . restrictionCutFile ) bin_intervals = get_rf_bins ( rf_interval , min_distance = args . minDistance , max_distance = args . maxLibraryInsertSize ) rf_positions = intervalListToIntervalTree ( rf_interval )  else :          bin_intervals = get_bins ( args . binSize [ 0 ] , chrom_sizes , args . region )  matrix_size = len ( bin_intervals ) bin_intval_tree = intervalListToIntervalTree ( bin_intervals ) ref_id2name = str1 . references shared_array_list = [ ] index_dict = { } end = - 1 for i , seq in enumerate ( bin_intval_tree ) :          start = end + 1 interval_list = [ ] for interval in bin_intval_tree [ seq ] :              interval_list . append ( ( interval . begin , interval . end , interval . data ) )  end = start + len ( bin_intval_tree [ seq ] ) - 1 index_dict [ seq ] = ( start , end ) interval_list = sorted ( interval_list ) shared_array_list . extend ( interval_list )  shared_build_intval_tree = RawArray ( C_Interval , shared_array_list ) bin_intval_tree = None dangling_sequences = dict ( ) if args . danglingSequence :          args . restrictionSequence = args . restrictionSequence . upper ( ) args . danglingSequence = args . danglingSequence . upper ( ) dangling_sequences [ <str> ] = args . danglingSequence dangling_sequences [ <str> ] = str ( Seq ( args . danglingSequence , generic_dna ) . reverse_complement ( ) ) log . info ( <str> <str> . format ( dangling_sequences ) )  binsize = 10 number_of_elements_coverage = 0 start_pos_coverage = [ ] end_pos_coverage = [ ] for chrom , start , end in bin_intervals :          start_pos_coverage . append ( number_of_elements_coverage ) number_of_elements_coverage += ( end - start ) // binsize end_pos_coverage . append ( number_of_elements_coverage - 1 )  pos_coverage = RawArray ( C_Coverage , list ( zip ( start_pos_coverage , end_pos_coverage ) ) ) start_pos_coverage = None end_pos_coverage = None coverage = Array ( c_uint , [ 0 ] * number_of_elements_coverage ) args . threads = args . threads - 1 row = [ None ] * args . threads col = [ None ] * args . threads data = [ None ] * args . threads for i in range ( args . threads ) :          row [ i ] = RawArray ( c_uint , args . inputBufferSize ) col [ i ] = RawArray ( c_uint , args . inputBufferSize ) data [ i ] = RawArray ( c_ushort , args . inputBufferSize )  start_time = time . time ( ) iter_num = 0 one_mate_unmapped = 0 one_mate_low_quality = 0 one_mate_not_unique = 0 dangling_end = 0 self_circle = 0 self_ligation = 0 same_fragment = 0 mate_not_close_to_rf = 0 duplicated_pairs = 0 count_inward = 0 count_outward = 0 count_left = 0 count_right = 0 inter_chromosomal = 0 short_range = 0 long_range = 0 pair_added = 0 buffer_workers1 = [ None ] * args . threads buffer_workers2 = [ None ] * args . threads process = [ None ] * args . threads all_data_processed = False hic_matrix = coo_matrix ( ( matrix_size , matrix_size ) , dtype = <str> ) queue = [ None ] * args . threads all_threads_done = False thread_done = [ False ] * args . threads count_output = 0 count_call_of_read_input = 0 computed_pairs = 0 if args . doTestRun :          args . inputBufferSize = args . doTestRunLines  while not all_data_processed or not all_threads_done :          for i in range ( args . threads ) :              if queue [ i ] is None and not all_data_processed :                  count_call_of_read_input += 1 buffer_workers1 [ i ] , buffer_workers2 [ i ] , all_data_processed , duplicated_pairs_ , one_mate_unmapped_ , one_mate_not_unique_ , one_mate_low_quality_ , iter_num_ = readBamFiles ( pFileOneIterator = str1 , pFileTwoIterator = str2 , pNumberOfItemsPerBuffer = args . inputBufferSize , pSkipDuplicationCheck = args . skipDuplicationCheck , pReadPosMatrix = read_pos_matrix , pRefId2name = ref_id2name , pMinMappingQuality = args . minMappingQuality ) duplicated_pairs += duplicated_pairs_ one_mate_unmapped += one_mate_unmapped_ one_mate_not_unique += one_mate_not_unique_ one_mate_low_quality += one_mate_low_quality_ iter_num += iter_num_ queue [ i ] = Queue ( ) thread_done [ i ] = False computed_pairs += len ( buffer_workers1 [ i ] ) process [ i ] = Process ( target = process_data , kwargs = dict ( pMateBuffer1 = buffer_workers1 [ i ] , pMateBuffer2 = buffer_workers2 [ i ] , pMinMappingQuality = args . minMappingQuality , pKeepSelfCircles = args . keepSelfCircles , pRestrictionSequence = args . restrictionSequence , pRemoveSelfLigation = args . removeSelfLigation , pMatrixSize = matrix_size , pRfPositions = rf_positions , pRefId2name = ref_id2name , pDanglingSequences = dangling_sequences , pBinsize = binsize , pResultIndex = i , pQueueOut = queue [ i ] , pTemplate = str1 , pOutputBamSet = args . outBam , pCounter = count_output , pSharedBinIntvalTree = shared_build_intval_tree , pDictBinIntervalTreeIndex = index_dict , pCoverage = coverage , pCoverageIndex = pos_coverage , pOutputFileBufferDir = <str> , pRow = row [ i ] , pCol = col [ i ] , pData = data [ i ] , pMaxInsertSize = args . maxLibraryInsertSize , pQuickQCMode = args . doTestRun ) ) process [ i ] . start ( ) count_output += 1  elif queue [ i ] is not None and not queue [ i ] . empty ( ) :                  result = queue [ i ] . get ( ) if result [ 0 ] is not None :                      elements = result [ 0 ] [ 15 ] if hic_matrix is None :                          hic_matrix = coo_matrix ( ( data [ i ] [ : elements ] , ( row [ i ] [ : elements ] , col [ i ] [ : elements ] ) ) , shape = ( matrix_size , matrix_size ) )  else :                          hic_matrix += coo_matrix ( ( data [ i ] [ : elements ] , ( row [ i ] [ : elements ] , col [ i ] [ : elements ] ) ) , shape = ( matrix_size , matrix_size ) )  dangling_end += result [ 0 ] [ 3 ] self_circle += result [ 0 ] [ 4 ] self_ligation += result [ 0 ] [ 5 ] same_fragment += result [ 0 ] [ 6 ] mate_not_close_to_rf += result [ 0 ] [ 7 ] count_inward += result [ 0 ] [ 8 ] count_outward += result [ 0 ] [ 9 ] count_left += result [ 0 ] [ 10 ] count_right += result [ 0 ] [ 11 ] inter_chromosomal += result [ 0 ] [ 12 ] short_range += result [ 0 ] [ 13 ] long_range += result [ 0 ] [ 14 ] pair_added += result [ 0 ] [ 15 ] iter_num += result [ 0 ] [ 16 ]  for bam_index in result [ 0 ] [ 19 ] :                      mate1 = buffer_workers1 [ i ] [ bam_index ] mate2 = buffer_workers2 [ i ] [ bam_index ] mate1 . flag |= 0x1 mate2 . flag |= 0x1 mate1 . flag |= 0x40 mate2 . flag |= 0x80 mate1 . mrnm = mate2 . rname mate2 . mrnm = mate1 . rname mate1 . mpos = mate2 . pos mate2 . mpos = mate1 . pos out_bam_file . write ( mate1 ) out_bam_file . write ( mate2 )  buffer_workers1 [ i ] = None buffer_workers2 [ i ] = None queue [ i ] = None process [ i ] . join ( ) process [ i ] . terminate ( ) process [ i ] = None thread_done [ i ] = True if iter_num % 1e6 < 100000 :                      elapsed_time = time . time ( ) - start_time log . info ( <str> <str> <str> . format ( iter_num , elapsed_time , iter_num / elapsed_time ) ) log . info ( <str> <str> . format ( pair_added , float ( 100 * pair_added ) / iter_num ) )  if args . doTestRun and iter_num > args . doTestRunLines :                      log . debug ( <str> ) all_data_processed = True thread_done [ i ] = True break   elif all_data_processed and queue [ i ] is None :                  thread_done [ i ] = True  else :                  time . sleep ( 1 )   if all_data_processed :              all_threads_done = True for thread in thread_done :                  if not thread :                      all_threads_done = False     if not args . doTestRun :          if args . outBam :              out_bam_file . close ( )  dia = dia_matrix ( ( [ hic_matrix . diagonal ( ) ] , [ 0 ] ) , shape = hic_matrix . shape ) hic_matrix = hic_matrix + hic_matrix . T - dia bin_intervals = enlarge_bins ( bin_intervals [ : ] , chrom_sizes ) bin_max = [ ] for cover in pos_coverage :              max_element = 0 for i in range ( cover . begin , cover . end , 1 ) :                  if coverage [ i ] > max_element :                      max_element = coverage [ i ]   if max_element == 0 :                  bin_max . append ( np . nan )  else :                  bin_max . append ( max_element )   chr_name_list , start_list , end_list = list ( zip ( * bin_intervals ) ) bin_intervals = list ( zip ( chr_name_list , start_list , end_list , bin_max ) ) hic_ma = hm . hiCMatrix ( ) hic_ma . setMatrix ( hic_matrix , cut_intervals = bin_intervals )  if args . removeSelfLigation :          msg = <str>  else :          msg = <str>  mappable_unique_high_quality_pairs = iter_num - ( one_mate_unmapped + one_mate_low_quality + one_mate_not_unique ) intermediate_qc_log = StringIO ( ) intermediate_qc_log . write ( . format ( args . outFileName . name , iter_num , args . minDistance , args . maxLibraryInsertSize ) ) intermediate_qc_log . write ( <str> ) intermediate_qc_log . write ( <str> . format ( mappable_unique_high_quality_pairs , 100 * float ( mappable_unique_high_quality_pairs ) / iter_num ) ) intermediate_qc_log . write ( <str> . format ( pair_added , 100 * float ( pair_added ) / iter_num ) ) intermediate_qc_log . write ( <str> . format ( one_mate_unmapped , 100 * float ( one_mate_unmapped ) / iter_num ) ) intermediate_qc_log . write ( <str> . format ( one_mate_not_unique , 100 * float ( one_mate_not_unique ) / iter_num ) ) intermediate_qc_log . write ( <str> . format ( one_mate_low_quality , 100 * float ( one_mate_low_quality ) / iter_num ) ) intermediate_qc_log . write ( <str> ) intermediate_qc_log . write ( <str> . format ( dangling_end , 100 * float ( dangling_end ) / mappable_unique_high_quality_pairs ) ) intermediate_qc_log . write ( <str> . format ( msg , self_ligation , 100 * float ( self_ligation ) / mappable_unique_high_quality_pairs ) ) intermediate_qc_log . write ( <str> . format ( mate_not_close_to_rf , 100 * float ( mate_not_close_to_rf ) / mappable_unique_high_quality_pairs ) ) intermediate_qc_log . write ( <str> . format ( same_fragment , 100 * float ( same_fragment ) / mappable_unique_high_quality_pairs ) ) intermediate_qc_log . write ( <str> . format ( self_circle , 100 * float ( self_circle ) / mappable_unique_high_quality_pairs ) ) intermediate_qc_log . write ( <str> . format ( duplicated_pairs , 100 * float ( duplicated_pairs ) / mappable_unique_high_quality_pairs ) ) if pair_added > 0 :          intermediate_qc_log . write ( <str> ) intermediate_qc_log . write ( <str> . format ( inter_chromosomal , 100 * float ( inter_chromosomal ) / pair_added ) ) intermediate_qc_log . write ( <str> . format ( short_range , 100 * float ( short_range ) / pair_added ) ) intermediate_qc_log . write ( <str> . format ( long_range , 100 * float ( long_range ) / pair_added ) ) intermediate_qc_log . write ( <str> . format ( count_inward , 100 * float ( count_inward ) / pair_added ) ) intermediate_qc_log . write ( <str> . format ( count_outward , 100 * float ( count_outward ) / pair_added ) ) intermediate_qc_log . write ( <str> . format ( count_left , 100 * float ( count_left ) / pair_added ) ) intermediate_qc_log . write ( <str> . format ( count_right , 100 * float ( count_right ) / pair_added ) )  log_file_name = os . path . join ( args . QCfolder , <str> ) log_file = open ( log_file_name , <str> ) log_file . write ( intermediate_qc_log . getvalue ( ) ) log_file . close ( ) QC . main ( <str> . format ( log_file_name , args . QCfolder ) . split ( ) ) args . outFileName . close ( ) unlink ( args . outFileName . name ) hic_metadata = { } hic_metadata [ <str> ] = intermediate_qc_log . getvalue ( ) hic_metadata [ <str> ] = np . string_ ( <str> + __version__ ) hic_metadata [ <str> ] = np . string_ ( <str> ) if args . genomeAssembly :          hic_metadata [ <str> ] = np . string_ ( args . genomeAssembly )  intermediate_qc_log . close ( ) if args . outFileName . name . endswith ( <str> ) and args . binSize is not None and len ( args . binSize ) > 2 :          matrixFileHandlerOutput = MatrixFileHandler ( pFileType = <str> , pHiCInfo = hic_metadata ) matrixFileHandlerOutput . set_matrix_variables ( hic_ma . matrix , hic_ma . cut_intervals , hic_ma . nan_bins , hic_ma . correction_factors , hic_ma . distance_counts ) matrixFileHandlerOutput . save ( args . outFileName . name + <str> + str ( args . binSize [ 0 ] ) , pSymmetric = True , pApplyCorrection = False ) for resolution in args . binSize [ 1 : ] :              hic_matrix_to_merge = deepcopy ( hic_ma ) _mergeFactor = int ( resolution ) // args . binSize [ 0 ] merged_matrix = hicMergeMatrixBins . merge_bins ( hic_matrix_to_merge , _mergeFactor ) matrixFileHandlerOutput = MatrixFileHandler ( pFileType = <str> , pAppend = True , pHiCInfo = hic_metadata ) matrixFileHandlerOutput . set_matrix_variables ( merged_matrix . matrix , merged_matrix . cut_intervals , merged_matrix . nan_bins , merged_matrix . correction_factors , merged_matrix . distance_counts ) matrixFileHandlerOutput . save ( args . outFileName . name + <str> + str ( resolution ) , pSymmetric = True , pApplyCorrection = False )   else :          if not args . doTestRun :              hic_ma . save ( args . outFileName . name , pHiCInfo = hic_metadata )    class Tester ( object ) :      def __init__ ( self ) :          hic_test_data_dir = os . environ . get ( <str> , False ) if hic_test_data_dir :              self . root = hic_test_data_dir  else :              self . root = os . path . dirname ( os . path . abspath ( __file__ ) ) + <str>  self . bam_file_1 = os . path . join ( self . root , <str> )    