from jaratoolbox import loadbehavior from jaratoolbox import loadopenephys from jaratoolbox import spikesanalysis import numpy as np from pylab import * import os SAMPLING_RATE = 30000.0 timeRange = [ - 0.5 , 1 ] ephysRoot = <str> ephysSession = <str> ephysDir = os . path . join ( ephysRoot , ephysSession ) event_filename = os . path . join ( ephysDir , <str> ) tetrodeID = 1 numTetrodes = 8 behaviorDir = <str> behavDataFileName = os . path . join ( behaviorDir , <str> ) bdata = loadbehavior . BehaviorData ( behavDataFileName , readmode = <str> ) freqEachTrial = bdata [ <str> ] possibleFreq = np . unique ( freqEachTrial ) numberOfTrials = len ( freqEachTrial ) sortedTrials = [ ] numTrialsEachFreq = [ ] for indf , oneFreq in enumerate ( possibleFreq ) :      indsThisFreq = np . flatnonzero ( freqEachTrial == oneFreq ) sortedTrials = np . concatenate ( ( sortedTrials , indsThisFreq ) ) numTrialsEachFreq . append ( len ( indsThisFreq ) )  sortingInds = argsort ( sortedTrials ) ev = loadopenephys . Events ( event_filename ) eventTimes = np . array ( ev . timestamps ) / SAMPLING_RATE evID = np . array ( ev . eventID ) eventOnsetTimes = eventTimes [ evID == 1 ] while ( numberOfTrials < len ( eventOnsetTimes ) ) :      eventOnsetTimes = eventOnsetTimes [ : - 1 ]  spike_filename = os . path . join ( ephysDir , <str> . format ( tetrodeID ) ) sp = loadopenephys . DataSpikes ( spike_filename ) spkTimeStamps = np . array ( sp . timestamps ) / SAMPLING_RATE ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spkTimeStamps , eventOnsetTimes , timeRange ) sortedIndexForEachSpike = sortingInds [ trialIndexForEachSpike ] responseRange = [ 0.010 , 0.020 ] nSpikes = spikesanalysis . count_spikes_in_range ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) meanSpikesEachFrequency = np . empty ( len ( possibleFreq ) ) trialsEachFreq = [ ] for indf , oneFreq in enumerate ( possibleFreq ) :      trialsEachFreq . append ( np . flatnonzero ( freqEachTrial == oneFreq ) )  for indf , oneFreq in enumerate ( possibleFreq ) :      meanSpikesEachFrequency [ indf ] = np . mean ( nSpikes [ trialsEachFreq [ indf ] ] )  clf ( ) ax2 = plt . subplot2grid ( ( 1 , 4 ) , ( 0 , 0 ) , colspan = 3 ) plot ( spikeTimesFromEventOnset , sortedIndexForEachSpike , <str> , ms = 1 ) axvline ( x = 0 , ymin = 0 , ymax = 1 , color = <str> ) numTrials = cumsum ( numTrialsEachFreq ) for indf , num in enumerate ( numTrials ) :      ax2 . axhline ( y = num , xmin = 0 , xmax = 1 , color = <str> , zorder = 0 )  tickPositions = numTrials - mean ( numTrialsEachFreq ) / 2 tickLabels = [ <str> % ( possibleFreq [ indf ] / 1000 ) for indf in range ( len ( possibleFreq ) ) ] ax2 . set_yticks ( tickPositions ) ax2 . set_yticklabels ( tickLabels ) ylabel ( <str> . format ( numTrials [ - 1 ] ) ) title ( ephysDir + <str> . format ( tetrodeID ) ) xlabel ( <str> ) ax2 = plt . subplot2grid ( ( 1 , 4 ) , ( 0 , 3 ) , colspan = 1 ) ax2 . set_xscale ( <str> ) plot ( possibleFreq , meanSpikesEachFrequency , <str> ) ylabel ( <str> . format ( * responseRange ) ) xlabel ( <str> ) show ( )  