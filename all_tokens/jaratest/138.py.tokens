from jaratoolbox import settings from jaratoolbox import spikesorting from jaratoolbox import loadopenephys from jaratoolbox import spikesanalysis from jaratoolbox import spikesorting from pylab import * import numpy as np reload ( spikesorting ) import os class MultipleSessionsToCluster ( spikesorting . TetrodeToCluster ) :      def __init__ ( self , animalName , sessionList , tetrode , analysisDate ) :          self . animalName = animalName self . sessionList = sessionList self . SAMPLING_RATE = 30000.0 self . tetrode = tetrode self . dataTT = None self . recordingNumber = np . array ( [ ] ) self . samples = None self . timestamps = None self . clusters = None self . nSpikes = None self . analysisDate = analysisDate self . clustersDir = os . path . join ( settings . EPHYS_PATH , self . animalName , <str> . format ( self . analysisDate ) ) self . fetFilename = os . path . join ( self . clustersDir , <str> % self . tetrode ) self . report = None self . reportFileName = <str> . format ( self . tetrode ) self . featureNames = [ <str> , <str> , <str> ] self . nFeatures = len ( self . featureNames ) self . featureValues = None self . process = None  def load_all_waveforms ( self ) :          for ind , session in enumerate ( self . sessionList ) :              if session :                  ephysDir = os . path . join ( settings . EPHYS_PATH , self . animalName , session ) spikeFile = os . path . join ( ephysDir , <str> . format ( self . tetrode ) ) dataSpkObj = loadopenephys . DataSpikes ( spikeFile ) numSpikes = dataSpkObj . nRecords sessionVector = np . zeros ( numSpikes ) + ind samplesThisSession = dataSpkObj . samples . astype ( float ) - 2 ** 15 samplesThisSession = ( 1000.0 / dataSpkObj . gain [ 0 , 0 ] ) * samplesThisSession timestampsThisSession = dataSpkObj . timestamps / self . SAMPLING_RATE if ind == 0 :                      self . samples = samplesThisSession self . timestamps = timestampsThisSession self . recordingNumber = sessionVector  else :                      self . samples = np . concatenate ( [ self . samples , samplesThisSession ] ) self . timestamps = np . concatenate ( [ self . timestamps , timestampsThisSession ] ) self . recordingNumber = np . concatenate ( [ self . recordingNumber , sessionVector ] )    self . nSpikes = len ( self . timestamps )  def create_multisession_fet_files ( self ) :          if not os . path . exists ( self . clustersDir ) :              print <str> % ( self . clustersDir ) os . makedirs ( self . clustersDir )  if self . samples is None :              self . load_waveforms ( )  self . featureValues = spikesorting . calculate_features ( self . samples , self . featureNames ) spikesorting . write_fet_file ( self . fetFilename , self . featureValues )  def set_clusters_from_file ( self ) :          clusterFile = os . path . join ( self . clustersDir , <str> % self . tetrode ) self . clusters = np . fromfile ( clusterFile , dtype = <str> , sep = <str> ) [ 1 : ]  def save_single_session_clu_files ( self , copyClusterReport = True ) :          clusters = self . clusters recordingNumber = self . recordingNumber sessions = self . sessionList for indSession , session in enumerate ( self . sessionList ) :              sessionClusterDir = os . path . join ( settings . EPHYS_PATH , self . animalName , session + <str> ) if not os . path . exists ( sessionClusterDir ) :                  print <str> % ( sessionClusterDir ) os . makedirs ( sessionClusterDir )  sessionClusterFile = os . path . join ( sessionClusterDir , <str> . format ( self . tetrode ) ) fid = open ( sessionClusterFile , <str> ) fid . write ( <str> . format ( <str> ) ) clusterNumsThisSession = self . clusters [ self . recordingNumber == indSession ] print <str> . format ( session ) for cn in clusterNumsThisSession :                  fid . write ( <str> . format ( cn ) )  fid . close ( ) if copyClusterReport :                  pass    def save_multisession_report ( self ) :          if self . clusters == None :              self . set_clusters_from_file ( )  figTitle = <str> . format ( self . tetrode ) self . report = MultiSessionClusterReport ( self . samples , self . timestamps , self . clusters , outputDir = self . clustersDir , filename = self . reportFileName , figtitle = figTitle , showfig = False )   class MultiSessionClusterReport ( object ) :      def __init__ ( self , samples , timestamps , clusters , outputDir = None , filename = None , showfig = True , figtitle = <str> , nrows = 12 ) :          self . timestamps = timestamps self . samples = samples self . nSpikes = len ( self . timestamps ) self . clusters = clusters self . clustersList = np . unique ( self . clusters ) self . nClusters = len ( self . clustersList ) self . nRows = nrows self . nPages = self . nClusters // ( self . nRows + 1 ) + 1 self . spikesEachCluster = [ ] self . find_spikes_each_cluster ( ) self . fig = None self . nPages = 0 self . figTitle = figtitle self . plot_report ( showfig = showfig ) if outputDir is not None :              self . save_report ( outputDir , filename )   def __str__ ( self ) :          return <str> % ( self . nClusters )  def find_spikes_each_cluster ( self ) :          self . spikesEachCluster = np . empty ( ( self . nClusters , self . nSpikes ) , dtype = bool ) for indc , clusterID in enumerate ( self . clustersList ) :              self . spikesEachCluster [ indc , : ] = ( self . clusters == clusterID )   def plot_report ( self , showfig = False ) :          print <str> self . fig = plt . gcf ( ) self . fig . clf ( ) self . fig . set_facecolor ( <str> ) nCols = 3 nRows = self . nRows for indc , clusterID in enumerate ( self . clustersList ) :              if ( indc + 1 ) > self . nRows :                  print <str> continue  tsThisCluster = self . timestamps [ self . spikesEachCluster [ indc , : ] ] wavesThisCluster = self . samples [ self . spikesEachCluster [ indc , : ] , : , : ] plt . subplot ( self . nRows , nCols , indc * nCols + 1 ) spikesorting . plot_isi_loghist ( tsThisCluster ) if indc < ( self . nClusters - 1 ) :                  plt . xlabel ( <str> ) plt . gca ( ) . set_xticklabels ( <str> )  plt . ylabel ( <str> % clusterID , rotation = 0 , va = <str> , ha = <str> ) plt . subplot ( 2 * self . nRows , nCols , 2 * ( indc * nCols ) + 6 ) spikesorting . plot_events_in_time ( tsThisCluster ) if indc < ( self . nClusters - 1 ) :                  plt . xlabel ( <str> ) plt . gca ( ) . set_xticklabels ( <str> )  plt . subplot ( 2 * self . nRows , nCols , 2 * ( indc * nCols ) + 3 ) spikesorting . plot_projections ( wavesThisCluster ) plt . subplot ( self . nRows , nCols , indc * nCols + 2 ) spikesorting . plot_waveforms ( wavesThisCluster )  plt . figtext ( 0.5 , 0.92 , self . figTitle , ha = <str> , fontweight = <str> , fontsize = 10 ) if showfig :              plt . show ( )   def get_title ( self ) :          return <str>  def get_default_filename ( self , figformat ) :          return <str> % ( figformat )  def save_report ( self , outputdir , filename = None , figformat = None ) :          if not os . path . exists ( outputdir ) :              print <str> % ( outputdir ) os . makedirs ( outputdir )  self . fig . set_size_inches ( ( 8.5 , 11 ) ) if figformat is None :              figformat = <str>  if filename is None :              filename = self . get_default_filename ( figformat )  fullFileName = os . path . join ( outputdir , filename ) print <str> % fullFileName self . fig . savefig ( fullFileName , format = figformat )   if __name__ == <str> :      from jaratoolbox . test . nick . ephysExperiments import ephys_experiment as ee reload ( ee ) animalName = <str> sessionList = [ <str> , <str> , <str> , <str> , <str> ] tetrode = 6 oneTT = MultipleSessionsToCluster ( animalName , sessionList , tetrode , <str> ) oneTT . load_all_waveforms ( ) clusterFile = os . path . join ( oneTT . clustersDir , <str> % oneTT . tetrode ) if os . path . isfile ( clusterFile ) :          oneTT . set_clusters_from_file ( )  else :          oneTT . create_multisession_fet_files ( ) oneTT . run_clustering ( ) oneTT . set_clusters_from_file ( )  oneTT . save_multisession_report ( ) oneTT . save_single_session_clu_files ( ) figure ( ) cluster = 3 clusterSpikeTimestamps = oneTT . timestamps [ ( oneTT . clusters == cluster ) & ( oneTT . recordingNumber == 0 ) ] exp = ee . EphysExperiment ( <str> , <str> ) spikeData , eventData , plotTitle = exp . get_session_ephys_data ( sessionList [ 2 ] , 6 ) eventOnsetTimes = exp . get_event_onset_times ( eventData ) exp . plot_raster ( clusterSpikeTimestamps , eventOnsetTimes , <str> )   