import matplotlib . pyplot as plt from jaratoolbox import settings from jaratoolbox import loadopenephys from jaratoolbox import extraplots import numpy as np import os , glob import subprocess import time __author__ = <str> __version__ = <str> SAMPLES_PER_SPIKE = 40 N_CHANNELS = 4 NUMCLUSTERS = 12 class SessionToCluster ( object ) :      def __init__ ( self , animalName , ephysSession , tetrodes , serverUser = None , serverName = None , serverPath = None ) :          self . animalName = animalName self . ephysSession = ephysSession self . tetrodes = tetrodes self . serverUser = serverUser self . serverName = serverName self . serverPath = serverPath self . localAnimalPath = os . path . join ( settings . EPHYS_PATH , animalName ) self . localSessionPath = os . path . join ( self . localAnimalPath , ephysSession ) self . client = None  def transfer_data_to_server ( self ) :          destPath = os . path . join ( self . serverPath , self . animalName ) remotePath = <str> % ( self . serverUser , self . serverName , destPath ) transferCommand = [ <str> , <str> , <str> , self . localSessionPath , remotePath ] print <str> . join ( transferCommand ) subprocess . call ( transferCommand )  def run_clustering_remotely ( self ) :          self . client = paramiko . SSHClient ( ) self . client . load_system_host_keys ( ) self . client . connect ( self . serverName , 22 , self . serverUser ) commandFormat = <str> for oneTetrode in self . tetrodes :              commandStr = commandFormat % ( self . animalName , self . ephysSession , oneTetrode ) print <str> % oneTetrode ( stdin , stdout , stderr ) = self . client . exec_command ( commandStr ) print <str>  self . client . close ( )  def delete_fet_files ( self ) :          kkResultsPathRemote = os . path . join ( self . serverPath , self . animalName , self . ephysSession ) + <str> commandStr = <str> % kkResultsPathRemote print <str> print commandStr self . client = paramiko . SSHClient ( ) self . client . load_system_host_keys ( ) self . client . connect ( self . serverName , 22 , self . serverUser ) ( stdin , stdout , stderr ) = self . client . exec_command ( commandStr ) print <str>  def transfer_results_back ( self ) :          destPath = os . path . join ( self . serverPath , self . animalName ) remotePath = <str> % ( self . serverUser , self . serverName , destPath ) remotePathResults = os . path . join ( remotePath , self . ephysSession + <str> ) remotePathReports = os . path . join ( remotePath , self . ephysSession + <str> ) transferCommandResults = [ <str> , <str> , <str> , <str> , <str> , remotePathResults , self . localAnimalPath ] transferCommandReports = [ <str> , <str> , <str> , remotePathReports , self . localAnimalPath ] print <str> . join ( transferCommandResults ) subprocess . call ( transferCommandResults ) print <str> . join ( transferCommandReports ) subprocess . call ( transferCommandReports )  def consolidate_reports ( self ) :          reportsDir = os . path . join ( self . localAnimalPath , <str> ) thisSessionReportsDir = self . localSessionPath + <str> if not os . path . exists ( reportsDir ) :              print <str> % ( reportsDir ) os . makedirs ( reportsDir )  commandList = [ <str> , <str> , thisSessionReportsDir + <str> , reportsDir ] commandStr = <str> . join ( commandList ) print <str> print commandStr subprocess . call ( commandStr , shell = True ) print <str>   class TetrodeToCluster ( object ) :      def __init__ ( self , animalName , ephysSession , tetrode , features = None ) :          self . animalName = animalName self . ephysSession = ephysSession self . tetrode = tetrode self . dataTT = None self . nSpikes = None self . dataDir = os . path . join ( settings . EPHYS_PATH , self . animalName , self . ephysSession ) self . clustersDir = os . path . join ( settings . EPHYS_PATH , self . animalName , self . ephysSession + <str> ) self . reportDir = os . path . join ( settings . EPHYS_PATH , self . animalName , <str> ) self . tetrodeFile = os . path . join ( self . dataDir , <str> . format ( tetrode ) ) self . fetFilename = os . path . join ( self . clustersDir , <str> . format ( tetrode ) ) self . reportFileName = <str> . format ( self . animalName , ephysSession , tetrode ) self . report = None if features is None :              self . featureNames = [ <str> , <str> , <str> ]  else :              self . featureNames = features  self . nFeatures = len ( self . featureNames ) self . featureValues = None self . process = None  def load_waveforms ( self ) :          print <str> self . dataTT = loadopenephys . DataSpikes ( self . tetrodeFile ) self . nSpikes = self . dataTT . nRecords self . dataTT . samples = self . dataTT . samples . astype ( float ) - 2 ** 15 self . dataTT . samples = ( 1000.0 / self . dataTT . gain [ 0 , 0 ] ) * self . dataTT . samples self . dataTT . timestamps = self . dataTT . timestamps / self . dataTT . samplingRate  def create_fet_files ( self ) :          if not os . path . exists ( self . clustersDir ) :              print <str> % ( self . clustersDir ) os . makedirs ( self . clustersDir )  if self . dataTT is None :              self . load_waveforms ( )  self . featureValues = calculate_features ( self . dataTT . samples , self . featureNames ) write_fet_file ( self . fetFilename , self . featureValues )  def run_clustering ( self ) :          maxNumberOfEventsToUse = 1e5 Subset = np . floor ( self . nSpikes / min ( self . nSpikes , maxNumberOfEventsToUse ) ) MinClusters = 10 MaxClusters = 12 MaxPossibleClusters = 12 UseFeatures = ( self . nFeatures * N_CHANNELS ) * <str> KKtetrode = <str> % ( self . tetrode ) KKsuffix = <str> KKpath = settings . KK_PATH KKcommandAndParams = [ KKpath , KKtetrode , KKsuffix , <str> , <str> % Subset , <str> , <str> % MinClusters , <str> , <str> % MaxClusters , <str> , <str> % MaxPossibleClusters , <str> , UseFeatures ] print <str> . join ( KKcommandAndParams ) returnCode = subprocess . call ( KKcommandAndParams , cwd = self . clustersDir ) if returnCode :              print <str>   def save_report ( self ) :          if self . dataTT is None :              self . load_waveforms ( )  self . dataTT . set_clusters ( os . path . join ( self . clustersDir , <str> % self . tetrode ) ) figTitle = self . dataDir + <str> % self . tetrode self . report = ClusterReportFromData ( self . dataTT , outputDir = self . reportDir , filename = self . reportFileName , figtitle = figTitle , showfig = False )  def get_ISI_values ( self ) :          return self . report . ISIViolations   def calculate_features ( waveforms , featureNames ) :      nFeatures = len ( featureNames ) [ nSpikes , nChannels , nSamples ] = waveforms . shape featureValues = np . empty ( ( nSpikes , 0 ) , dtype = float ) for oneFeature in featureNames :          print <str> . format ( oneFeature ) if oneFeature == <str> :              theseValues = waveforms . max ( axis = 2 ) featureValues = np . hstack ( ( featureValues , theseValues ) )  elif oneFeature == <str> :              halfSample = waveforms . shape [ 2 ] / 2 theseValues = waveforms [ : , : , : halfSample ] . max ( axis = 2 ) featureValues = np . hstack ( ( featureValues , theseValues ) )  elif oneFeature == <str> :              theseValues = waveforms . min ( axis = 2 ) featureValues = np . hstack ( ( featureValues , theseValues ) )  elif oneFeature == <str> :              halfSample = waveforms . shape [ 2 ] / 2 theseValues = waveforms [ : , : , : halfSample ] . min ( axis = 2 ) featureValues = np . hstack ( ( featureValues , theseValues ) )  elif oneFeature == <str> :              theseValues = np . sqrt ( np . sum ( waveforms . astype ( float ) ** 2 , axis = 2 ) ) featureValues = np . hstack ( ( featureValues , theseValues ) )  elif oneFeature == <str> :              halfSample = waveforms . shape [ 2 ] / 2 theseValues = np . sqrt ( np . sum ( waveforms [ : , : , : halfSample ] . astype ( float ) ** 2 , axis = 2 ) ) featureValues = np . hstack ( ( featureValues , theseValues ) )  elif oneFeature == <str> :              halfSample = waveforms . shape [ 2 ] / 2 minIndexWave = waveforms . argmin ( axis = 2 ) minBoolWave = minIndexWave < halfSample theseValues = np . sqrt ( np . sum ( waveforms . astype ( float ) ** 2 , axis = 2 ) ) theseValues = theseValues * minBoolWave featureValues = np . hstack ( ( featureValues , theseValues ) )  elif oneFeature == <str> :              halfSample = waveforms . shape [ 2 ] / 2 minIndexWave = waveforms . argmin ( axis = 2 ) minBoolWave = minIndexWave < halfSample theseValues = np . sqrt ( np . sum ( waveforms . astype ( float ) ** 2 , axis = 2 ) ) theseValues = theseValues * minBoolWave featureValues = np . hstack ( ( featureValues , theseValues ) )  elif oneFeature == <str> :              halfSample = waveforms . shape [ 2 ] / 2 minIndexWave = waveforms . argmin ( axis = 2 ) minWave = waveforms . min ( axis = 2 ) valleyBoolWave = np . ones ( minWave . shape ) for indBool , valley in enumerate ( minWave ) :                  spikeChannel = minWave [ indBool ] . argmin ( ) if minIndexWave [ indBool ] [ spikeChannel ] > halfSample :                      valleyBoolWave [ indBool ] = np . full ( [ 4 ] , - 1 )   theseValues = np . sqrt ( np . sum ( waveforms . astype ( float ) ** 2 , axis = 2 ) ) theseValues = theseValues * valleyBoolWave featureValues = np . hstack ( ( featureValues , theseValues ) )  elif oneFeature == <str> :              halfSample = waveforms . shape [ 2 ] / 2 minIndexWave = waveforms . argmin ( axis = 2 ) minWave = waveforms . min ( axis = 2 ) theseFullValues = np . sqrt ( np . sum ( waveforms . astype ( float ) ** 2 , axis = 2 ) ) theseHalfValues = np . sqrt ( np . sum ( waveforms [ : , : , : halfSample ] . astype ( float ) ** 2 , axis = 2 ) ) theseValues = np . zeros ( theseFullValues . shape ) for indBool , valley in enumerate ( minWave ) :                  spikeChannel = minWave [ indBool ] . argmin ( ) if minIndexWave [ indBool ] [ spikeChannel ] < halfSample :                      theseValues [ indBool ] = theseFullValues [ indBool ]  else :                      theseValues [ indBool ] = theseHalfValues [ indBool ]   featureValues = np . hstack ( ( featureValues , theseValues ) )   return featureValues  def write_fet_file ( filename , fetArray ) :      print <str> . format ( filename ) nTotalFeatures = fetArray . shape [ 1 ] fid = open ( filename , <str> ) fid . write ( <str> . format ( nTotalFeatures ) ) for onerow in fetArray :          strarray = [ <str> . format ( val ) for val in onerow ] oneline = <str> . join ( strarray ) + <str> fid . write ( oneline )  fid . close ( )  def pp_features ( featureValues , nvals = 4 ) :      for indr in range ( nvals ) :          for oneval in featureValues [ indr , : ] :              print <str> % oneval ,  print <str>  print <str> for oneval in featureValues [ - 1 , : ] :          print <str> % oneval ,  print <str>  def plot_isi_loghist ( timeStamps , nBins = 350 , fontsize = 8 ) :      fontsizeLegend = fontsize xLims = [ 1e-1 , 1e4 ] ax = plt . gca ( ) ISI = np . diff ( timeStamps ) if np . any ( ISI < 0 ) :          raise <str>  if len ( ISI ) == 0 :          ISI = np . array ( 10 )  logISI = np . log10 ( ISI ) [ ISIhistogram , ISIbinsLog ] = np . histogram ( logISI , bins = nBins ) ISIbins = 1000 * ( 10 ** ISIbinsLog [ : - 1 ] ) fractionViolation = np . mean ( ISI < 1e-3 ) fractionViolation2 = np . mean ( ISI < 2e-3 ) hp , = plt . semilogx ( ISIbins , ISIhistogram , color = <str> ) plt . setp ( hp , lw = 0.5 , color = <str> ) yLims = plt . ylim ( ) plt . xlim ( xLims ) plt . text ( 0.15 , 0.85 * yLims [ - 1 ] , <str> . format ( len ( timeStamps ) ) , fontsize = fontsizeLegend , va = <str> ) plt . text ( 0.15 , 0.6 * yLims [ - 1 ] , <str> . format ( fractionViolation , fractionViolation2 ) , fontsize = fontsizeLegend , va = <str> ) ax . xaxis . grid ( True ) ax . yaxis . grid ( False ) plt . xlabel ( <str> ) ax . set_yticks ( plt . ylim ( ) ) extraplots . set_ticks_fontsize ( ax , fontsize ) return fractionViolation2  def plot_events_in_time ( timeStamps , nBins = 50 , fontsize = 8 ) :      ax = plt . gca ( ) timeBinEdges = np . linspace ( timeStamps [ 0 ] , timeStamps [ - 1 ] , nBins ) ( nEvents , binEdges ) = np . histogram ( timeStamps , bins = timeBinEdges ) hp , = plt . plot ( ( binEdges - timeStamps [ 0 ] ) / 60.0 , np . r_ [ nEvents , 0 ] , drawstyle = <str> ) plt . setp ( hp , lw = 1 , color = <str> ) plt . xlabel ( <str> ) plt . axis ( <str> ) ax . set_yticks ( plt . ylim ( ) ) extraplots . boxoff ( ax ) extraplots . set_ticks_fontsize ( ax , fontsize ) return hp  def plot_waveforms ( waveforms , ntraces = 40 , fontsize = 8 ) :      ( nSpikes , nChannels , nSamplesPerSpike ) = waveforms . shape spikesToPlot = np . random . randint ( nSpikes , size = ntraces ) alignedWaveforms = align_waveforms ( waveforms [ spikesToPlot , : , : ] ) meanWaveforms = np . mean ( alignedWaveforms , axis = 0 ) scalebarSize = abs ( meanWaveforms . min ( ) ) xRange = np . arange ( nSamplesPerSpike ) for indc in range ( nChannels ) :          newXrange = xRange + indc * ( nSamplesPerSpike + 2 ) wavesToPlot = alignedWaveforms [ : , indc , : ] . T plt . plot ( newXrange , wavesToPlot , color = <str> , lw = 0.4 , clip_on = False ) plt . hold ( True ) plt . plot ( newXrange , meanWaveforms [ indc , : ] , color = <str> , lw = 1.5 , clip_on = False )  plt . plot ( 2 * [ - 7 ] , [ 0 , - scalebarSize ] , color = <str> , lw = 2 ) plt . text ( - 10 , - scalebarSize / 2 , <str> . format ( np . round ( scalebarSize ) ) , ha = <str> , va = <str> , ma = <str> , fontsize = fontsize ) plt . hold ( False ) plt . axis ( <str> )  def align_waveforms ( waveforms , peakPosition = 8 ) :      meanWaveforms = np . mean ( waveforms , axis = 0 ) minEachChan = meanWaveforms . min ( axis = 1 ) minChan = minEachChan . argmin ( ) minSampleEachSpike = waveforms [ : , minChan , : ] . argmin ( axis = 1 ) wavesToShift = np . flatnonzero ( minSampleEachSpike != peakPosition ) newWaveforms = waveforms . copy ( ) for indw in wavesToShift :          newWaveforms [ indw , : , : ] = np . roll ( waveforms [ indw , : , : ] , peakPosition - minSampleEachSpike [ indw ] , axis = 1 )  return ( newWaveforms )  def plot_projections ( waveforms , npoints = 200 ) :      ( nSpikes , nChannels , nSamplesPerSpike ) = waveforms . shape spikesToPlot = np . random . randint ( nSpikes , size = npoints ) peaks = - np . min ( waveforms [ spikesToPlot , : , : ] , axis = 2 ) plt . plot ( peaks [ : , 0 ] , peaks [ : , 1 ] , <str> , ms = 0.5 ) plt . hold ( True ) plt . plot ( - peaks [ : , 2 ] , peaks [ : , 3 ] , <str> , ms = 0.5 ) plt . plot ( 0 , 0 , <str> , color = <str> ) plt . hold ( False ) plt . axis ( <str> )  class ClusterReportFromData ( object ) :      def __init__ ( self , dataTT , outputDir = None , filename = None , showfig = True , figtitle = <str> , nrows = 12 ) :          self . dataTT = dataTT self . nSpikes = 0 self . clustersList = [ ] self . nClusters = 0 self . spikesEachCluster = [ ] self . fig = None self . nRows = nrows self . ISIViolations = np . full ( NUMCLUSTERS , 1.0 ) self . set_parameters ( ) self . nPages = 0 self . figTitle = figtitle self . plot_report ( showfig = showfig ) if outputDir is not None :              self . save_report ( outputDir , filename )   def set_parameters ( self ) :          self . nSpikes = len ( self . dataTT . timestamps ) self . clustersList = np . unique ( self . dataTT . clusters ) self . nClusters = len ( self . clustersList ) self . find_spikes_each_cluster ( ) self . nPages = self . nClusters // ( self . nRows + 1 ) + 1  def __str__ ( self ) :          return <str> % ( self . nClusters )  def find_spikes_each_cluster ( self ) :          self . spikesEachCluster = np . empty ( ( self . nClusters , self . nSpikes ) , dtype = bool ) for indc , clusterID in enumerate ( self . clustersList ) :              self . spikesEachCluster [ indc , : ] = ( self . dataTT . clusters == clusterID )   def plot_report ( self , showfig = False ) :          print <str> self . fig = plt . gcf ( ) self . fig . clf ( ) self . fig . set_facecolor ( <str> ) nCols = 3 nRows = self . nRows for indc , clusterID in enumerate ( self . clustersList ) :              if ( indc + 1 ) > self . nRows :                  print <str> continue  tsThisCluster = self . dataTT . timestamps [ self . spikesEachCluster [ indc , : ] ] wavesThisCluster = self . dataTT . samples [ self . spikesEachCluster [ indc , : ] , : , : ] plt . subplot ( self . nRows , nCols , indc * nCols + 1 ) self . ISIViolations [ clusterID - 1 ] = plot_isi_loghist ( tsThisCluster ) print <str> + str ( clusterID ) + <str> + str ( self . ISIViolations [ clusterID - 1 ] ) if indc < ( self . nClusters - 1 ) :                  plt . xlabel ( <str> ) plt . gca ( ) . set_xticklabels ( <str> )  plt . ylabel ( <str> % clusterID , rotation = 0 , va = <str> , ha = <str> ) plt . subplot ( 2 * self . nRows , nCols , 2 * ( indc * nCols ) + 6 ) plot_events_in_time ( tsThisCluster ) if indc < ( self . nClusters - 1 ) :                  plt . xlabel ( <str> ) plt . gca ( ) . set_xticklabels ( <str> )  plt . subplot ( 2 * self . nRows , nCols , 2 * ( indc * nCols ) + 3 ) plot_projections ( wavesThisCluster ) plt . subplot ( self . nRows , nCols , indc * nCols + 2 ) plot_waveforms ( wavesThisCluster )  plt . figtext ( 0.5 , 0.92 , self . figTitle , ha = <str> , fontweight = <str> , fontsize = 10 ) if showfig :              plt . show ( )   def get_title ( self ) :          return <str>  def get_default_filename ( self , figformat ) :          return <str> % ( figformat )  def save_report ( self , outputdir , filename = None , figformat = None ) :          if not os . path . exists ( outputdir ) :              print <str> % ( outputdir ) os . makedirs ( outputdir )  self . fig . set_size_inches ( ( 8.5 , 11 ) ) if figformat is None :              figformat = <str>  if filename is None :              filename = self . get_default_filename ( figformat )  fullFileName = os . path . join ( outputdir , filename ) print <str> % fullFileName self . fig . savefig ( fullFileName , format = figformat )   class ClusterReportTetrode ( ClusterReportFromData ) :      def __init__ ( self , animalName , ephysSession , tetrode , outputDir = None , showfig = False , figtitle = None , nrows = 12 ) :          self . animalName = animalName self . ephysSession = ephysSession self . tetrode = tetrode self . dataDir = <str> self . clustersFile = <str> self . tetrodeFile = <str> if figtitle is None :              self . figTitle = self . dataDir + <str> % self . tetrode  else :              self . figTitle = figtitle  self . load_data ( ) super ( ClusterReportTetrode , self ) . __init__ ( self . dataTT , outputDir = outputDir , showfig = showfig , figtitle = self . figTitle , nrows = nrows )  def load_data ( self ) :          self . dataDir = os . path . join ( settings . EPHYS_PATH , <str> % ( self . animalName , self . ephysSession ) ) clustersDir = os . path . join ( settings . EPHYS_PATH , <str> % ( self . animalName , self . ephysSession ) ) self . tetrodeFile = os . path . join ( self . dataDir , <str> % self . tetrode ) print <str> % ( self . tetrodeFile ) dataTT = loadneuralynx . DataTetrode ( self . tetrodeFile , readWaves = True ) self . clustersFile = os . path . join ( clustersDir , <str> % self . tetrode ) dataTT . set_clusters ( self . clustersFile ) self . dataTT = dataTT  def __str__ ( self ) :          return <str> % ( self . animalName , self . ephysSession , self . tetrode , self . nClusters )  def get_default_filename ( self , figformat ) :          return <str> % ( self . animalName , self . ephysSession , self . tetrode , figformat )   def save_all_reports ( animalName , ephysSession , tetrodes , outputDir ) :      if not os . path . exists ( outputDir ) :          print <str> % ( outputDir ) os . makedirs ( outputDir )  for onetetrode in tetrodes :          sreport = ClusterReportTetrode ( animalName , ephysSession , onetetrode ) sreport . save_report ( outputDir )   def merge_kk_clusters ( animalName , ephysSession , tetrode , clustersToMerge , reportDir = None ) :      dataDir = os . path . join ( settings . EPHYS_PATH , <str> % ( animalName , ephysSession ) ) if reportDir is None :          reportDir = os . path . join ( settings . PROCESSED_REVERSAL_PATH , settings . CLUSTERS_REPORTS_DIR )  fileName = <str> % ( tetrode ) fullFileName = os . path . join ( dataDir , fileName ) backupFileName = os . path . join ( dataDir , fileName + <str> ) print <str> % backupFileName os . system ( <str> % ( fullFileName , backupFileName ) ) clusterData = np . fromfile ( fullFileName , dtype = <str> , sep = <str> ) indNoiseSpike = np . flatnonzero ( clusterData == 1 ) [ 0 ] clusterData [ clusterData == clustersToMerge [ 1 ] ] = clustersToMerge [ 0 ] clusterData [ indNoiseSpike ] = clustersToMerge [ 1 ] clusterData . tofile ( fullFileName , sep = <str> , format = <str> ) print <str> % reportDir ClusterReportTetrode ( animalName , ephysSession , tetrode , reportDir )  if __name__ == <str> :      CASE = 4 if CASE == 1 :          animalName = <str> ephysSession = <str> tetrode = 6 sreport = ClusterReportTetrode ( animalName , ephysSession , tetrode , <str> )  elif CASE == 1.2 :          animalName = <str> ephysSession = <str> tetrode = 6 sreport = ClusterReportTetrode ( animalName , ephysSession , tetrode , <str> , nrows = 24 )  elif CASE == 1.3 :          oneTT = TetrodeToCluster ( <str> , <str> , 8 ) oneTT . load_waveforms ( ) oneTT . run_clustering ( )  elif CASE == 2 :          animalName = <str> ephysSession = <str> save_all_reports ( animalName , ephysSession , [ 2 ] , <str> )  elif CASE == 3 :          animalName = <str> ephysSession = <str> tetrode = 2  elif CASE == 4 :          animalName = <str> ephysSession = <str> tetrodes = [ 1 , 2 ] thisSession = SessionToCluster ( animalName , ephysSession , tetrodes , <str> , <str> , <str> ) thisSession . delete_fet_files ( )    