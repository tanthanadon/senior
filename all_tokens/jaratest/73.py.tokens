from jaratoolbox import loadbehavior from jaratoolbox import behavioranalysis from jaratoolbox import loadopenephys from jaratoolbox import spikesanalysis from jaratoolbox import settings import numpy as np from pylab import * import os SAMPLING_RATE = 30000.0 timeRange = [ - 0.5 , 1 ] responseRange = [ 0.0 , 0.100 ] selectedIntensity = None subject = <str> behavSession = <str> ; ephysSession = <str> behavSession = <str> ; ephysSession = <str> tetrodes = [ 3 , 6 ] nTetrodes = len ( tetrodes ) fullephysDir = os . path . join ( settings . EPHYS_PATH , subject , ephysSession ) event_filename = os . path . join ( fullephysDir , <str> ) experimenter = settings . DEFAULT_EXPERIMENTER paradigm = <str> behavDataFileName = loadbehavior . path_to_behavior_data ( subject , experimenter , paradigm , behavSession ) bdata = loadbehavior . BehaviorData ( behavDataFileName , readmode = <str> ) freqEachTrial = bdata [ <str> ] intensityEachTrial = bdata [ <str> ] nTrials = len ( freqEachTrial ) ev = loadopenephys . Events ( event_filename ) eventTimes = np . array ( ev . timestamps ) / SAMPLING_RATE evID = np . array ( ev . eventID ) eventOnsetTimes = eventTimes [ evID == 1 ] if nTrials != len ( eventOnsetTimes ) :      print <str> minNtrials = min ( nTrials , len ( eventOnsetTimes ) ) nTrials = minNtrials freqEachTrial = freqEachTrial [ : nTrials ] intensityEachTrial = intensityEachTrial [ : nTrials ] eventOnsetTimes = eventOnsetTimes [ : nTrials ]  possibleFreq = np . unique ( freqEachTrial ) possibleIntensity = np . unique ( intensityEachTrial ) if selectedIntensity is None :      selectedTrials = np . ones ( nTrials , dtype = bool )  else :      selectedTrials = ( intensityEachTrial == selectedIntensity )  freqEachTrial = freqEachTrial [ selectedTrials ] trialsEachFreq = behavioranalysis . find_trials_each_type ( freqEachTrial , possibleFreq ) numTrialsEachFreq = trialsEachFreq . sum ( axis = 0 ) sortedTrials = np . nonzero ( trialsEachFreq . T ) [ 1 ] sortingInds = np . argsort ( sortedTrials ) eventOnsetTimes = eventOnsetTimes [ selectedTrials ] for indt , tetrodeID in enumerate ( tetrodes ) :      spikesFilename = os . path . join ( fullephysDir , <str> . format ( tetrodeID ) ) sp = loadopenephys . DataSpikes ( spikesFilename ) spkTimeStamps = np . array ( sp . timestamps ) / SAMPLING_RATE ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spkTimeStamps , eventOnsetTimes , timeRange ) sortedIndexForEachSpike = sortingInds [ trialIndexForEachSpike ] nSpikes = spikesanalysis . count_spikes_in_range ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) meanSpikesEachFrequency = np . empty ( len ( possibleFreq ) ) for indf , oneFreq in enumerate ( possibleFreq ) :          meanSpikesEachFrequency [ indf ] = np . mean ( nSpikes [ trialsEachFreq [ : , indf ] ] )  clf ( ) ax2 = plt . subplot2grid ( ( 1 , 4 ) , ( 0 , 0 ) , colspan = 3 ) plot ( spikeTimesFromEventOnset , sortedIndexForEachSpike , <str> , ms = 1 ) axvline ( x = 0 , ymin = 0 , ymax = 1 , color = <str> ) cumTrials = cumsum ( numTrialsEachFreq ) for indf , num in enumerate ( cumTrials ) :          ax2 . axhline ( y = num , xmin = 0 , xmax = 1 , color = <str> , zorder = 0 )  tickPositions = cumTrials - mean ( numTrialsEachFreq ) / 2 tickLabels = [ <str> % ( possibleFreq [ indf ] / 1000 ) for indf in range ( len ( possibleFreq ) ) ] ax2 . set_yticks ( tickPositions ) ax2 . set_yticklabels ( tickLabels ) ylabel ( <str> . format ( cumTrials [ - 1 ] ) ) title ( fullephysDir + <str> . format ( tetrodeID ) ) xlabel ( <str> ) ax2 = plt . subplot2grid ( ( 1 , 4 ) , ( 0 , 3 ) , colspan = 1 ) ax2 . set_xscale ( <str> ) plot ( possibleFreq , meanSpikesEachFrequency , <str> ) ylabel ( <str> . format ( * responseRange ) ) xlabel ( <str> ) show ( ) waitforbuttonpress ( )   