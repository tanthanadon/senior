import os import numpy as np from scipy import signal from jaratoolbox import spikesanalysis from jaratoolbox import behavioranalysis from jaratoolbox import celldatabase from jaratoolbox import ephyscore from jaratoolbox import settings import studyparams d1mice = studyparams . ASTR_D1_CHR2_MICE dbPath = os . path . join ( settings . FIGURES_DATA_PATH , studyparams . STUDY_NAME , <str> . format ( <str> . join ( d1mice ) ) ) db = celldatabase . load_hdf ( dbPath ) dataframe = db thresholdFRA = 0.2 latencyDataList = [ ] for indIter , ( indRow , dbRow ) in enumerate ( dataframe . iterrows ( ) ) :      cell = ephyscore . Cell ( dbRow , useModifiedClusters = True ) try :          ephysData , bdata = cell . load ( <str> )  except ( IndexError , ValueError ) :          print ( <str> . format ( indRow ) ) dataframe . loc [ indRow , <str> ] = np . nan continue  eventOnsetTimes = ephysData [ <str> ] [ <str> ] eventOnsetTimes = spikesanalysis . minimum_event_onset_diff ( eventOnsetTimes , minEventOnsetDiff = 0.2 ) spikeTimes = ephysData [ <str> ] freqEachTrial = bdata [ <str> ] possibleFreq = np . unique ( freqEachTrial ) intensityEachTrial = bdata [ <str> ] possibleIntensity = np . unique ( intensityEachTrial ) if len ( eventOnsetTimes ) == len ( freqEachTrial ) + 1 :          eventOnsetTimes = eventOnsetTimes [ : - 1 ]  elif len ( eventOnsetTimes ) < len ( freqEachTrial ) :          print ( <str> ) dataframe . loc [ indRow , <str> ] = np . nan continue  else :          print ( <str> ) dataframe . loc [ indRow , <str> ] = np . nan continue  trialsEachCondition = behavioranalysis . find_trials_each_combination ( intensityEachTrial , possibleIntensity , freqEachTrial , possibleFreq ) baseRange = [ - 0.1 , 0 ] responseRange = [ 0 , 0.1 ] alignmentRange = [ - 0.2 , 0.2 ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , eventOnsetTimes , alignmentRange ) nspkBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) nspkResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) conditionMatShape = np . shape ( trialsEachCondition ) numRepeats = np . product ( conditionMatShape [ 1 : ] ) nSpikesMat = np . reshape ( nspkResp . squeeze ( ) . repeat ( numRepeats ) , conditionMatShape ) spikesFilteredByTrialType = nSpikesMat * trialsEachCondition avgRespArray = np . sum ( spikesFilteredByTrialType , 0 ) / np . sum ( trialsEachCondition , 0 ) . astype ( <str> ) thresholdResponse = nspkBase . mean ( ) + thresholdFRA * ( avgRespArray . max ( ) - nspkBase . mean ( ) ) if not np . any ( avgRespArray > thresholdResponse ) :          print ( <str> ) dataframe . loc [ indRow , <str> ] = np . nan continue  fra = avgRespArray > thresholdResponse selectedTrials = np . any ( trialsEachCondition [ : , fra ] , axis = 1 ) indexLimitsSelectedTrials = indexLimitsEachTrial [ : , selectedTrials ] timeRangeForLatency = [ - 0.1 , 0.1 ] try :          ( respLatency , interim ) = spikesanalysis . response_latency ( spikeTimesFromEventOnset , indexLimitsSelectedTrials , timeRangeForLatency , threshold = 0.5 , win = signal . hanning ( 11 ) )  except IndexError :          print ( <str> . format ( indRow ) ) dataframe . loc [ indRow , <str> ] = np . nan continue  dataframe . loc [ indRow , <str> ] = respLatency print ( <str> . format ( 1e3 * respLatency ) )  print ( <str> . format ( dbPath ) ) celldatabase . save_hdf ( dataframe , dbPath )  