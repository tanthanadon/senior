import numpy as np import pycuslsa as pyslsa import matplotlib . pyplot as plt import neuraltda . topology2 as tp2 import neuraltda . simpComp as sc import neuraltda . spectralAnalysis as sa import pandas as pd import h5py as h5 import pickle import tqdm import os import datetime daystr = datetime . datetime . now ( ) . strftime ( <str> ) figsavepth = <str> + daystr + <str> print ( figsavepth ) class TPEnv :      def __init__ ( self , n_holes , hole_rad ) :          self . xlim = [ - 1 , 1 ] self . ylim = [ - 1 , 1 ] self . holes = [ ] self . hole_rad = hole_rad c = 0.75 * ( 2 * np . random . rand ( 2 ) - 1 ) for hole in range ( n_holes ) :              while self . hole_collide ( c ) :                  c = 0.75 * ( 2 * np . random . rand ( 2 ) - 1 )  self . holes . append ( c )  self . hole_rad = hole_rad  def in_hole ( self , x , y ) :          for hole in self . holes :              if np . linalg . norm ( np . subtract ( [ x , y ] , hole ) ) < self . hole_rad :                  return True   return False  def hole_collide ( self , c ) :          for h in self . holes :              if np . sqrt ( ( h [ 0 ] - c [ 0 ] ) ** 2 + ( h [ 1 ] - c [ 1 ] ) ** 2 ) <= 2 * self . hole_rad :                  return True   return False   def generate_environments ( N , h , numrepeats = 1 ) :      envs = [ ] for nholes in range ( N ) :          for r in range ( numrepeats ) :              envs . append ( TPEnv ( nholes , h ) )   return envs  def convert_env_to_img ( env , NSQ ) :      img = np . ones ( ( NSQ , NSQ ) ) X , Y = np . meshgrid ( np . linspace ( - 1 , 1 , NSQ ) , np . linspace ( - 1 , 1 , NSQ ) ) for hole in env . holes :          hx = hole [ 0 ] hy = hole [ 1 ] diffx = X - hx * np . ones ( np . shape ( X ) ) diffy = Y - hy * np . ones ( np . shape ( Y ) ) dists = np . sqrt ( np . power ( diffx , 2 ) + np . power ( diffy , 2 ) ) img [ dists < env . hole_rad ] = 0  return img  def compute_env_img_correlations ( imgs ) :      nsq , _ = np . shape ( imgs [ 0 ] ) dat_mat = np . zeros ( ( len ( imgs ) , nsq * nsq ) ) for ind , img in enumerate ( imgs ) :          dat_mat [ ind , : ] = img . flatten ( )  cormat = np . corrcoef ( dat_mat ) return cormat  def generate_paths ( space , n_steps , ntrials , dl ) :      final_pts = np . zeros ( ( ntrials , n_steps , 2 ) ) for trial in range ( ntrials ) :          pts = [ ] pt = ( 2 * np . random . rand ( 1 , 2 ) - 1 ) [ 0 ] while space . in_hole ( pt [ 0 ] , pt [ 1 ] ) :              pt = ( 2 * np . random . rand ( 1 , 2 ) - 1 ) [ 0 ]  steps_to_go = n_steps while steps_to_go > 0 :              if steps_to_go % 10000 == 0 :                  pass  theta = 2 * np . pi * np . random . rand ( 1 ) [ 0 ] dx = dl * np . cos ( theta ) dy = dl * np . sin ( theta ) if ( abs ( pt [ 0 ] + dx ) < 1 and abs ( pt [ 1 ] + dy ) < 1 and not space . in_hole ( pt [ 0 ] + dx , pt [ 1 ] + dy ) ) :                  steps_to_go -= 1 pt [ 0 ] = pt [ 0 ] + dx pt [ 1 ] = pt [ 1 ] + dy pts . append ( np . copy ( pt ) )   pts = np . vstack ( pts ) final_pts [ trial , : , : ] = pts  return final_pts  def generate_place_fields_random ( n_fields , rad ) :      centers = 2 * np . random . rand ( n_fields , 2 ) - 1 return ( centers , rad )  def generate_place_fields ( n_fields , rad ) :      nf = np . round ( np . sqrt ( n_fields ) ) cx = np . linspace ( - 1 , 1 , nf ) cy = np . linspace ( - 1 , 1 , nf ) centers = np . array ( [ np . array ( ( x , y ) ) for x in cx for y in cy ] ) rads = rad * np . ones ( n_fields ) return ( centers , rads )  def generate_place_fields_perturbed_lattice ( n_fields , rad , stddev = 0.1 ) :      nf = np . round ( np . sqrt ( n_fields ) ) cx = np . linspace ( - 1 , 1 , nf ) cy = np . linspace ( - 1 , 1 , nf ) cx = cx + stddev * np . random . randn ( len ( cx ) ) cy = cy + stddev * np . random . randn ( len ( cy ) ) centers = np . array ( [ np . array ( ( x , y ) ) for x in cx for y in cy ] ) return ( centers , rad )  def generate_place_fields_CI ( n_fields , rad_range , exclusion_param ) :      radii = ( rad_range [ 1 ] - rad_range [ 0 ] ) * np . random . random_sample ( n_fields ) + rad_range [ 0 ] field_c = [ ] for field in range ( n_fields ) :          c = 2 * np . random . rand ( 2 ) - 1 if field == 0 :              field_c . append ( c ) continue  added = False collision = False trie = 0 maxtries = 100 while trie < maxtries and added == False :              for cbar_ind , cbar in enumerate ( field_c ) :                  if np . linalg . norm ( c - cbar ) < exclusion_param * radii [ cbar_ind ] :                      c = 2 * np . random . rand ( 2 ) - 1 collision = True break   if collision :                  trie += 1 collision = False continue  else :                  field_c . append ( c ) added = True   if not added :              field_c . append ( c )   return ( np . array ( field_c ) , radii )  def generate_spikes_gaussian ( paths , fields , max_rate , sigma ) :      ncell , dim = fields . shape ntrial , nwin , _ = paths . shape spikes = np . zeros ( ( ncell , nwin , ntrial ) ) P1 = paths [ : , : , np . newaxis , : ] C1 = fields [ np . newaxis , np . newaxis , : , : ] P1 = np . tile ( P1 , [ 1 , 1 , ncell , 1 ] ) C1 = np . tile ( C1 , [ ntrial , nwin , 1 , 1 ] ) S = P1 - C1 M = np . einsum ( <str> , S , S ) probs = max_rate * np . exp ( - 1 * M / ( 2 * sigma ** 2 ) ) spikes = 1 * np . greater ( probs , np . random . random ( np . shape ( probs ) ) ) return np . einsum ( <str> , spikes )  def generate_spikes ( paths , fields , max_rate , rads ) :      ncell , dim = fields . shape ntrial , nwin , _ = paths . shape spikes = np . zeros ( ( ncell , nwin , ntrial ) ) P1 = paths [ : , : , np . newaxis , : ] C1 = fields [ np . newaxis , np . newaxis , : , : ] P1 = np . tile ( P1 , [ 1 , 1 , ncell , 1 ] ) C1 = np . tile ( C1 , [ ntrial , nwin , 1 , 1 ] ) S = P1 - C1 M = np . einsum ( <str> , S , S ) M = np . sqrt ( M ) SIGMA = np . tile ( rads [ np . newaxis , np . newaxis , : ] , ( ntrial , nwin , 1 ) ) probs = max_rate * np . less ( M , SIGMA ) spikes = 1 * np . greater ( probs , np . random . random ( np . shape ( probs ) ) ) return np . einsum ( <str> , spikes )  def spikes_to_dataframe ( spikes , fs , nsecs ) :      ( ncells , nwin , ntrial ) = spikes . shape spikes_frame = pd . DataFrame ( columns = [ <str> , <str> , <str> ] ) trials_frame = pd . DataFrame ( columns = [ <str> , <str> , <str> ] ) for trial in range ( ntrial ) :          for cell in range ( ncells ) :              cellspikes = np . nonzero ( spikes [ cell , : , trial ] ) [ 0 ] + trial * ( nsecs + 2 ) * fs celldict = { <str> : len ( cellspikes ) * [ cell ] , <str> : cellspikes , <str> : len ( cellspikes ) * [ 0 ] } cellframe = pd . DataFrame ( celldict ) spikes_frame = spikes_frame . append ( cellframe , ignore_index = True )  trial_frame = pd . DataFrame ( { <str> : <str> , <str> : trial * ( nsecs + 2 ) * fs , <str> : ( trial * ( nsecs + 2 ) + nsecs ) * fs , <str> : 0 } , index = [ 0 ] ) trials_frame = trials_frame . append ( trial_frame , ignore_index = True )  clusters_frame = pd . DataFrame ( { <str> : range ( ncells ) , <str> : ncells * [ <str> ] } ) return ( spikes_frame . sort_values ( by = <str> ) , trials_frame , clusters_frame )  L = 2 vel = 0.1 * L hole_rad = 0.3 nsecs = 30 * 60 fs = 10 nwin = nsecs * fs ncells = 100 dl = vel / fs dl = vel / 1 ntrials = 10 max_rate_hz = 4 max_rate_phys = fs max_rate = max_rate_hz / max_rate_phys sigma = 0.1 * L beta = - 1.0 dim = 1 max_hole = 5 nrepeats = 5 num_envs = max_hole * nrepeats exclusion_param = 1.1 NSQ = 100 windt = 100.0 thresh = 6.0 period = [ 0 , 0 ] dtovr = 5.0 print ( <str> ) envs = generate_environments ( max_hole , hole_rad , nrepeats ) print ( <str> ) imgs = [ ] for env in envs :      imgs . append ( convert_env_to_img ( env , NSQ ) )  print ( <str> ) corrmat = compute_env_img_correlations ( imgs ) print ( <str> ) ( fields , rads ) = generate_place_fields_CI ( ncells , [ sigma , 0.1 * L ] , exclusion_param ) spikes = [ ] print ( <str> ) for env1 in tqdm . tqdm ( envs ) :      fields1 , rads1 = generate_place_fields_CI ( ncells , [ sigma , 0.1 * L ] , exclusion_param ) pths1 = generate_paths ( env1 , nwin , ntrials , dl ) spikes1 = generate_spikes ( pths1 , fields1 , max_rate , rads1 ) spikes . append ( spikes1 )  SCGs = [ ] SCGs_trials = [ ] for ind , spikes1 in enumerate ( spikes ) :      print ( <str> ) E1s = [ ] tspikes , ttrials , tclust = spikes_to_dataframe ( spikes1 , fs = fs , nsecs = nsecs ) tp2 . build_binned_file_quick ( tspikes , ttrials , tclust , windt , fs , [ <str> ] , period , <str> . format ( ind ) , dt_overlap = dtovr ) print ( <str> ) with h5 . File ( <str> . format ( ind ) , <str> ) as bf :          poptens = np . array ( bf [ <str> ] [ <str> ] ) ncell , nwin , ntrial = poptens . shape for trial in range ( ntrial ) :              binmat = sc . binnedtobinary ( poptens [ : , : , trial ] , thresh ) print ( np . amax ( np . sum ( binmat , axis = 0 ) ) ) maxsimps = sc . binarytomaxsimplex ( binmat , rDup = True ) E1 = pyslsa . build_SCG ( maxsimps ) E1s . append ( E1 ) SCGs_trials . append ( E1 )   SCGs . append ( E1s )  dists = np . zeros ( ( num_envs * ntrials , num_envs * ntrials ) ) print ( <str> ) for d1 in tqdm . tqdm ( range ( num_envs * ntrials ) ) :      for d2 in tqdm . tqdm ( range ( d1 , num_envs * ntrials ) ) :          dists [ d1 , d2 ] = pyslsa . cuJS ( SCGs_trials [ d1 ] , SCGs_trials [ d2 ] , dim , beta )   print ( <str> ) with open ( os . path . join ( figsavepth , <str> . format ( ntrials , max_hole , nrepeats ) ) , <str> ) as f :      pickle . dump ( ( dists , spikes , fields , envs , corrmat ) , f )   