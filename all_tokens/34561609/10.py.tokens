import logging import datetime import numpy as np import pandas as pd import os import sys import subprocess import pickle import h5py import time import glob from scipy . interpolate import interp1d from scipy import integrate from ephys import events , core def create_subwindows ( segment , subwin_len , n_subwin_starts ) :      starts = np . floor ( np . linspace ( segment [ 0 ] , segment [ 0 ] + subwin_len , n_subwin_starts ) ) nsubwin = np . floor ( ( segment [ 1 ] - segment [ 0 ] ) / subwin_len ) subwindows = [ ] for start in starts :          subwin_front = np . round ( np . arange ( start , segment [ 1 ] , subwin_len ) ) for front in subwin_front :              subwin_end = front + subwin_len subwindows . append ( [ front , subwin_end ] )   return subwindows  def compute_gen_windows ( trial_len , fs , segment_info , win_size , dt_overlap ) :          gen_seg_start , gen_seg_end = get_segment ( [ 0 , trial_len ] , fs , segment_info ) gen_seg = [ gen_seg_start , gen_seg_end ] win_size_samples = int ( np . round ( win_size / 1000. * fs ) ) overlap_samples = int ( np . round ( dt_overlap / 1000. * fs ) ) gen_windows = create_subwindows ( gen_seg , win_size_samples , overlap_samples ) return gen_windows  def create_subwindows ( segment , subwin_len , noverlap = 0 ) :      dur = segment [ 1 ] - segment [ 0 ] skip = subwin_len - noverlap max_k = int ( np . floor ( float ( dur ) / float ( skip ) ) ) starts = [ segment [ 0 ] + k * skip for k in range ( max_k ) ] windows = [ [ w , min ( w + ( subwin_len - 1 ) , segment [ 1 ] ) ] for w in starts ] return windows  def old_get_segment ( trial_bounds , fs , segment_info ) :      if segment_info [ <str> ] == 1 :          return trial_bounds  else :          seg_start = trial_bounds [ 0 ] + np . floor ( segment_info [ <str> ] * ( fs / 1000. ) ) seg_end = trial_bounds [ 1 ] + np . floor ( segment_info [ <str> ] * ( fs / 1000. ) )  return [ seg_start , seg_end ]  def do_dag_bin ( block_path , spikes , trials , clusters , fs , winsize , segment_info , cluster_group = [ <str> ] , dt_overlap = 0.0 ) :      block_path = os . path . abspath ( block_path ) analysis_id = datetime . datetime . utcnow ( ) . strftime ( <str> ) raw_binned_fname = analysis_id + <str> . format ( winsize , dt_overlap ) analysis_id_forward = analysis_id + <str> . format ( winsize , dt_overlap ) bfdict = { <str> : analysis_id_forward } binned_folder = os . path . join ( block_path , <str> . format ( analysis_id ) ) if not os . path . exists ( binned_folder ) :          os . makedirs ( binned_folder )  raw_binned_f = os . path . join ( binned_folder , raw_binned_fname ) build_binned_file ( spikes , trials , clusters , winsize , fs , cluster_group , segment_info , raw_binned_f , dt_overlap ) bfdict [ <str> ] = binned_folder return bfdict  def calc_CI_bettis_on_dataset ( block_path , analysis_id , cluster_group = None , windt_ms = 50. , n_subwin = 5 , threshold = 6 , segment_info = DEFAULT_SEGMENT_INFO , persistence = False ) :      global alogf analysis_path = os . path . join ( block_path , <str> . format ( analysis_id ) ) if not os . path . exists ( analysis_path ) :          os . makedirs ( analysis_path )  analysis_logfile_name = <str> . format ( analysis_id ) alogf = os . path . join ( analysis_path , analysis_logfile_name ) maxbetti = 10 kwikfile = core . find_kwik ( block_path ) kwikname , ext = os . path . splitext ( os . path . basename ( kwikfile ) ) spikes = core . load_spikes ( block_path ) clusters = core . load_clusters ( block_path ) trials = events . load_trials ( block_path ) fs = core . load_fs ( block_path ) windt_samps = np . floor ( windt_ms * ( fs / 1000. ) ) topology_log ( alogf , <str> . format ( str ( fs ) ) ) topology_log ( alogf , <str> . format ( str ( windt_ms ) , str ( windt_samps ) ) ) topology_log ( alogf , <str> . format ( str ( cluster_group ) ) ) nclu = len ( clusters [ clusters [ <str> ] . isin ( cluster_group ) ] ) topology_log ( alogf , <str> . format ( str ( nclu ) ) ) topology_log ( alogf , <str> . format ( str ( threshold ) ) ) stims = set ( trials [ <str> ] . values ) for stim in stims :          print ( <str> . format ( stim ) ) topology_log ( alogf , <str> . format ( stim ) ) stim_trials = trials [ trials [ <str> ] == stim ] nreps = len ( stim_trials . index ) topology_log ( alogf , <str> . format ( stim , str ( nreps ) ) ) stim_bettis = np . zeros ( [ nreps , maxbetti ] ) betti_savefile = kwikname + <str> . format ( stim ) + <str> betti_savefile = os . path . join ( analysis_path , betti_savefile ) topology_log ( alogf , <str> . format ( betti_savefile ) ) betti_persistence_savefile = kwikname + <str> . format ( stim ) + <str> betti_persistence_savefile = os . path . join ( analysis_path , betti_persistence_savefile ) topology_log ( alogf , <str> . format ( betti_persistence_savefile ) ) betti_persistence_dict = dict ( ) for rep in range ( nreps ) :              topology_log ( alogf , <str> . format ( str ( rep ) ) ) pfile = kwikname + <str> . format ( stim ) + <str> . format ( int ( rep ) ) + <str> pfile = os . path . join ( analysis_path , pfile ) topology_log ( alogf , <str> . format ( pfile ) ) trial_start = stim_trials . iloc [ rep ] [ <str> ] trial_end = stim_trials . iloc [ rep ] [ <str> ] cg_params = DEFAULT_CG_PARAMS cg_params [ <str> ] = windt_samps cg_params [ <str> ] = cluster_group cg_params [ <str> ] = n_subwin cg_params [ <str> ] = threshold segment = get_segment ( [ trial_start , trial_end ] , fs , segment_info ) print ( <str> . format ( str ( trial_start ) , str ( trial_end ) ) ) print ( <str> . format ( str ( segment [ 0 ] ) , str ( segment [ 1 ] ) ) ) topology_log ( alogf , <str> . format ( str ( trial_start ) , str ( trial_end ) ) ) topology_log ( alogf , <str> . format ( str ( segment [ 0 ] ) , str ( segment [ 1 ] ) ) ) bettis = calc_bettis ( spikes , segment , clusters , pfile , cg_params , persistence ) trial_bettis = bettis [ - 1 ] [ 1 ] stim_bettis [ rep , : len ( trial_bettis ) ] = trial_bettis betti_persistence_dict [ <str> . format ( str ( rep ) ) ] = bettis  stim_bettis_frame = pd . DataFrame ( stim_bettis ) stim_bettis_frame . to_csv ( betti_savefile , index_label = <str> ) if persistence :              with open ( betti_persistence_savefile , <str> ) as bpfile :                  pickle . dump ( betti_persistence_dict , bpfile )   topology_log ( alogf , <str> )   def calc_CI_bettis_on_loaded_dataset ( spikes , clusters , trials , fs , kwikfile , kwikname , cluster_group = None , windt_ms = 50. , n_subwin = 5 , segment_info = DEFAULT_SEGMENT_INFO , persistence = False ) :      maxbetti = 10 windt_samps = np . floor ( windt_ms * ( fs / 1000. ) ) stims = set ( trials [ <str> ] . values ) for stim in stims :          print ( <str> . format ( stim ) ) stim_trials = trials [ trials [ <str> ] == stim ] nreps = len ( stim_trials . index ) stim_bettis = np . zeros ( [ nreps , maxbetti ] ) betti_savefile = kwikname + <str> . format ( stim ) + <str> betti_savefile = os . path . join ( block_path , betti_savefile ) betti_persistence_savefile = kwikname + <str> . format ( stim ) + <str> betti_persistence_savefile = os . path . join ( block_path , betti_persistence_savefile ) betti_persistence_dict = dict ( ) for rep in range ( nreps ) :              pfile = kwikname + <str> . format ( stim ) + <str> . format ( int ( rep ) ) + <str> pfile = os . path . join ( block_path , pfile ) trial_start = stim_trials . iloc [ rep ] [ <str> ] trial_end = stim_trials . iloc [ rep ] [ <str> ] cg_params = DEFAULT_CG_PARAMS cg_params [ <str> ] = windt_samps cg_params [ <str> ] = cluster_group cg_params [ <str> ] = n_subwin segment = get_segment ( [ trial_start , trial_end ] , fs , segment_info ) print ( <str> . format ( str ( trial_start ) , str ( trial_end ) ) ) print ( <str> . format ( str ( segment [ 0 ] ) , str ( segment [ 1 ] ) ) ) bettis = calc_bettis ( spikes , segment , clusters , pfile , cg_params , persistence ) trial_bettis = bettis [ - 1 ] [ 1 ] stim_bettis [ rep , : len ( trial_bettis ) ] = trial_bettis betti_persistence_dict [ <str> . format ( str ( rep ) ) ] = bettis  stim_bettis_frame = pd . DataFrame ( stim_bettis ) stim_bettis_frame . to_csv ( betti_savefile , index_label = <str> ) if persistence :              with open ( betti_persistence_savefile , <str> ) as bpfile :                  pickle . dump ( betti_persistence_dict , bpfile )     def calc_CI_bettis_on_dataset_average_activity ( block_path , cluster_group = None , windt_ms = 50. , n_subwin = 5 , segment_info = DEFAULT_SEGMENT_INFO , persistence = False ) :      maxbetti = 10 kwikfile = core . find_kwik ( block_path ) kwikname , ext = os . path . splitext ( os . path . basename ( kwikfile ) ) spikes = core . load_spikes ( block_path ) clusters = core . load_clusters ( block_path ) trials = events . load_trials ( block_path ) fs = core . load_fs ( block_path ) windt_samps = np . floor ( windt_ms * ( fs / 1000. ) ) stims = set ( trials [ <str> ] . values ) for stim in stims :          print ( <str> . format ( stim ) ) stim_trials = trials [ trials [ <str> ] == stim ] nreps = len ( stim_trials . index ) stim_bettis = np . zeros ( [ nreps , maxbetti ] ) betti_savefile = kwikname + <str> . format ( stim ) + <str> betti_savefile = os . path . join ( block_path , betti_savefile ) betti_persistence_savefile = kwikname + <str> . format ( stim ) + <str> betti_persistence_savefile = os . path . join ( block_path , betti_persistence_savefile ) betti_persistence_dict = dict ( ) pfile = kwikname + <str> . format ( stim ) + <str> + <str> pfile = os . path . join ( block_path , pfile ) first_trial_start = stim_trials . iloc [ 0 ] [ <str> ] first_trial_end = stim_trials . iloc [ 0 ] [ <str> ] segment = get_segment ( [ first_trial_start , first_trial_end ] , fs , segment_info ) cg_params = DEFAULT_CG_PARAMS cg_params [ <str> ] = windt_samps cg_params [ <str> ] = cluster_group cg_params [ <str> ] = n_subwin print ( <str> . format ( str ( segment [ 0 ] ) , str ( segment [ 1 ] ) ) ) for rep in range ( nreps ) [ 1 : ] :              trial_start = stim_trials . iloc [ rep ] [ <str> ] trial_end = stim_trials . iloc [ rep ] [ <str> ] spikes [ <str> ] = spikes . apply ( lambda row : spike_time_subtracter ( row , trial_start , trial_end , first_trial_start ) , axis = 1 )  bettis = calc_bettis ( spikes , segment , clusters , pfile , cg_params , persistence ) trial_bettis = bettis [ - 1 ] [ 1 ] stim_bettis [ rep , : len ( trial_bettis ) ] = trial_bettis betti_persistence_dict [ <str> . format ( str ( rep ) ) ] = bettis stim_bettis_frame = pd . DataFrame ( stim_bettis ) stim_bettis_frame . to_csv ( betti_savefile , index_label = <str> ) if persistence :              with open ( betti_persistence_savefile , <str> ) as bpfile :                  pickle . dump ( betti_persistence_dict , bpfile )     def calc_CI_bettis_binned_data ( analysis_id , binned_data_file , block_path , thresh ) :      global alogf bdf_name , ext = os . path . splitext ( os . path . basename ( binned_data_file ) ) analysis_path = os . path . join ( block_path , <str> . format ( analysis_id , bdf_name ) ) if not os . path . exists ( analysis_path ) :          os . makedirs ( analysis_path )  analysis_files_prefix = <str> . format ( bdf_name , analysis_id ) analysis_logfile_name = <str> . format ( bdf_name , analysis_id ) alogf = os . path . join ( analysis_path , analysis_logfile_name ) maxbetti = 50 kwikfile = core . find_kwik ( block_path ) kwikname , ext = os . path . splitext ( os . path . basename ( kwikfile ) ) topology_log ( alogf , <str> . format ( kwikfile ) ) topology_log ( alogf , <str> . format ( bdf_name ) ) topology_log ( alogf , <str> . format ( thresh ) ) with h5py . File ( binned_data_file , <str> ) as bdf :          stims = bdf . keys ( ) nstims = len ( stims ) for stim in stims :              topology_log ( alogf , <str> . format ( stim ) ) stim_trials = bdf [ stim ] nreps = len ( stim_trials ) topology_log ( alogf , <str> . format ( stim , str ( nreps ) ) ) stim_bettis = np . zeros ( [ nreps , maxbetti ] ) betti_savefile = analysis_files_prefix + <str> . format ( stim ) + <str> betti_savefile = os . path . join ( analysis_path , betti_savefile ) topology_log ( alogf , <str> . format ( betti_savefile ) ) betti_persistence_savefile = analysis_files_prefix + <str> . format ( stim ) + <str> betti_persistence_savefile = os . path . join ( analysis_path , betti_persistence_savefile ) topology_log ( alogf , <str> . format ( betti_persistence_savefile ) ) betti_persistence_dict = dict ( ) for rep , repkey in enumerate ( stim_trials . keys ( ) ) :                  pfile = analysis_files_prefix + <str> . format ( stim ) + <str> . format ( repkey ) + <str> pfile = os . path . join ( analysis_path , pfile ) bettis = calc_bettis_from_binned_data ( stim_trials [ repkey ] , pfile , thresh ) trial_bettis = bettis [ - 1 ] [ 1 ] stim_bettis [ int ( rep ) , : len ( trial_bettis ) ] = trial_bettis betti_persistence_dict [ <str> . format ( str ( rep ) ) ] = bettis  stim_bettis_frame = pd . DataFrame ( stim_bettis ) stim_bettis_frame . to_csv ( betti_savefile , index_label = <str> ) with open ( betti_persistence_savefile , <str> ) as bpfile :                  pickle . dump ( betti_persistence_dict , bpfile )   topology_log ( alogf , <str> )   def calc_CI_bettis_permuted_binned_data ( analysis_id , binned_data_file , block_path , thresh ) :      global alogf bdf_name , ext = os . path . splitext ( os . path . basename ( binned_data_file ) ) analysis_path = os . path . join ( block_path , <str> . format ( analysis_id , bdf_name ) ) if not os . path . exists ( analysis_path ) :          os . makedirs ( analysis_path )  analysis_files_prefix = <str> . format ( bdf_name , analysis_id ) analysis_logfile_name = <str> . format ( bdf_name , analysis_id ) alogf = os . path . join ( analysis_path , analysis_logfile_name ) maxbetti = 50 kwikfile = core . find_kwik ( block_path ) kwikname , ext = os . path . splitext ( os . path . basename ( kwikfile ) ) topology_log ( alogf , <str> . format ( kwikfile ) ) topology_log ( alogf , <str> . format ( bdf_name ) ) topology_log ( alogf , <str> . format ( thresh ) ) with h5py . File ( binned_data_file , <str> ) as bdf :          stims = bdf . keys ( ) nstims = len ( stims ) for stim in stims :              topology_log ( alogf , <str> . format ( stim ) ) stim_trials = bdf [ stim ] nreps = len ( stim_trials ) topology_log ( alogf , <str> . format ( stim , str ( nreps ) ) ) stim_bettis = np . zeros ( [ nreps , maxbetti ] ) betti_savefile = analysis_files_prefix + <str> . format ( stim ) + <str> betti_savefile = os . path . join ( analysis_path , betti_savefile ) topology_log ( alogf , <str> . format ( betti_savefile ) ) betti_persistence_savefile = analysis_files_prefix + <str> . format ( stim ) + <str> betti_persistence_savefile = os . path . join ( analysis_path , betti_persistence_savefile ) topology_log ( alogf , <str> . format ( betti_persistence_savefile ) ) betti_persistence_dict = dict ( ) for rep , repkey in enumerate ( stim_trials . keys ( ) ) :                  stim_trial_rep = stim_trials [ repkey ] betti_persistence_perm_dict = dict ( ) for perm , permkey in enumerate ( stim_trial_rep . keys ( ) ) :                      pfile = analysis_files_prefix + <str> . format ( stim ) + <str> . format ( repkey , permkey ) + <str> pfile = os . path . join ( analysis_path , pfile ) bettis = calc_bettis_from_binned_data ( stim_trial_rep [ permkey ] , pfile , thresh ) betti_persistence_perm_dict [ <str> . format ( str ( perm ) ) ] = bettis  betti_persistence_dict [ <str> . format ( str ( rep ) ) ] = betti_persistence_perm_dict  with open ( betti_persistence_savefile , <str> ) as bpfile :                  pickle . dump ( betti_persistence_dict , bpfile )   topology_log ( alogf , <str> )   def shuffle_control_binned_data ( binned_data_file , permuted_data_file , nshuffs ) :      global alogf with h5py . File ( binned_data_file , <str> ) as popvec_f :          win_size = popvec_f . attrs [ <str> ] fs = popvec_f . attrs [ <str> ] nclus = popvec_f . attrs [ <str> ] stims = popvec_f . keys ( ) with h5py . File ( permuted_data_file , <str> ) as perm_f :              perm_f . attrs [ <str> ] = win_size perm_f . attrs [ <str> ] = <str> perm_f . attrs [ <str> ] = <str> perm_f . attrs [ <str> ] = fs for stim in stims :                  perm_stimgrp = perm_f . create_group ( stim ) stimdata = popvec_f [ stim ] trials = stimdata . keys ( ) for trial in trials :                      trialdata = stimdata [ trial ] clusters = trialdata [ <str> ] popvec = trialdata [ <str> ] windows = trialdata [ <str> ] nwins = len ( windows ) for perm_num in range ( nshuffs ) :                          clusters_to_save = clusters popvec_save = popvec perm_permgrp = perm_stimgrp . create_group ( <str> + str ( trial ) + <str> + str ( perm_num ) ) for clu_num in range ( nclus ) :                              permt = np . random . permutation ( nwins ) np . random . shuffle ( popvec_save [ clu_num , : ] )  perm_permgrp . create_dataset ( <str> , data = popvec_save ) perm_permgrp . create_dataset ( <str> , data = clusters_to_save ) perm_permgrp . create_dataset ( <str> , data = windows )       def permute_binned_data ( binned_data_file , permuted_data_file , n_cells_in_perm , n_perm ) :      global alogf with h5py . File ( binned_data_file , <str> ) as popvec_f :          win_size = popvec_f . attrs [ <str> ] fs = popvec_f . attrs [ <str> ] nclus = popvec_f . attrs [ <str> ] permt = np . random . permutation ( nclus ) permt = permt [ 0 : n_cells_in_perm ] stims = popvec_f . keys ( ) with h5py . File ( permuted_data_file , <str> ) as perm_f :              perm_f . attrs [ <str> ] = win_size perm_f . attrs [ <str> ] = <str> perm_f . attrs [ <str> ] = <str> perm_f . attrs [ <str> ] = fs perm_f . attrs [ <str> ] = nclus for stim in stims :                  perm_stimgrp = perm_f . create_group ( stim ) stimdata = popvec_f [ stim ] trials = stimdata . keys ( ) for trial in trials :                      perm_trialgrp = perm_stimgrp . create_group ( trial ) trialdata = stimdata [ trial ] clusters = trialdata [ <str> ] popvec = trialdata [ <str> ] windows = trialdata [ <str> ] for perm_num in range ( n_perm ) :                              permt = np . random . permutation ( nclus ) permt = permt [ 0 : n_cells_in_perm ] . tolist ( ) clusters_to_save = np . zeros ( clusters . shape ) popvec_save = np . zeros ( popvec . shape ) popvec . read_direct ( popvec_save ) clusters . read_direct ( clusters_to_save ) clusters_to_save = clusters_to_save [ permt ] popvec_save = popvec_save [ permt ] perm_permgrp = perm_trialgrp . create_group ( str ( perm_num ) ) perm_permgrp . create_dataset ( <str> , data = popvec_save ) perm_permgrp . create_dataset ( <str> , data = clusters_to_save ) perm_permgrp . create_dataset ( <str> , data = windows )       def make_shuffled_controls ( path_to_binned , nshuffs ) :      path_to_binned = os . path . abspath ( path_to_binned ) binned_data_files = glob . glob ( os . path . join ( path_to_binned , <str> ) ) if not binned_data_files :          print ( <str> ) sys . exit ( - 1 )  shuffled_controls_folder = os . path . join ( path_to_binned , <str> ) if not os . path . exists ( shuffled_controls_folder ) :          os . makedirs ( shuffled_controls_folder )  for binned_data_file in binned_data_files :          bdf_fold , bdf_full_name = os . path . split ( binned_data_file ) bdf_name , bdf_ext = os . path . splitext ( bdf_full_name ) scf_name = bdf_name + <str> shuffled_control_file = os . path . join ( shuffled_controls_folder , scf_name ) shuffle_control_binned_data ( binned_data_file , shuffled_control_file , nshuffs )   def make_permuted_binned_data ( path_to_binned , n_cells_in_perm , n_perms ) :      path_to_binned = os . path . abspath ( path_to_binned ) binned_data_files = glob . glob ( os . path . join ( path_to_binned , <str> ) ) if not binned_data_files :          print ( <str> ) sys . exit ( - 1 )  permuted_binned_folder = os . path . join ( path_to_binned , <str> ) if not os . path . exists ( permuted_binned_folder ) :          os . makedirs ( permuted_binned_folder )  for binned_data_file in binned_data_files :          bdf_fold , bdf_full_name = os . path . split ( binned_data_file ) bdf_name , bdf_ext = os . path . splitext ( bdf_full_name ) pbd_name = bdf_name + <str> permuted_data_file = os . path . join ( permuted_binned_folder , pbd_name ) permute_binned_data ( binned_data_file , permuted_data_file , n_cells_in_perm , n_perms )   def do_compute_betti_shuffle ( stim_trials , pfile_stem , thresh , nshuffs = 1 ) :      assert <str> in stim_trials . keys ( ) , <str> data_tensor = np . array ( stim_trials [ <str> ] ) clusters = np . array ( stim_trials [ <str> ] ) levels = ( data_tensor . shape ) [ 2 : ] assert len ( levels ) == 1 , <str> bettidict = { } for trial in range ( levels [ 0 ] ) :          pfile = pfile_stem + <str> % trial data_mat = data_tensor [ : , : , trial ] data_mat = ( np . random . permute ( data_mat . T ) ) . T bettis = calc_bettis ( data_mat , clusters , pfile , thresh ) bettidict [ str ( trial ) ] = { <str> : bettis }  return bettidict  def do_compute_betti_multilevel ( stim_trials , pfile_stem , thresh ) :      assert <str> in stim_trials . keys ( ) , <str> data_tensor = np . array ( stim_trials [ <str> ] ) clusters = np . array ( stim_trials [ <str> ] ) dts = data_tensor . shape levels = ( dts ) [ 2 : ] nlen = np . product ( dts [ 2 : ] ) reshaped_data = np . reshape ( data_tensor , ( dts [ 0 ] , dts [ 1 ] , nlen ) ) bettidict = { } for trial in range ( nlen ) :          ids = lin2ind ( levels , trial ) pfile = pfile_stem + <str> . join ( [ <str> % s for s in ids ] ) + <str> data_mat = reshaped_data [ : , : , trial ] bettis = calc_bettis ( data_mat , clusters , pfile , thresh ) bettidict [ str ( trial ) ] = { <str> : bettis , <str> : ids }  return bettidict  def do_compute_betti_sliding_window ( stim_trials , pfile_stem , thresh , shuffle , nperms , ncellsperm , sliding_window_length = 10 ) :      assert <str> in stim_trials . keys ( ) , <str> data_tensor = np . array ( stim_trials [ <str> ] ) clusters = np . array ( stim_trials [ <str> ] ) ( ncells , nwin , ntrials ) = ( data_tensor . shape ) bettidict = { } nslide = nwin - sliding_window_length for trial in range ( ntrials ) :          bettitrial = { } for slide in range ( nslide ) :              pfile = get_pfile_name ( pfile_stem , rep = trial , slide = slide ) data_mat = data_tensor [ : , slide : slide + sliding_window_length , trial ] if nperms :                  bettipermdict = { } ( new_tensor , perm_cells ) = get_perms ( data_mat , nperms , ncellsperm ) for perm in range ( nperms ) :                      pfile = get_pfile_name ( pfile_stem , rep = trial , slide = slide , perm = perm ) print ( perm ) nmat = new_tensor [ : , : , perm ] if shuffle :                          nmat = get_shuffle ( nmat )  perm_clus = clusters [ perm_cells [ : , perm ] ] bettis = calc_bettis ( data_mat , perm_clusters , pfile , thresh ) bettipermdict [ str ( perm ) ] = { <str> : bettis }  bettitrial [ str ( slide ) ] = bettipermdict  else :                  if shuffle :                      data_mat = get_shuffle ( data_mat ) pfile = get_pfile_name ( pfile_stem , rep = trial , slide = slide , shuffled = 1 )  bettis = calc_bettis ( data_mat , clusters , pfile , thresh ) bettitrial [ str ( slide ) ] = { <str> : bettis }   bettidict [ str ( trial ) ] = bettitrial  return bettidict  def compute_topology_all_trials ( data_tensor , clusters , pfile_stem , thresh , remove_duplicates = False ) :      ( ncells , nwin , ntrials ) = data_tensor . shape rs = nwin * ntrials pfile = pfile_stem + <str> data_mat = np . reshape ( data_tensor , ( ncells , rs ) ) if remove_duplicates :          lex_ind = np . lexsort ( data_mat ) data_mat = data_mat [ : , lex_ind ] diff = np . diff ( data_mat , axis = 1 ) ui = np . ones ( len ( data_mat . T ) , <str> ) ui [ 1 : ] = ( diff != 0 ) . any ( axis = 0 ) data_mat = data_mat [ : , ui ]  pbettis = calc_bettis ( data_mat , clusters , pfile , thresh ) bettis = pbettis [ - 1 ] bpd = { <str> : bettis } return bpd  def calc_CI_bettis_all_trials ( analysis_id , binned_data_file , block_path , thresh ) :      bdf_name , ext = os . path . splitext ( os . path . basename ( binned_data_file ) ) analysis_path = os . path . join ( block_path , <str> . format ( analysis_id ) ) if not os . path . exists ( analysis_path ) :          os . makedirs ( analysis_path )  with h5py . File ( binned_data_file , <str> ) as bdf :          stims = bdf . keys ( ) bpd_withstim = dict ( ) for stim in stims :              stim_trials = bdf [ stim ] betti_savefile = analysis_id + <str> . format ( stim ) + <str> betti_savefile = os . path . join ( analysis_path , betti_savefile ) bps = analysis_id + <str> . format ( stim ) + <str> betti_persistence_savefile = os . path . join ( analysis_path , bps ) bpd = dict ( ) pfile_stem = analysis_id + <str> . format ( stim ) pfile_stem = os . path . join ( analysis_path , pfile_stem ) data_tens = np . array ( stim_trials [ <str> ] ) clusters = np . array ( stim_trials [ <str> ] ) bpd = compute_topology_all_trials ( data_tens , clusters , pfile_stem , thresh ) bpd_withstim [ stim ] = bpd with open ( betti_persistence_savefile , <str> ) as bpfile :                  pickle . dump ( bpd , bpfile )   bpdws_sfn = os . path . join ( analysis_path , analysis_id + <str> ) with open ( bpdws_sfn , <str> ) as bpdwsfile :              pickle . dump ( bpd_withstim , bpdwsfile )  return bpdws_sfn   def concatenate_trials ( data_tensor ) :      ( ncells , nwin , ntrials ) = data_tensor . shape rs = nwin * ntrials data_mat = np . reshape ( data_tensor , ( ncells , rs ) ) return data_mat  def compute_total_topology ( analysis_id , binned_data_file , block_path , thresh ) :      bdf_name , ext = os . path . splitext ( os . path . basename ( binned_data_file ) ) analysis_path = os . path . join ( block_path , <str> . format ( analysis_id ) ) if not os . path . exists ( analysis_path ) :          os . makedirs ( analysis_path )  bpd = dict ( ) pfile_stem = analysis_id + <str> pfile_stem = os . path . join ( analysis_path , pfile_stem ) with h5py . File ( binned_data_file , <str> ) as bdf :          stims = bdf . keys ( ) nstims = len ( stims ) bpd_withstim = dict ( ) stim_mat_list = [ ] for stim in stims :              stim_trials = bdf [ stim ] data_tens = np . array ( stim_trials [ <str> ] ) clusters = np . array ( stim_trials [ <str> ] ) stim_mat = concatenate_trials ( data_tens ) stim_mat_list . append ( stim_mat )  ( ncell , nwin ) = stim_mat_list [ 0 ] . shape stimtens = np . zeros ( ( ncell , nwin , nstims ) ) for ind , stim_mat in enumerate ( stim_mat_list ) :              stimtens [ : , : , ind ] = stim_mat  bpd = compute_topology_all_trials ( stimtens , clusters , pfile_stem , thresh , remove_duplicates = True ) bpdws_sfn = os . path . join ( analysis_path , analysis_id + <str> ) with open ( bpdws_sfn , <str> ) as bpdwsfile :              pickle . dump ( bpd , bpdwsfile )  return bpdws_sfn    