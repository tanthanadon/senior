import os import time import numpy as np import pandas as pd from sklearn import neighbors import matplotlib . pyplot as plt from jaratoolbox import settings from jaratoolbox import celldatabase from jaratoolbox import spikesorting from jaratoolbox import ephyscore import figparams reload ( spikesorting ) reload ( ephyscore ) SAVE = True dbPath = os . path . join ( settings . FIGURES_DATA_PATH , figparams . STUDY_NAME , <str> ) db = celldatabase . load_hdf ( dbPath ) cellsToRescue = db . query ( <str> ) for indRow , dbRow in cellsToRescue . iterrows ( ) :      cell = ephyscore . Cell ( dbRow , useModifiedClusters = False ) timestamps , samples , recordingNumber = cell . load_all_spikedata ( ) isiViolations = spikesorting . calculate_ISI_violations ( timestamps ) print <str> . format ( isiViolations * 100 ) print <str> . format ( len ( timestamps ) ) featuresMat = spikesorting . calculate_features ( samples , [ <str> , <str> , <str> ] ) try :          dM = spikesorting . distance_to_centroid ( featuresMat )  except :          continue  sortArray = np . argsort ( dM ) spikesToRemove = 0 thisISIviolation = isiViolations jumpBy = int ( len ( timestamps ) * 0.01 ) if jumpBy == 0 :          jumpBy = 1  includeBool = sortArray < ( len ( sortArray ) - spikesToRemove ) timestampsToInclude = timestamps [ includeBool ] while thisISIviolation > 0.02 :          spikesToRemove += jumpBy includeBool = sortArray < ( len ( sortArray ) - spikesToRemove ) timestampsToInclude = timestamps [ includeBool ] thisISIviolation = spikesorting . calculate_ISI_violations ( np . sort ( timestampsToInclude ) ) print <str> . format ( spikesToRemove , thisISIviolation )  print <str> . format ( len ( timestampsToInclude ) , len ( timestamps ) ) for thisRecordingNum in np . unique ( recordingNumber ) :          indsThisRecording = np . flatnonzero ( recordingNumber == thisRecordingNum ) includeThisRecording = includeBool [ indsThisRecording ] subject = cell . dbRow [ <str> ] date = cell . dbRow [ <str> ] tetrode = int ( cell . dbRow [ <str> ] ) cluster = int ( cell . dbRow [ <str> ] ) ephysTimeThisRecording = cell . dbRow [ <str> ] [ thisRecordingNum ] clusterDir = <str> . format ( <str> . join ( [ date , ephysTimeThisRecording ] ) ) clusterFullPath = os . path . join ( settings . EPHYS_PATH , subject , clusterDir ) clusterFile = os . path . join ( clusterFullPath , <str> . format ( tetrode ) ) allClustersThisTetrode = np . fromfile ( clusterFile , dtype = <str> , sep = <str> ) [ 1 : ] nClusters = len ( np . unique ( allClustersThisTetrode ) ) indsThisCluster = np . flatnonzero ( allClustersThisTetrode == cluster ) assert len ( indsThisCluster ) == len ( includeThisRecording ) for indIter , indThisSpike in enumerate ( indsThisCluster ) :              includeThisSpike = includeThisRecording [ indIter ] if includeThisSpike == 0 :                  allClustersThisTetrode [ indThisSpike ] = 0   modifiedClusterFile = os . path . join ( clusterFullPath , <str> . format ( tetrode ) ) fid = open ( modifiedClusterFile , <str> ) fid . write ( <str> . format ( nClusters + 1 ) ) print <str> . format ( ephysTimeThisRecording ) for cn in allClustersThisTetrode :              fid . write ( <str> . format ( cn ) )  fid . close ( )  db . loc [ indRow , <str> ] = thisISIviolation  if SAVE :      celldatabase . save_hdf ( db , dbPath ) print <str> . format ( dbPath )   