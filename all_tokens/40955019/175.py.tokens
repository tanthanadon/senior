import os from jaratoolbox import celldatabase from jaratoolbox import spikesanalysis from jaratoolbox import settings from jaratoolbox import ephyscore from jaratoolbox import spikesorting from scipy import stats import numpy as np from numpy import inf import pandas reload ( celldatabase ) reload ( spikesorting ) reload ( ephyscore ) STUDY_NAME = <str> SAVE = 1 RECALCULATE_TETRODESTATS = 0 FIND_TETRODES_WITH_NO_SPIKES = 0 animals = [ <str> + s for s in map ( str , [ 15 , 16 , 17 , 18 , 19 , 20 , 21 , 25 , 26 , 29 ] ) ] inforecFolder = <str> dbList = [ ] for animal in animals :      inforecFn = os . path . join ( inforecFolder , <str> . format ( animal ) ) if RECALCULATE_TETRODESTATS :          ci = spikesorting . ClusterInforec ( inforecFn ) ci . process_all_experiments ( recluster = False )  if FIND_TETRODES_WITH_NO_SPIKES :          ci = spikesorting . ClusterInforec ( inforecFn ) ci . find_tetrodes_with_no_spikes ( ) continue  db = celldatabase . generate_cell_database ( inforecFn ) noiseZscore = np . empty ( len ( db ) ) noisePval = np . empty ( len ( db ) ) baseRange = [ - 0.1 , 0 ] responseRange = [ 0 , 0.1 ] for indRow , dbRow in db . iterrows ( ) :          cell = ephyscore . Cell ( dbRow , useModifiedClusters = True ) if <str> in cell . dbRow [ <str> ] :              sessionType = <str>  elif <str> in cell . dbRow [ <str> ] :              sessionType = <str>  elif <str> in cell . dbRow [ <str> ] :              sessionType = <str>  try :              ephysData , bdata = cell . load ( sessionType )  except ValueError :              zScore = 0 pVal = 0  else :              spikeTimes = ephysData [ <str> ] eventOnsetTimes = ephysData [ <str> ] [ <str> ] alignmentRange = [ baseRange [ 0 ] , responseRange [ 1 ] ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , eventOnsetTimes , alignmentRange ) nspkBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) nspkResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) [ zScore , pVal ] = stats . ranksums ( nspkResp , nspkBase )  noiseZscore [ indRow ] = zScore noisePval [ indRow ] = pVal  db [ <str> ] = noiseZscore db [ <str> ] = noisePval pulseZscore = np . empty ( len ( db ) ) pulsePval = np . empty ( len ( db ) ) baseRange = [ - 0.1 , 0 ] responseRange = [ 0 , 0.1 ] for indRow , dbRow in db . iterrows ( ) :          cell = ephyscore . Cell ( dbRow ) if <str> in cell . dbRow [ <str> ] :              sessionType = <str>  elif <str> in cell . dbRow [ <str> ] :              sessionType = <str>  try :              ephysData , bdata = cell . load ( sessionType )  except ( ValueError , IndexError ) :              zScore = 0 pVal = 0  else :              spikeTimes = ephysData [ <str> ] eventOnsetTimes = ephysData [ <str> ] [ <str> ] alignmentRange = [ baseRange [ 0 ] , responseRange [ 1 ] ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , eventOnsetTimes , alignmentRange ) nspkBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) nspkResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) [ zScore , pVal ] = stats . ranksums ( nspkResp , nspkBase )  pulseZscore [ indRow ] = zScore pulsePval [ indRow ] = pVal  db [ <str> ] = pulseZscore db [ <str> ] = pulsePval trainRatio = np . full ( len ( db ) , np . nan ) timeRange = [ - 0.1 , 1 ] baseRange = [ 0 , 0.05 ] responseRange = [ 0.2 , 0.25 ] for indRow , dbRow in db . iterrows ( ) :          cell = ephyscore . Cell ( dbRow ) try :              ephysData , bdata = cell . load ( <str> )  except ( ValueError , IndexError ) :              continue  else :              spikeTimes = ephysData [ <str> ] eventOnsetTimes = ephysData [ <str> ] [ <str> ] eventOnsetTimes = spikesanalysis . minimum_event_onset_diff ( eventOnsetTimes , 0.5 ) ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , eventOnsetTimes , timeRange ) avgSpikesBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) . mean ( ) avgSpikesResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) . mean ( ) ratio = avgSpikesResp / avgSpikesBase  trainRatio [ indRow ] = ratio  db [ <str> ] = trainRatio dbList . append ( db )  masterdb = pandas . concat ( dbList , ignore_index = True ) dbPath = <str> if SAVE :      print <str> . format ( dbPath ) masterdb . to_hdf ( dbPath , <str> )   