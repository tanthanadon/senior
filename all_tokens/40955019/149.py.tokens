import pandas as pd from scipy import signal from scipy import stats import numpy as np from jaratoolbox import celldatabase from jaratoolbox import spikesanalysis from jaratoolbox import behavioranalysis from jaratoolbox import loadopenephys from jaratoolbox import extraplots from jaratoolbox import settings from jaratoolbox import ephyscore import figparams from matplotlib import pyplot as plt import os STUDY_NAME = <str> def index_all_true_before ( arr ) :      if any ( ~ arr ) :          indLastTrue = np . min ( np . where ( ~ arr ) ) - 1  else :          indLastTrue = len ( arr ) - 1  return indLastTrue  def angle_population_vector_zar ( angles ) :      X = np . mean ( np . cos ( angles ) ) Y = np . mean ( np . sin ( angles ) ) r = np . sqrt ( X ** 2 + Y ** 2 ) return r  def rayleigh_test ( angles ) :      if angles . ndim > 1 :          angles = angles . flatten ( )  N = angles . size R = N * angle_population_vector_zar ( angles ) zVal = R ** 2. / N pVal = np . exp ( np . sqrt ( 1. + 4 * N + 4 * ( N ** 2. - R ** 2 ) ) - 1. - 2. * N ) return zVal , pVal  def spiketimes_each_frequency ( spikeTimesFromEventOnset , trialIndexForEachSpike , freqEachTrial ) :      possibleFreq = np . unique ( freqEachTrial ) for freq in possibleFreq :          trialsThisFreq = np . flatnonzero ( freqEachTrial == freq ) spikeTimesThisFreq = spikeTimesFromEventOnset [ np . in1d ( trialIndexForEachSpike , trialsThisFreq ) ] trialIndicesThisFreq = trialIndexForEachSpike [ np . in1d ( trialIndexForEachSpike , trialsThisFreq ) ] yield ( freq , spikeTimesThisFreq , trialIndicesThisFreq )   CASE = 1 SAVE = True significantFreqsArray = np . array ( [ ] ) if CASE == 1 :      dbPath = <str> dataframe = pd . read_hdf ( dbPath , key = <str> ) for indIter , ( indRow , dbRow ) in enumerate ( dataframe . iterrows ( ) ) :          if not <str> in dbRow [ <str> ] :              dataframe . loc [ indRow , <str> ] = np . nan print <str> continue  cell = ephyscore . Cell ( dbRow , useModifiedClusters = True ) try :              ephysData , bdata = cell . load ( <str> )  except ( IndexError , ValueError ) :              failed = True print <str> . format ( indRow ) dataframe . loc [ indRow , <str> ] = np . nan continue  spikeTimes = ephysData [ <str> ] if len ( spikeTimes ) < 100 :              dataframe . loc [ indRow , <str> ] = np . nan print <str> continue  numFreq = len ( np . unique ( bdata [ <str> ] ) ) allFreqVS = np . empty ( numFreq ) allFreqRal = np . empty ( numFreq ) allFreqPval = np . empty ( numFreq ) eventOnsetTimes = ephysData [ <str> ] [ <str> ] eventOnsetTimes = spikesanalysis . minimum_event_onset_diff ( eventOnsetTimes , minEventOnsetDiff = 0.7 ) baseRange = [ - 0.5 , - 0.1 ] responseRange = [ 0.1 , 0.5 ] alignmentRange = [ baseRange [ 0 ] , responseRange [ 1 ] ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , eventOnsetTimes , alignmentRange ) nspkBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) nspkResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) [ zScore , pVal ] = stats . ranksums ( nspkResp , nspkBase ) if pVal > 0.05 :              dataframe . loc [ indRow , <str> ] = np . nan print <str> continue  timeRange = [ 0.1 , 0.5 ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , eventOnsetTimes , timeRange ) freqEachTrial = bdata [ <str> ] for indFreq , ( freq , spiketimes , trialInds ) in enumerate ( spiketimes_each_frequency ( spikeTimesFromEventOnset , trialIndexForEachSpike , freqEachTrial ) ) :              strength , phase = signal . vectorstrength ( spiketimes , 1.0 / freq ) radsPerSec = freq * 2 * np . pi spikeRads = ( spiketimes * radsPerSec ) % ( 2 * np . pi ) ral = np . array ( [ 2 * len ( spiketimes ) * ( strength ** 2 ) ] ) zVal , pVal = rayleigh_test ( spikeRads ) allFreqVS [ indFreq ] = strength allFreqRal [ indFreq ] = ral allFreqPval [ indFreq ] = pVal  possibleFreq = np . unique ( freqEachTrial ) if any ( allFreqPval < 0.05 ) :              sigPvals = np . array ( allFreqPval ) < 0.05 highestSyncInd = index_all_true_before ( sigPvals ) dataframe . loc [ indRow , <str> ] = possibleFreq [ allFreqPval < 0.05 ] . max ( ) dataframe . loc [ indRow , <str> ] = possibleFreq [ highestSyncInd ]  else :              dataframe . loc [ indRow , <str> ] = 0  correctedPval = 0.05 / len ( possibleFreq ) if any ( allFreqPval < correctedPval ) :              dataframe . loc [ indRow , <str> ] = possibleFreq [ allFreqPval < correctedPval ] . max ( ) freqsBelowThresh = allFreqPval < correctedPval freqsBelowThresh = freqsBelowThresh . astype ( int ) if len ( significantFreqsArray ) == 0 :                  significantFreqsArray = freqsBelowThresh  else :                  significantFreqsArray = np . vstack ( ( significantFreqsArray , freqsBelowThresh ) )   else :              dataframe . loc [ indRow , <str> ] = 0   if SAVE :          dataframe . to_hdf ( dbPath , <str> ) print <str> . format ( dbPath )    