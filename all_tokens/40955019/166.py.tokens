import numpy as np from jaratoolbox import celldatabase from jaratoolbox import ephyscore from jaratoolbox import spikesanalysis from matplotlib import pyplot as plt import os import pandas as pd dbPath = <str> database = celldatabase . load_hdf ( dbPath ) goodISI = database . query ( <str> ) goodShape = goodISI . query ( <str> ) goodLaser = goodShape . query ( <str> ) goodNSpikes = goodLaser . query ( <str> ) db = database CASE = 3 if CASE == 0 :      for indIter , ( indRow , dbRow ) in enumerate ( db . iterrows ( ) ) :          cell = ephyscore . Cell ( dbRow , useModifiedClusters = True ) try :              ephysData , bdata = cell . load ( <str> )  except ( IndexError , ValueError ) :              print <str> . format ( indRow )  eventOnsetTimes = ephysData [ <str> ] [ <str> ] spikeTimes = ephysData [ <str> ] cellLatency = dbRow [ <str> ] if not cellLatency > 0 :              print <str> continue  baseRange = [ - 0.1 , - 0.05 ] responseRange = [ cellLatency , cellLatency + 0.05 , 0.1 + cellLatency ] alignmentRange = [ baseRange [ 0 ] , responseRange [ - 1 ] ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , eventOnsetTimes , alignmentRange ) nspkBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) nspkResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) avgResponse = nspkResp . mean ( axis = 0 ) onsetSpikes = avgResponse [ 0 ] sustainedSpikes = avgResponse [ 1 ] onsetRate = onsetSpikes / ( responseRange [ 1 ] - responseRange [ 0 ] ) sustainedRate = sustainedSpikes / ( responseRange [ 2 ] - responseRange [ 1 ] ) baseSpikes = nspkBase . mean ( ) baseRate = baseSpikes / ( baseRange [ 1 ] - baseRange [ 0 ] ) onsetBaseSubtracted = onsetRate - baseRate sustainedBaseSubtracted = sustainedRate - baseRate db . loc [ indRow , <str> ] = onsetRate db . loc [ indRow , <str> ] = sustainedRate db . loc [ indRow , <str> ] = baseRate  celldatabase . save_hdf ( db , <str> )  elif CASE == 1 :      PLOT = 0 SAVE = 1 for indIter , ( indRow , dbRow ) in enumerate ( db . iterrows ( ) ) :          cell = ephyscore . Cell ( dbRow , useModifiedClusters = True ) try :              ephysData , bdata = cell . load ( <str> )  except ( IndexError , ValueError ) :              print <str> . format ( indRow )  eventOnsetTimes = ephysData [ <str> ] [ <str> ] spikeTimes = ephysData [ <str> ] freqEachTrial = bdata [ <str> ] if len ( eventOnsetTimes ) != len ( freqEachTrial ) :              eventOnsetTimes = eventOnsetTimes [ : - 1 ] if len ( eventOnsetTimes ) != len ( freqEachTrial ) :                  print <str> continue   possibleFreq = np . unique ( freqEachTrial ) intensityEachTrial = bdata [ <str> ] cfTrials = freqEachTrial == dbRow [ <str> ] eventsThisFreq = eventOnsetTimes [ cfTrials ] intenThisFreq = intensityEachTrial [ cfTrials ] possibleIntensity = np . unique ( intenThisFreq ) if len ( possibleIntensity ) > 4 :              intenToUse = possibleIntensity [ - 5 : ]  else :              intenToUse = possibleIntensity  highIntenTrials = np . in1d ( intenThisFreq , intenToUse ) eventsThisFreqHighIntensity = eventsThisFreq [ highIntenTrials ] cellLatency = dbRow [ <str> ] if not cellLatency > 0 :              print <str> continue  baseRange = [ - 0.1 , - 0.05 ] responseRange = [ cellLatency , cellLatency + 0.05 , 0.1 + cellLatency ] alignmentRange = [ baseRange [ 0 ] , responseRange [ - 1 ] ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , eventsThisFreqHighIntensity , alignmentRange ) nspkBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) nspkResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) avgResponse = nspkResp . mean ( axis = 0 ) onsetSpikes = avgResponse [ 0 ] sustainedSpikes = avgResponse [ 1 ] onsetRate = onsetSpikes / ( responseRange [ 1 ] - responseRange [ 0 ] ) sustainedRate = sustainedSpikes / ( responseRange [ 2 ] - responseRange [ 1 ] ) baseSpikes = nspkBase . mean ( ) baseRate = baseSpikes / ( baseRange [ 1 ] - baseRange [ 0 ] ) onsetBaseSubtracted = onsetRate - baseRate sustainedBaseSubtracted = sustainedRate - baseRate db . loc [ indRow , <str> ] = onsetRate db . loc [ indRow , <str> ] = sustainedRate db . loc [ indRow , <str> ] = baseRate if PLOT :              saveDir = <str> title = <str> . format ( dbRow [ <str> ] , dbRow [ <str> ] , dbRow [ <str> ] , int ( dbRow [ <str> ] ) , int ( dbRow [ <str> ] ) ) plt . clf ( ) ax = plt . subplot ( 111 ) ax . plot ( spikeTimesFromEventOnset , trialIndexForEachSpike , <str> ) ax . axvline ( x = 0 , color = <str> ) ax . axvline ( x = responseRange [ 0 ] , color = <str> ) ax . axvline ( x = responseRange [ 1 ] , color = <str> ) ax . axvline ( x = responseRange [ 2 ] , color = <str> ) ax . set_xlabel ( <str> ) ax . set_xlim ( alignmentRange ) plt . tight_layout ( ) plt . savefig ( os . path . join ( saveDir , title ) )   if SAVE :          celldatabase . save_hdf ( db , dbPath )   elif CASE == 2 :      plt . clf ( ) ax0 = plt . subplot ( 111 ) mono = [ ] maxSpikes = [ ] goodFit = db . query ( <str> ) goodFit [ <str> ] = np . sqrt ( goodFit [ <str> ] * goodFit [ <str> ] ) goodFitToUse = goodFit . query ( <str> ) goodFitToUseNSpikes = goodFitToUse . query ( <str> ) for indIter , ( indRow , dbRow ) in enumerate ( goodFitToUseNSpikes . iterrows ( ) ) :          print indRow failed = False cell = ephyscore . Cell ( dbRow , useModifiedClusters = True ) try :              ephysData , bdata = cell . load ( <str> )  except ( IndexError , ValueError ) :              failed = True print <str> . format ( indRow )  eventOnsetTimes = ephysData [ <str> ] [ <str> ] spikeTimes = ephysData [ <str> ] freqEachTrial = bdata [ <str> ] if len ( eventOnsetTimes ) != len ( freqEachTrial ) :              eventOnsetTimes = eventOnsetTimes [ : - 1 ] if len ( eventOnsetTimes ) != len ( freqEachTrial ) :                  continue   possibleFreq = np . unique ( freqEachTrial ) intensityEachTrial = bdata [ <str> ] possibleIntensity = np . unique ( intensityEachTrial ) cfTrials = freqEachTrial == dbRow [ <str> ] eventsThisFreq = eventOnsetTimes [ cfTrials ] intenThisFreq = intensityEachTrial [ cfTrials ] baseRange = [ - 0.1 , 0 ] responseRange = [ 0 , 0.1 ] alignmentRange = [ baseRange [ 0 ] , responseRange [ 1 ] ] meanSpikesAllInten = np . empty ( len ( possibleIntensity ) ) maxSpikesAllInten = np . empty ( len ( possibleIntensity ) ) for indInten , inten in enumerate ( possibleIntensity ) :              trialsThisIntensity = intenThisFreq == inten eventsThisCombo = eventsThisFreq [ trialsThisIntensity ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , eventsThisCombo , alignmentRange ) nspkBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) nspkResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) spikesThisInten = nspkResp [ : , 0 ] try :                  meanSpikesThisInten = np . mean ( spikesThisInten ) maxSpikesThisInten = np . max ( spikesThisInten )  except ValueError :                  meanSpikesThisInten = 0 maxSpikesThisInten = 0  meanSpikesAllInten [ indInten ] = meanSpikesThisInten maxSpikesAllInten [ indInten ] = maxSpikesThisInten  overallMaxSpikes = np . max ( maxSpikesAllInten ) maxSpikes . append ( overallMaxSpikes ) if len ( meanSpikesAllInten ) > 10 :              ax0 . plot ( meanSpikesAllInten / max ( meanSpikesAllInten ) . astype ( float ) , <str> , alpha = 0.3 )   ax0 . set_xticks ( range ( len ( possibleIntensity ) ) ) ax0 . set_xticklabels ( possibleIntensity ) ax0 . set_xlabel ( <str> ) ax0 . set_ylabel ( <str> ) plt . show ( )  elif CASE == 3 :      plt . clf ( ) ax0 = plt . subplot ( 111 ) mono = [ ] maxSpikes = [ ] goodFit = db . query ( <str> ) goodFit [ <str> ] = np . sqrt ( goodFit [ <str> ] * goodFit [ <str> ] ) goodFitToUse = goodFit . query ( <str> ) goodFitToUseNSpikes = goodFitToUse . query ( <str> ) for indIter , ( indRow , dbRow ) in enumerate ( goodFitToUseNSpikes . iterrows ( ) ) :          print indRow failed = False cell = ephyscore . Cell ( dbRow , useModifiedClusters = True ) try :              ephysData , bdata = cell . load ( <str> )  except ( IndexError , ValueError ) :              failed = True print <str> . format ( indRow )  eventOnsetTimes = ephysData [ <str> ] [ <str> ] spikeTimes = ephysData [ <str> ] freqEachTrial = bdata [ <str> ] if len ( eventOnsetTimes ) != len ( freqEachTrial ) :              eventOnsetTimes = eventOnsetTimes [ : - 1 ] if len ( eventOnsetTimes ) != len ( freqEachTrial ) :                  continue   possibleFreq = np . unique ( freqEachTrial ) intensityEachTrial = bdata [ <str> ] possibleIntensity = np . unique ( intensityEachTrial ) cellLatency = dbRow [ <str> ] if not cellLatency > 0 :              print <str> continue  baseRange = [ - 0.1 , - 0.05 ] responseRange = [ cellLatency , cellLatency + 0.1 ] alignmentRange = [ baseRange [ 0 ] , responseRange [ 1 ] ] allIntenBase = np . array ( [ ] ) allIntenResp = np . empty ( ( len ( possibleIntensity ) , len ( possibleFreq ) ) ) allIntenRespMedian = np . empty ( ( len ( possibleIntensity ) , len ( possibleFreq ) ) ) for indinten , inten in enumerate ( possibleIntensity ) :              spks = np . array ( [ ] ) freqs = np . array ( [ ] ) base = np . array ( [ ] ) for indfreq , freq in enumerate ( possibleFreq ) :                  selectinds = np . flatnonzero ( ( freqEachTrial == freq ) & ( intensityEachTrial == inten ) ) selectedOnsetTimes = eventOnsetTimes [ selectinds ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimes , selectedOnsetTimes , alignmentRange ) nspkBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) nspkResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) base = np . concatenate ( [ base , nspkBase . ravel ( ) ] ) spks = np . concatenate ( [ spks , nspkResp . ravel ( ) ] ) freqs = np . concatenate ( [ freqs , np . ones ( len ( nspkResp . ravel ( ) ) ) * freq ] ) allIntenBase = np . concatenate ( [ allIntenBase , nspkBase . ravel ( ) ] ) allIntenResp [ indinten , indfreq ] = np . mean ( nspkResp ) allIntenRespMedian [ indinten , indfreq ] = np . median ( nspkResp )   maxSpikes = np . max ( allIntenResp . ravel ( ) ) baseSpikes = np . mean ( allIntenBase . ravel ( ) ) timeRangeResp = responseRange [ 1 ] - responseRange [ 0 ] timeRangeBase = baseRange [ 1 ] - baseRange [ 0 ] maxFr = maxSpikes / timeRangeResp baseFr = baseSpikes / timeRangeBase db . loc [ indRow , <str> ] = maxFr db . loc [ indRow , <str> ] = baseFr    