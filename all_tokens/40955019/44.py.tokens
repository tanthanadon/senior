import os import sys import numpy as np import pandas as pd import importlib from jaratoolbox import settings import figparams from jaratoolbox import loadbehavior from jaratoolbox import loadopenephys from jaratoolbox import spikesanalysis from jaratoolbox import behavioranalysis import scipy . stats as stats import pdb FIGNAME = <str> outputDir = os . path . join ( settings . FIGURES_DATA_PATH , figparams . STUDY_NAME , FIGNAME ) paradigm = <str> scriptFullPath = os . path . realpath ( __file__ ) EPHYS_SAMPLING_RATE = 30000.0 soundTriggerChannel = 0 baseRange = [ - 0.1 , 0 ] responseRange = [ 0 , 0.1 ] timeRange = [ - 0.2 , 0.2 ] qualityList = [ 1 , 6 ] ISIcutoff = 0.02 numOfFreqs = 6 maxNumOfTrials = 300 BEHAVIOR_PATH = settings . BEHAVIOR_PATH_REMOTE EPHYS_PATH = settings . EPHYS_PATH_REMOTE psychometricFilePath = os . path . join ( settings . FIGURES_DATA_PATH , figparams . STUDY_NAME ) psychometricFileName = <str> psychometricFullPath = os . path . join ( psychometricFilePath , psychometricFileName ) allcells_psychometric = pd . read_hdf ( psychometricFullPath , key = <str> ) goodcells_psychometric = ( allcells_psychometric . cellQuality . isin ( qualityList ) ) & ( allcells_psychometric . ISI <= ISIcutoff ) cellInStr = ( allcells_psychometric . cellInStr == 1 ) keepAfterDupTest = allcells_psychometric . keep_after_dup_test cellSelector = goodcells_psychometric & cellInStr & keepAfterDupTest cellsToPlot = allcells_psychometric [ cellSelector ] bestFreqEachCell = np . zeros ( len ( cellsToPlot ) ) maxZscoreEachCell = np . zeros ( len ( cellsToPlot ) ) pValSoundResponseEachCell = np . ones ( len ( cellsToPlot ) ) maxZresponseIndEachCell = np . zeros ( len ( cellsToPlot ) ) freqSelectivityEachCell = np . ones ( len ( cellsToPlot ) ) zScoresEachFreqEachCell = np . zeros ( ( len ( cellsToPlot ) , numOfFreqs ) ) pValEachFreqEachCell = np . ones ( ( len ( cellsToPlot ) , numOfFreqs ) ) responseEachFreqEachCell = np . ma . masked_array ( np . empty ( ( len ( cellsToPlot ) , maxNumOfTrials , numOfFreqs ) ) , mask = np . zeros ( ( len ( cellsToPlot ) , maxNumOfTrials , numOfFreqs ) ) ) baselineEachFreqEachCell = np . ma . masked_array ( np . empty ( ( len ( cellsToPlot ) , maxNumOfTrials , numOfFreqs ) ) , mask = np . zeros ( ( len ( cellsToPlot ) , maxNumOfTrials , numOfFreqs ) ) ) responseIndEachFreqEachCell = np . zeros ( ( len ( cellsToPlot ) , numOfFreqs ) ) cellsToPlot = cellsToPlot . reset_index ( ) for ind , cell in cellsToPlot . iterrows ( ) :      print <str> , ind animalName = cell [ <str> ] allcellsFileName = <str> + animalName + <str> sys . path . append ( settings . ALLCELLS_PATH ) allcells = importlib . import_module ( allcellsFileName ) behavSession = cell [ <str> ] tetrode = cell [ <str> ] cluster = cell [ <str> ] cellIndex = allcells . cellDB . findcell ( animalName , behavSession , tetrode , cluster ) oneCell = allcells . cellDB [ cellIndex ] ephysSession = oneCell . ephysSession behavFileName = <str> . format ( animalName , paradigm , behavSession ) behavFile = os . path . join ( BEHAVIOR_PATH , animalName , behavFileName ) bdata = loadbehavior . BehaviorData ( behavFile , readmode = <str> ) fullEventFilename = os . path . join ( EPHYS_PATH , animalName , ephysSession , <str> ) eventData = loadopenephys . Events ( fullEventFilename ) eventData . timestamps = np . array ( eventData . timestamps ) / EPHYS_SAMPLING_RATE spikeFilename = os . path . join ( EPHYS_PATH , oneCell . animalName , oneCell . ephysSession , <str> . format ( oneCell . tetrode ) ) spikeData = loadopenephys . DataSpikes ( spikeFilename ) spikeData . timestamps = spikeData . timestamps / EPHYS_SAMPLING_RATE clustersDir = os . path . join ( EPHYS_PATH , oneCell . animalName , oneCell . ephysSession ) + <str> clusterFilename = os . path . join ( clustersDir , <str> . format ( oneCell . tetrode ) ) clusters = np . fromfile ( clusterFilename , dtype = <str> , sep = <str> ) [ 1 : ] spikeData . timestamps = spikeData . timestamps [ clusters == oneCell . cluster ] spikeData . samples = spikeData . samples [ clusters == oneCell . cluster , : , : ] spikeData . samples = spikeData . samples . astype ( float ) - 2 ** 15 spikeData . samples = ( 1000.0 / spikeData . gain [ 0 , 0 ] ) * spikeData . samples spikeTimestamps = spikeData . timestamps eventOnsetTimes = np . array ( eventData . timestamps ) soundOnsetEvents = ( eventData . eventID == 1 ) & ( eventData . eventChannel == soundTriggerChannel ) soundOnsetTimes = eventOnsetTimes [ soundOnsetEvents ] soundOnsetTimeBehav = bdata [ <str> ] missingTrials = behavioranalysis . find_missing_trials ( soundOnsetTimes , soundOnsetTimeBehav ) bdata . remove_trials ( missingTrials ) print <str> , ind possibleFreq = np . unique ( bdata [ <str> ] ) numFreqs = len ( possibleFreq ) zScores = [ ] pVals = [ ] responseEachFreq = [ ] baselineEachFreq = [ ] responseInds = [ ] for freq in possibleFreq :          oneFreqTrials = ( bdata [ <str> ] == freq ) & bdata [ <str> ] . astype ( <str> ) oneFreqSoundOnsetTimes = soundOnsetTimes [ oneFreqTrials ] ( spikeTimesFromEventOnset , trialIndexForEachSpike , indexLimitsEachTrial ) = spikesanalysis . eventlocked_spiketimes ( spikeTimestamps , oneFreqSoundOnsetTimes , timeRange ) nspkBase = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , baseRange ) nspkResp = spikesanalysis . spiketimes_to_spikecounts ( spikeTimesFromEventOnset , indexLimitsEachTrial , responseRange ) print nspkBase . shape , nspkResp . shape responseIndex = ( np . mean ( nspkResp ) - np . mean ( nspkBase ) ) / ( np . mean ( nspkResp ) + np . mean ( nspkBase ) ) responseInds . append ( responseIndex ) responseEachFreq . append ( np . squeeze ( nspkResp ) ) baselineEachFreq . append ( np . squeeze ( nspkBase ) ) print <str> , np . mean ( nspkBase ) , np . mean ( nspkResp ) , <str> , responseIndex zStat , pValue = stats . ranksums ( nspkResp , nspkBase ) print zStat , pValue zScores . append ( zStat ) pVals . append ( pValue )  indMaxZ = np . argmax ( np . abs ( zScores ) ) maxZscore = zScores [ indMaxZ ] bestFreq = possibleFreq [ indMaxZ ] pVal = pVals [ indMaxZ ] responseIndMaxZ = responseInds [ indMaxZ ] bestFreqEachCell [ ind ] = bestFreq maxZscoreEachCell [ ind ] = maxZscore maxZresponseIndEachCell [ ind ] = responseIndMaxZ pValSoundResponseEachCell [ ind ] = pVal zScoresEachFreqEachCell [ ind , : ] = zScores pValEachFreqEachCell [ ind , : ] = pVals responseIndEachFreqEachCell [ ind , : ] = responseInds for indf in range ( numOfFreqs ) :          numOfTrials = len ( responseEachFreq [ indf ] ) responseEachFreqEachCell [ ind , : numOfTrials , indf ] = responseEachFreq [ indf ] responseEachFreqEachCell . mask [ ind , numOfTrials : , indf ] = True baselineEachFreqEachCell [ ind , : numOfTrials , indf ] = baselineEachFreq [ indf ] baselineEachFreqEachCell . mask [ ind , numOfTrials : , indf ] = True  statistics , freqSelectivityEachCell [ ind ] = stats . f_oneway ( * responseEachFreq )  if not os . path . exists ( outputDir ) :      os . mkdir ( outputDir )  outputFile = <str> outputFullPath = os . path . join ( outputDir , outputFile ) np . savez ( outputFullPath , bestFreqEachCell = bestFreqEachCell , maxZscoreEachCell = maxZscoreEachCell , pValSoundResponseEachCell = pValSoundResponseEachCell , maxZresponseIndEachCell = maxZresponseIndEachCell , freqSelectivityEachCell = freqSelectivityEachCell , zScoresEachFreqEachCell = zScoresEachFreqEachCell , pValEachFreqEachCell = pValEachFreqEachCell , responseIndEachFreqEachCell = responseIndEachFreqEachCell , cellSelectorBoolArray = cellSelector , baselineWindow = baseRange , soundWindow = responseRange , paradigm = paradigm , script = scriptFullPath ) responseEachFreqEachCellFile = <str> baselineEachFreqEachCellFile = <str> responseEachFreqEachCell . dump ( os . path . join ( outputDir , responseEachFreqEachCellFile ) ) baselineEachFreqEachCell . dump ( os . path . join ( outputDir , baselineEachFreqEachCellFile ) )  