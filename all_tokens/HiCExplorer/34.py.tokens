import warnings warnings . simplefilter ( action = <str> , category = RuntimeWarning ) warnings . simplefilter ( action = <str> , category = PendingDeprecationWarning ) import os . path import logging import argparse import json from collections import OrderedDict from hicmatrix import HiCMatrix as hm from hicexplorer . utilities import enlarge_bins from scipy import sparse import numpy as np import multiprocessing from hicexplorer . _version import __version__ from hicexplorer . utilities import toString , toBytes , check_chrom_str_bytes from past . builtins import zip from past . builtins import map log = logging . getLogger ( __name__ ) hic_ma = None def parse_arguments ( args = None ) :      parser = argparse . ArgumentParser ( formatter_class = argparse . RawDescriptionHelpFormatter , conflict_handler = <str> , description = ) parserRequired = parser . add_argument_group ( <str> ) parserRequired . add_argument ( <str> , <str> , help = <str> , required = True ) parserRequired . add_argument ( <str> , help = <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> <str> , required = True ) parserRequired . add_argument ( <str> , help = <str> <str> <str> <str> , type = str , default = <str> , choices = [ <str> , <str> , <str> ] , required = True ) parserOpt = parser . add_argument_group ( <str> ) parserOpt . add_argument ( <str> , help = <str> <str> <str> , metavar = <str> , type = int ) parserOpt . add_argument ( <str> , help = <str> <str> <str> , metavar = <str> , type = int ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> <str> , metavar = <str> , type = int ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> , required = False ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> <str> <str> <str> , type = float , default = 0.01 ) parserOpt . add_argument ( <str> , help = <str> <str> <str> <str> <str> <str> , type = float , default = 0.01 ) parserOpt . add_argument ( <str> , help = <str> <str> , type = int ) parserOpt . add_argument ( <str> , help = <str> <str> <str> , nargs = <str> ) parserOpt . add_argument ( <str> , <str> , help = <str> , type = int , default = 1 ) parserOpt . add_argument ( <str> , <str> , action = <str> , help = <str> ) parserOpt . add_argument ( <str> , action = <str> , version = <str> . format ( __version__ ) ) return parser  def compute_matrix_wrapper ( args ) :      return compute_matrix ( * args )  def get_cut_weight_by_bin_id ( matrix , cut , depth , return_mean = False ) :      if cut < 0 or cut > matrix . shape [ 0 ] :          return None  start = max ( 0 , cut - depth ) end = min ( matrix . shape [ 0 ] , cut + depth ) if return_mean is True :          return matrix [ start : cut , cut : end ] . mean ( )  else :          return matrix [ start : cut , cut : end ] . todense ( ) . A1   def get_idx_of_bins_at_given_distance ( hic_matrix , idx , window_len ) :      chrom , cut_start , cut_end , _ = hic_matrix . getBinPos ( idx ) left_start = max ( 0 , cut_start - window_len ) left_idx = hic_matrix . getRegionBinRange ( chrom , left_start , left_start + 1 ) [ 0 ] chromosome_size = hic_matrix . get_chromosome_sizes ( ) chrom = check_chrom_str_bytes ( chromosome_size , chrom ) chr_end_pos = chromosome_size [ chrom ] right_end = min ( chr_end_pos , cut_end + window_len ) - 1 right_idx = hic_matrix . getRegionBinRange ( chrom , right_end , right_end ) [ 0 ] return left_idx , right_idx  def get_cut_weight ( hic_matrix , cut , window_len , return_mean = False ) :      if cut < 0 or cut > hic_matrix . matrix . shape [ 0 ] :          return None  try :          left_idx , right_idx = get_idx_of_bins_at_given_distance ( hic_matrix , cut , window_len )  except TypeError :          return None  if return_mean is True :          if hic_matrix . matrix [ left_idx : cut , cut : right_idx ] . nnz == 0 :              return 0  else :              return hic_matrix . matrix [ left_idx : cut , cut : right_idx ] . todense ( ) . mean ( )   else :          return hic_matrix . matrix [ left_idx : cut , cut : right_idx ] . todense ( ) . A1   def get_triangle ( hic_matrix , cut , window_len , return_mean = False ) :      if cut < 0 or cut > hic_matrix . matrix . shape [ 0 ] :          return None  left_idx , right_idx = get_idx_of_bins_at_given_distance ( hic_matrix , cut , window_len ) def remove_lower_triangle ( matrix ) :          return matrix [ np . triu_indices_from ( matrix ) ] . A1  edges_left = remove_lower_triangle ( hic_matrix . matrix [ left_idx : cut , : ] [ : , left_idx : cut ] . todense ( ) ) edges_right = remove_lower_triangle ( hic_matrix . matrix [ cut : right_idx , : ] [ : , cut : right_idx ] . todense ( ) ) return np . concatenate ( [ edges_left , edges_right ] )  def get_incremental_step_size ( min_win_size , max_win_size , start_step_len ) :      incremental_step = [ ] step = - 1 while 1 :          step += 1 inc_step = min_win_size + int ( start_step_len * ( step ** 1.5 ) ) if step > 1 and inc_step == incremental_step [ - 1 ] :              continue  if inc_step > max_win_size :              break  incremental_step . append ( inc_step )  return incremental_step  def compute_matrix ( bins_list , min_win_size = 8 , max_win_size = 50 , step_len = 2 ) :      global hic_ma positions_array = [ ] cond_matrix = [ ] incremental_step = get_incremental_step_size ( min_win_size , max_win_size , step_len ) for cut in bins_list :          chrom , chr_start , chr_end , _ = hic_ma . cut_intervals [ cut ] mult_matrix = [ get_cut_weight ( hic_ma , cut , depth , return_mean = True ) for depth in incremental_step ] if any ( x is None or np . isnan ( x ) for x in mult_matrix ) :              continue  cond_matrix . append ( mult_matrix ) positions_array . append ( ( chrom , chr_start , chr_end ) )  chrom , chr_start , chr_end = zip ( * positions_array ) cond_matrix = np . vstack ( cond_matrix ) return chrom , chr_start , chr_end , cond_matrix  class HicFindTads ( object ) :      def __init__ ( self , matrix , num_processors = 1 , max_depth = None , min_depth = None , step = None , delta = 0.01 , min_boundary_distance = None , use_zscore = True , p_correct_for_multiple_testing = <str> , p_threshold_comparisons = 0.01 , pChromosomes = None ) :          self . set_matrix ( matrix , pChromosomes ) if max_depth is not None and min_depth is not None and max_depth <= min_depth :              log . error ( <str> ) exit ( )  self . num_processors = num_processors self . max_depth = max_depth self . min_depth = min_depth self . step = step self . delta = delta self . min_boundary_distance = min_boundary_distance self . use_zscore = use_zscore self . binsize = self . hic_ma . getBinSize ( ) self . bedgraph_matrix = None self . boundaries = None self . set_variables ( ) self . correct_for_multiple_testing = p_correct_for_multiple_testing self . threshold_comparisons = p_threshold_comparisons  def set_matrix ( self , pMatrix , pChromosomes ) :          if isinstance ( pMatrix , str ) :              self . hic_ma = hm . hiCMatrix ( pMatrix )  else :              self . hic_ma = pMatrix  if pChromosomes is not None :              valid_chromosomes = [ ] invalid_chromosomes = [ ] log . debug ( <str> . format ( pChromosomes ) ) log . debug ( <str> . format ( self . hic_ma . chrBinBoundaries ) ) pChromosomes = toBytes ( pChromosomes ) for chrom in toString ( pChromosomes ) :                  if chrom in self . hic_ma . chrBinBoundaries :                      valid_chromosomes . append ( chrom )  else :                      invalid_chromosomes . append ( chrom )   if len ( invalid_chromosomes ) > 0 :                  log . warning ( <str> <str> ) log . warning ( <str> . join ( invalid_chromosomes ) )  self . hic_ma . reorderChromosomes ( valid_chromosomes )   def set_variables ( self ) :          if self . max_depth is None :              if self . binsize < 1000 :                  self . max_depth = self . binsize * 60  elif 1000 <= self . binsize < 20000 :                  self . max_depth = self . binsize * 40  else :                  self . max_depth = self . binsize * 10   elif self . max_depth < self . binsize * 5 :              log . error ( <str> ) exit ( 1 )  if self . min_depth is None :              if self . binsize < 1000 :                  self . min_depth = self . binsize * 30  elif 1000 <= self . binsize < 20000 :                  self . min_depth = self . binsize * 10  else :                  self . min_depth = self . binsize * 5   elif self . min_depth < self . binsize * 3 :              log . error ( <str> ) exit ( 1 )  if self . step is None :              if self . binsize < 1000 :                  self . step = self . binsize * 4  else :                  self . step = self . binsize * 2   elif self . step < self . binsize :              log . error ( <str> ) exit ( 1 )  log . debug ( <str> . format ( self . max_depth ) ) log . debug ( <str> . format ( self . min_depth ) ) log . debug ( <str> . format ( self . step ) ) log . debug ( <str> . format ( self . binsize ) )  @ staticmethod def peakdetect ( y_axis , x_axis = None , lookahead = 3 , delta = 0 , chrom = None ) :          max_peaks = [ ] min_peaks = [ ] dump = [ ] if x_axis is None :              x_axis = np . arange ( len ( y_axis ) )  if len ( y_axis ) != len ( x_axis ) :              raise ValueError ( <str> )  if not ( np . isscalar ( delta ) and delta >= 0 ) :              raise ValueError ( <str> )  min_y , max_y = np . Inf , - np . Inf max_pos , min_pos = None , None search_for = None prev_chrom = None for index , ( x , y ) in enumerate ( zip ( x_axis [ : - lookahead ] , y_axis [ : - lookahead ] ) ) :              assert - np . inf < y < np . inf , <str> . format ( index ) if prev_chrom is None :                  prev_chrom = chrom [ index ]  if prev_chrom != chrom [ index ] :                  min_y , max_y = np . Inf , - np . Inf max_pos , min_pos = None , None search_for = None  prev_chrom = chrom [ index ] if y > max_y :                  max_y = y max_pos = x  if y < min_y :                  min_y = y min_pos = x  if y < max_y - delta and max_y != np . Inf and search_for != <str> :                  if y_axis [ index : index + lookahead ] . max ( ) < max_y :                      max_peaks . append ( [ max_pos , max_y ] ) dump . append ( True ) max_y = y min_y = y min_pos = x search_for = <str> continue   if y > min_y + delta and min_y != - np . Inf and search_for != <str> :                  if y_axis [ index : index + lookahead ] . min ( ) > min_y :                      min_peaks . append ( [ min_pos , min_y ] ) dump . append ( False ) min_y = y max_y = y max_pos = x search_for = <str>    try :              if dump [ 0 ] :                  max_peaks . pop ( 0 )  else :                  min_peaks . pop ( 0 )  del dump  except IndexError :              pass  return [ max_peaks , min_peaks ]  @ staticmethod def delta_wrt_window ( min_idx_list , matrix_avg , chrom , window_len = 10 ) :          unique_chroms , chr_start_idx = np . unique ( chrom , return_index = True ) chr_start_idx = np . concatenate ( [ chr_start_idx , [ len ( chrom ) - 1 ] ] ) chr_start_idx = np . sort ( chr_start_idx ) chrom_ranges = [ ( chr_start_idx [ x ] , chr_start_idx [ x + 1 ] ) for x in range ( len ( chr_start_idx ) - 1 ) ] delta_to_mean = { } for min_idx in min_idx_list :              close_to_chrom_border = True for start_range , end_range in chrom_ranges :                  if start_range < min_idx < end_range :                      if min_idx - window_len >= start_range and min_idx + window_len < end_range :                          close_to_chrom_border = False continue    if close_to_chrom_border is True :                  delta_to_mean [ min_idx ] = np . nan  else :                  local_tad_score = np . concatenate ( [ matrix_avg [ min_idx - window_len : min_idx + 3 ] , matrix_avg [ min_idx + 4 : min_idx + window_len ] ] ) delta_to_mean [ min_idx ] = local_tad_score . mean ( ) - matrix_avg [ min_idx ]   return delta_to_mean  @ staticmethod def find_consensus_minima ( tad_score_matrix , lookahead = 3 , chrom = None ) :          tad_score_matrix_avg = tad_score_matrix . mean ( axis = 1 ) _max , _min = HicFindTads . peakdetect ( tad_score_matrix_avg , lookahead = lookahead , chrom = chrom ) if _min :              min_idx , _ = zip ( * _min )  else :              min_idx = [ ]  delta_to_mean = HicFindTads . delta_wrt_window ( min_idx , tad_score_matrix_avg , chrom ) return min_idx , delta_to_mean  def hierarchical_clustering ( self , boundary_list , clusters_cutoff = [ ] ) :          if clusters_cutoff :              clusters_cutoff = np . sort ( np . unique ( clusters_cutoff ) ) [ : : - 1 ]  chrom , start , value = zip ( * boundary_list ) unique_chr , indices = np . unique ( chrom , return_index = True ) indices = indices [ 1 : ] start_per_chr = np . split ( start , indices ) value_per_chr = np . split ( value , indices ) z_value = { } def get_domain_positions ( boundary_position ) :              start_ = None domain_list = [ ] for position in boundary_position :                  if start_ is None :                      start_ = position continue  domain_list . append ( ( start_ , position ) ) start_ = position  return domain_list  def find_in_clusters ( clusters_ , search_id ) :              for set_idx , set_of_ids in enumerate ( clusters_ ) :                  if search_id in set_of_ids :                      return set_idx    def cluster_to_regions ( clusters_ , chrom_name ) :              start_list = [ ] end_list = [ ] for set_ in clusters_ :                  if len ( set_ ) == 0 :                      continue  start_list . append ( domains [ min ( set_ ) ] [ 0 ] ) end_list . append ( domains [ max ( set_ ) ] [ 1 ] )  start_list = np . array ( start_list ) end_list = np . array ( end_list ) order = np . argsort ( start_list ) return zip ( [ chrom_name ] * len ( order ) , start_list [ order ] , end_list [ order ] )  return_clusters = { } for chrom_idx , chrom_name in enumerate ( unique_chr ) :              z_value [ chrom_name ] = [ ] return_clusters [ chrom_name ] = [ ] clust_cutoff = clusters_cutoff [ : ] domains = get_domain_positions ( start_per_chr [ chrom_idx ] ) clusters = [ { x } for x in range ( len ( domains ) ) ] cluster_x = [ int ( d_start + float ( d_end - d_start ) / 2 ) for d_start , d_end in domains ] assert len ( domains ) == len ( value_per_chr [ chrom_idx ] ) - 1 , <str> values = value_per_chr [ chrom_idx ] [ 1 : - 1 ] order = np . argsort ( values ) [ : : - 1 ] for idx , order_idx in enumerate ( order ) :                  if len ( clust_cutoff ) and idx + 1 < len ( order ) and values [ order_idx ] >= clust_cutoff [ 0 ] > values [ order [ idx + 1 ] ] :                      clust_cutoff = clust_cutoff [ 1 : ] return_clusters [ chrom_name ] . append ( cluster_to_regions ( clusters , chrom_name ) )  left = find_in_clusters ( clusters , order_idx ) right = find_in_clusters ( clusters , order_idx + 1 ) z_value [ chrom_name ] . append ( ( left , right , values [ order_idx ] , len ( clusters [ left ] ) + len ( clusters [ right ] ) , cluster_x [ left ] , cluster_x [ right ] ) ) gen_dist = int ( float ( abs ( cluster_x [ left ] - cluster_x [ right ] ) ) / 2 ) cluster_x . append ( min ( cluster_x [ left ] , cluster_x [ right ] ) + gen_dist ) clusters . append ( clusters [ left ] . union ( clusters [ right ] ) ) clusters [ left ] = set ( ) clusters [ right ] = set ( )   ret_ = { } for idx , cutoff in enumerate ( clusters_cutoff ) :              cutoff = str ( cutoff ) ret_ [ cutoff ] = [ ] for chr_name in return_clusters :                  try :                      ret_ [ cutoff ] . extend ( return_clusters [ chr_name ] [ idx ] )  except IndexError :                      pass    return z_value , ret_  def save_linkage ( Z , file_name ) :          try :              file_h = open ( file_name , <str> )  except IOError :              log . error ( <str> . format ( file_name ) ) return  count = 0 for chrom , values in Z . items ( ) :              for id_a , id_b , distance , num_clusters , pos_a , pos_b in values :                  count += 1 file_h . write ( <str> <str> . format ( chrom , int ( pos_a ) , int ( pos_b ) , count , distance , id_a , id_b , num_clusters ) )    def get_domains ( boundary_list ) :          prev_start = None prev_chrom = boundary_list [ 0 ] [ 0 ] domain_list = [ ] for chrom , start , value in boundary_list :              if start is None :                  prev_start = start prev_chrom = chrom continue  if prev_chrom != chrom :                  prev_chrom = chrom prev_start = None continue  domain_list . append ( ( chrom , prev_start , start , value ) ) prev_start = start prev_chrom = chrom  return domain_list  def save_bedgraph_matrix ( self , outfile ) :          params = OrderedDict ( ) params [ <str> ] = self . step params [ <str> ] = self . min_depth params [ <str> ] = self . max_depth params [ <str> ] = self . binsize params_str = json . dumps ( params , separators = ( <str> , <str> ) ) with open ( outfile , <str> ) as f :              f . write ( <str> + params_str + <str> ) for idx in range ( len ( self . bedgraph_matrix [ <str> ] ) ) :                  matrix_values = <str> . join ( np . char . mod ( <str> , self . bedgraph_matrix [ <str> ] [ idx , : ] ) ) f . write ( <str> . format ( toString ( self . bedgraph_matrix [ <str> ] [ idx ] ) , toString ( self . bedgraph_matrix [ <str> ] [ idx ] ) , toString ( self . bedgraph_matrix [ <str> ] [ idx ] ) , toString ( matrix_values ) ) )    def save_clusters ( clusters , file_prefix ) :          for cutoff , intervals in clusters . items ( ) :              fileh = open ( <str> . format ( file_prefix , cutoff ) , <str> ) for chrom , start , end in intervals :                  fileh . write ( <str> . format ( chrom , start , end ) )    def save_domains_and_boundaries ( self , prefix ) :          chrom = self . bedgraph_matrix [ <str> ] chr_start = self . bedgraph_matrix [ <str> ] chr_end = self . bedgraph_matrix [ <str> ] matrix = self . bedgraph_matrix [ <str> ] min_idx = self . boundaries [ <str> ] delta_of_min = self . boundaries [ <str> ] pvalue_of_min = self . boundaries [ <str> ] unique_chroms , chr_start_idx = np . unique ( chrom , return_index = True ) if len ( unique_chroms ) == 1 :              chr_start_idx = [ 0 ] chr_end_idx = [ len ( chrom ) - 1 ]  else :              chr_end_idx = chr_start_idx chr_end_idx [ chr_end_idx == 0 ] = len ( chrom ) chr_end_idx -= 1  min_idx = np . sort ( np . concatenate ( [ chr_start_idx , chr_end_idx , min_idx ] ) ) mean_mat_all = matrix . mean ( axis = 1 ) filtered_min_idx = [ ] for idx in min_idx :              if idx not in delta_of_min :                  delta_of_min [ idx ] = np . nan  if self . correct_for_multiple_testing == <str> :                  if delta_of_min [ idx ] >= self . delta and idx in pvalue_of_min and pvalue_of_min [ idx ] <= self . pvalueFDR :                      filtered_min_idx += [ idx ]   elif self . correct_for_multiple_testing == <str> :                  if delta_of_min [ idx ] >= self . delta and idx in pvalue_of_min and pvalue_of_min [ idx ] <= self . threshold_comparisons :                      filtered_min_idx += [ idx ]   elif self . correct_for_multiple_testing == <str> :                  if delta_of_min [ idx ] >= self . delta and idx in pvalue_of_min and pvalue_of_min [ idx ] <= self . threshold_comparisons :                      filtered_min_idx += [ idx ]    if self . correct_for_multiple_testing == <str> :              log . info ( <str> . format ( self . delta , self . threshold_comparisons , len ( filtered_min_idx ) ) )  elif self . correct_for_multiple_testing == <str> :              log . info ( <str> . format ( self . delta , self . threshold_comparisons , len ( filtered_min_idx ) ) )  else :              log . info ( <str> . format ( self . delta , len ( filtered_min_idx ) , self . threshold_comparisons ) )  count = 1 with open ( prefix + <str> , <str> ) as file_boundary_bin , open ( prefix + <str> , <str> ) as file_domains , open ( prefix + <str> , <str> ) as gff :              for idx , min_bin_id in enumerate ( filtered_min_idx ) :                  if min_bin_id in chr_end_idx :                      continue  if min_bin_id not in delta_of_min :                      delta_of_min [ min_bin_id ] = np . nan  right_bin_center = chr_start [ min_bin_id ] + int ( ( chr_end [ min_bin_id ] - chr_start [ min_bin_id ] ) / 2 ) left_bin_center = chr_start [ min_bin_id - 1 ] + int ( ( chr_end [ min_bin_id - 1 ] - chr_start [ min_bin_id - 1 ] ) / 2 ) if chrom [ min_bin_id ] != chrom [ min_bin_id - 1 ] :                      continue  file_boundary_bin . write ( <str> . format ( toString ( chrom [ min_bin_id ] ) , left_bin_center , right_bin_center , min_bin_id , mean_mat_all [ min_bin_id ] ) ) gff . write ( <str> <str> <str> . format ( chrom = toString ( chrom [ min_bin_id ] ) , start = left_bin_center , end = right_bin_center , delta = delta_of_min [ min_bin_id ] , pvalue = pvalue_of_min [ min_bin_id ] , score = mean_mat_all [ min_bin_id ] , id = min_bin_id ) ) start = chr_start [ min_bin_id ] if idx + 1 == len ( filtered_min_idx ) or chrom [ min_bin_id ] != chrom [ filtered_min_idx [ idx + 1 ] ] :                      continue  end = chr_start [ filtered_min_idx [ idx + 1 ] ] if count % 2 == 0 :                      rgb = <str>  else :                      rgb = <str>  file_domains . write ( <str> . format ( toString ( chrom [ min_bin_id ] ) , start , end , count , mean_mat_all [ min_bin_id ] , rgb , self . delta ) ) count += 1   with open ( prefix + <str> , <str> ) as tad_score :              for idx in range ( 1 , len ( chrom ) ) :                  right_bin_center = chr_start [ idx ] + int ( ( chr_end [ idx ] - chr_start [ idx ] ) / 2 ) left_bin_center = chr_start [ idx - 1 ] + int ( ( chr_end [ idx - 1 ] - chr_start [ idx - 1 ] ) / 2 ) if right_bin_center <= left_bin_center :                      continue  tad_score . write ( <str> . format ( toString ( chrom [ idx ] ) , left_bin_center , right_bin_center , mean_mat_all [ idx ] ) )    def compute_spectra_matrix ( self , perchr = True ) :          log . info ( <str> ) self . hic_ma . diagflat ( value = 0 ) self . hic_ma . maskBins ( self . hic_ma . nan_bins ) orig_intervals = self . hic_ma . cut_intervals [ : ] if self . use_zscore :              log . info ( <str> ) self . hic_ma . convert_to_zscore_matrix ( maxdepth = self . max_depth * 2.5 , perchr = perchr )  new_intervals = enlarge_bins ( self . hic_ma . cut_intervals ) if new_intervals != orig_intervals :              self . hic_ma . interval_trees , self . hic_ma . chrBinBoundaries = self . hic_ma . intervalListToIntervalTree ( new_intervals ) self . hic_ma . cut_intervals = new_intervals self . hic_ma . orig_cut_intervals = new_intervals self . hic_ma . orig_bin_ids = list ( range ( len ( new_intervals ) ) ) self . hic_ma . nan_bins = [ ]  if self . min_depth % self . hic_ma . getBinSize ( ) != 0 :              log . warn ( <str> <str> . format ( self . hic_ma . getBinSize ( ) ) )  if self . step % self . hic_ma . getBinSize ( ) != 0 :              log . warn ( <str> <str> . format ( self . hic_ma . getBinSize ( ) ) )  self . binsize = self . hic_ma . getBinSize ( ) log . info ( <str> ) min_depth_in_bins = int ( self . min_depth / self . binsize ) max_depth_in_bins = int ( self . max_depth / self . binsize ) step_in_bins = int ( self . step / self . binsize ) if step_in_bins == 0 :              log . error ( <str> . format ( self . binsize ) ) exit ( 1 )  incremental_step = get_incremental_step_size ( self . min_depth , self . max_depth , self . step ) log . info ( <str> <str> . format ( min_depth_in_bins , self . binsize * min_depth_in_bins , max_depth_in_bins , self . binsize * max_depth_in_bins , step_in_bins , incremental_step ) ) if min_depth_in_bins <= 1 :              log . error ( <str> <str> . format ( self . binsize ) ) exit ( 0 )  if max_depth_in_bins <= 1 :              log . error ( <str> <str> . format ( self . binsize ) ) exit ( 0 )  limit = 2 * max_depth_in_bins self . hic_ma . matrix = sparse . triu ( self . hic_ma . matrix , k = 0 , format = <str> ) - sparse . triu ( self . hic_ma . matrix , k = limit , format = <str> ) self . hic_ma . matrix . eliminate_zeros ( ) func = compute_matrix_wrapper TASKS = [ ] bins_to_consider = [ ] global hic_ma hic_ma = self . hic_ma for chrom in list ( self . hic_ma . chrBinBoundaries ) :              bins_to_consider . extend ( list ( range ( * self . hic_ma . chrBinBoundaries [ chrom ] ) ) )  for idx_array in np . array_split ( bins_to_consider , self . num_processors ) :              TASKS . append ( ( idx_array , self . min_depth , self . max_depth , self . step ) )  if self . num_processors > 1 :              pool = multiprocessing . Pool ( self . num_processors ) log . info ( <str> . format ( self . num_processors ) ) res = pool . map_async ( func , TASKS ) . get ( 9999999 ) pool . close ( )  else :              res = map ( func , TASKS )  chrom = [ ] chr_start = [ ] chr_end = [ ] matrix = [ ] for _chrom , _chr_start , _chr_end , _matrix in res :              chrom . extend ( toString ( _chrom ) ) chr_start . extend ( _chr_start ) chr_end . extend ( _chr_end ) matrix . append ( _matrix )  matrix = np . vstack ( matrix ) self . bedgraph_matrix = { <str> : np . array ( chrom ) , <str> : np . array ( chr_start ) . astype ( int ) , <str> : np . array ( chr_end ) . astype ( int ) , <str> : matrix }  def load_bedgraph_matrix ( self , filename , pChromosomes = None ) :          matrix = [ ] chrom_list = [ ] start_list = [ ] end_list = [ ] with open ( filename , <str> ) as fh :              for line in fh :                  if line . startswith ( <str> ) :                      parameters = json . loads ( line [ 1 : ] . strip ( ) ) continue  fields = line . strip ( ) . split ( <str> ) chrom , start , end = fields [ 0 : 3 ] if pChromosomes is not None :                      if chrom in pChromosomes :                          chrom_list . append ( chrom ) start_list . append ( int ( float ( start ) ) ) end_list . append ( int ( float ( end ) ) ) matrix . append ( map ( float , fields [ 3 : ] ) )   else :                      chrom_list . append ( chrom ) start_list . append ( int ( float ( start ) ) ) end_list . append ( int ( float ( end ) ) ) matrix . append ( map ( float , fields [ 3 : ] ) )    self . min_depth = parameters [ <str> ] self . max_depth = parameters [ <str> ] self . step = parameters [ <str> ] self . binsize = parameters [ <str> ] matrix = np . vstack ( matrix ) self . bedgraph_matrix = { <str> : np . array ( chrom_list ) , <str> : np . array ( start_list ) . astype ( int ) , <str> : np . array ( end_list ) . astype ( int ) , <str> : matrix }  def min_pvalue ( self , min_idx ) :          log . info ( <str> . format ( self . min_depth ) ) pvalues = [ ] chrom = self . bedgraph_matrix [ <str> ] chr_start = self . bedgraph_matrix [ <str> ] chr_end = self . bedgraph_matrix [ <str> ] window_len = self . min_depth from scipy . stats import ranksums new_min_idx = [ ] for idx in min_idx :              matrix_idx = self . hic_ma . getRegionBinRange ( chrom [ idx ] , chr_start [ idx ] , chr_end [ idx ] ) if matrix_idx is None :                  continue  else :                  matrix_idx = matrix_idx [ 0 ]  new_min_idx += [ idx ] min_chr , min_start , min_end , _ = self . hic_ma . getBinPos ( matrix_idx ) assert toString ( chrom [ idx ] ) == toString ( min_chr ) and chr_start [ idx ] == min_start and chr_end [ idx ] == min_end left_idx , right_idx = get_idx_of_bins_at_given_distance ( self . hic_ma , matrix_idx , window_len ) left = get_cut_weight ( self . hic_ma , left_idx , window_len ) right = get_cut_weight ( self . hic_ma , right_idx , window_len ) boundary = get_cut_weight ( self . hic_ma , matrix_idx , window_len ) if left is None :                  left = [ ]  if right is None :                  right = [ ]  if len ( left ) == 0 and len ( right ) == 0 :                  pval = np . nan  elif boundary is None or len ( boundary ) == 0 or len ( left ) == 0 or len ( right ) == 0 :                  pval = np . nan  else :                  try :                      pval1 = ranksums ( boundary , left ) [ 1 ] pval2 = ranksums ( boundary , right ) [ 1 ] pval = min ( pval1 , pval2 )  except ValueError :                      pval = np . nan   pvalues += [ pval ]  assert len ( pvalues ) == len ( new_min_idx ) if self . correct_for_multiple_testing == <str> :              pvalues = np . array ( [ e if ~ np . isnan ( e ) else 1 for e in pvalues ] ) pvalues_ = sorted ( pvalues ) largest_p_i = 0 for i , p in enumerate ( pvalues_ ) :                  if p <= ( self . threshold_comparisons * ( i + 1 ) / len ( pvalues_ ) ) :                      if p >= largest_p_i :                          largest_p_i = p    self . pvalueFDR = largest_p_i  elif self . correct_for_multiple_testing == <str> :              pvalues = np . array ( pvalues ) * len ( pvalues ) to_one_index_values = np . array ( [ e > 1 if ~ np . isnan ( e ) else False for e in pvalues ] ) if len ( to_one_index_values ) > 0 :                  pvalues [ to_one_index_values ] = 1   return OrderedDict ( zip ( new_min_idx , pvalues ) )  def find_boundaries ( self ) :          avg_bin_size = np . median ( self . bedgraph_matrix [ <str> ] - self . bedgraph_matrix [ <str> ] ) if self . min_boundary_distance is None :              self . min_boundary_distance = avg_bin_size * 4  lookahead = int ( self . min_boundary_distance / avg_bin_size ) if lookahead < 1 :              raise ValueError ( <str> )  min_idx , delta = HicFindTads . find_consensus_minima ( self . bedgraph_matrix [ <str> ] , lookahead = lookahead , chrom = self . bedgraph_matrix [ <str> ] ) pvalues = self . min_pvalue ( min_idx ) if len ( min_idx ) <= 10 :              mat_mean = self . bedgraph_matrix [ <str> ] . mean ( axis = 1 ) m_mean = mat_mean . mean ( ) m_median = np . median ( mat_mean ) m_75 = np . percentile ( mat_mean , 75 ) m_25 = np . percentile ( mat_mean , 25 ) msg = ( <str> <str> <str> <str> <str> <str> <str> <str> . format ( self . delta , self . min_boundary_distance , m_mean , m_median , m_25 , m_75 ) ) if len ( min_idx ) == 0 :                  log . error ( <str> . format ( msg ) ) exit ( 1 )  else :                  log . info ( <str> . format ( len ( min_idx ) , msg ) )   self . boundaries = { <str> : min_idx , <str> : delta , <str> : pvalues }   def print_args ( args ) :      for key , value in args . _get_kwargs ( ) :          log . info ( <str> . format ( key , value ) )   def main ( args = None ) :      args = parse_arguments ( ) . parse_args ( args ) ft = HicFindTads ( args . matrix , num_processors = args . numberOfProcessors , max_depth = args . maxDepth , min_depth = args . minDepth , step = args . step , delta = args . delta , min_boundary_distance = args . minBoundaryDistance , use_zscore = True , p_correct_for_multiple_testing = args . correctForMultipleTesting , p_threshold_comparisons = args . thresholdComparisons , pChromosomes = args . chromosomes ) tad_score_file = args . outPrefix + <str> zscore_matrix_file = args . outPrefix + <str> if args . TAD_sep_score_prefix is not None :          tad_score_file = args . TAD_sep_score_prefix + <str> zscore_matrix_file = args . TAD_sep_score_prefix + <str> if not os . path . isfile ( tad_score_file ) :              log . error ( <str> <str> . format ( tad_score_file ) ) exit ( 1 )  if not os . path . isfile ( zscore_matrix_file ) :              log . error ( <str> <str> . format ( zscore_matrix_file ) ) exit ( 1 )  log . info ( <str> . format ( tad_score_file ) ) ft . set_matrix ( zscore_matrix_file , args . chromosomes ) ft . load_bedgraph_matrix ( tad_score_file , args . chromosomes )  elif not os . path . isfile ( tad_score_file ) :          ft . compute_spectra_matrix ( ) ft . hic_ma . save ( args . outPrefix + <str> ) ft . save_bedgraph_matrix ( tad_score_file )  else :          log . info ( <str> . format ( tad_score_file ) ) log . info ( <str> ) ft . set_matrix ( zscore_matrix_file , args . chromosomes ) ft . load_bedgraph_matrix ( tad_score_file , args . chromosomes )  ft . find_boundaries ( ) ft . save_domains_and_boundaries ( args . outPrefix )   