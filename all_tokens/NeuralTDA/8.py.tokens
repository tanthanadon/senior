import os import subprocess import time import glob import pickle import logging import datetime import tqdm import tempfile import numpy as np import h5py from scipy . interpolate import interp1d from ephys import events , core import neuraltda . stimulus_space as sc TOPOLOGY_LOG = logging . getLogger ( <str> ) SCM_EXECUTABLE = <str> def setup_logging ( func_name ) :      logging_dir = os . path . join ( os . getcwd ( ) , <str> ) if not os . path . exists ( logging_dir ) :          os . makedirs ( logging_dir )  logging_fname = ( <str> . format ( func_name ) + datetime . datetime . utcnow ( ) . strftime ( <str> ) + <str> ) logging_file = os . path . join ( logging_dir , logging_fname ) logger = logging . getLogger ( <str> ) logger . setLevel ( logging . DEBUG ) file_handler = logging . FileHandler ( logging_file ) file_handler . setLevel ( logging . DEBUG ) stream_handler = logging . StreamHandler ( logging . DEBUG ) formatter = logging . Formatter ( <str> ) formatter . converter = time . gmtime file_handler . setFormatter ( formatter ) stream_handler . setFormatter ( formatter ) logger . addHandler ( file_handler ) logger . addHandler ( stream_handler ) logger . info ( <str> . format ( func_name ) )  def get_spikes_in_window ( spikes , window , rec ) :      mask = ( ( spikes [ <str> ] <= window [ 1 ] ) & ( spikes [ <str> ] >= window [ 0 ] ) & ( spikes [ <str> ] == rec ) ) return spikes [ mask ]  def get_windows_for_spike ( t , subwin_len , noverlap , segment ) :      skip = subwin_len - noverlap dur = segment [ 1 ] - segment [ 0 ] A = ( int ( t ) - int ( segment [ 0 ] ) ) / int ( skip ) J = int ( int ( subwin_len - 1 ) / int ( skip ) ) max_k = int ( np . floor ( float ( dur ) / float ( skip ) ) ) wins = [ ] i0 = int ( A ) wins . append ( i0 ) wins = i0 - np . array ( range ( J + 1 ) ) wins = wins [ wins >= 0 ] wins = wins [ wins < max_k ] return wins  def build_perseus_persistent_input ( cell_groups , savefile ) :      with open ( savefile , <str> ) as pfile :          pfile . write ( <str> ) for ind , win_grp in enumerate ( cell_groups ) :              grp = list ( win_grp [ 1 ] ) grp_dim = len ( grp ) - 1 if grp_dim < 0 :                  continue  vert_str = str ( grp ) vert_str = vert_str . replace ( <str> , <str> ) vert_str = vert_str . replace ( <str> , <str> ) vert_str = vert_str . replace ( <str> , <str> ) vert_str = vert_str . replace ( <str> , <str> ) out_str = str ( grp_dim ) + <str> + vert_str + <str> . format ( str ( ind + 1 ) ) pfile . write ( out_str )   return savefile  def build_perseus_input ( cell_groups , savefile ) :      with open ( savefile , <str> ) as pfile :          pfile . write ( <str> ) for ind , win_grp in enumerate ( cell_groups ) :              grp = list ( win_grp [ 1 ] ) grp_dim = len ( grp ) - 1 if grp_dim < 0 :                  continue  vert_str = str ( grp ) vert_str = vert_str . replace ( <str> , <str> ) vert_str = vert_str . replace ( <str> , <str> ) vert_str = vert_str . replace ( <str> , <str> ) vert_str = vert_str . replace ( <str> , <str> ) out_str = str ( grp_dim ) + <str> + vert_str + <str> . format ( str ( 1 ) ) pfile . write ( out_str )   return savefile  def run_perseus ( pfile ) :      pfile_split = os . path . splitext ( pfile ) of_string = pfile_split [ 0 ] perseus_command = <str> perseus_return_code = subprocess . call ( [ perseus_command , <str> , pfile , of_string ] ) betti_file = of_string + <str> return betti_file  def get_segment ( trial_bounds , fs , segment_info ) :      assert type ( segment_info ) == list seg_start = trial_bounds [ 0 ] + np . floor ( segment_info [ 0 ] * ( fs / 1000.0 ) ) seg_end = trial_bounds [ 1 ] + np . floor ( segment_info [ 1 ] * ( fs / 1000.0 ) ) return [ seg_start , seg_end ]  def calc_cell_groups ( data_mat , clusters , thresh ) :      cell_groups = [ ] nwin = data_mat . shape [ 1 ] mean_fr = np . mean ( data_mat , axis = 1 , keepdims = True ) mean_frs = np . tile ( mean_fr , ( 1 , nwin ) ) above_thresh = np . greater ( data_mat , thresh * mean_frs ) for win in range ( nwin ) :          clus_in_group = clusters [ above_thresh [ : , win ] ] cell_groups . append ( [ win , clus_in_group ] )  return cell_groups  def calc_bettis ( data_mat , clusters , pfile , thresh ) :      cell_groups = calc_cell_groups ( data_mat , clusters , thresh ) build_perseus_persistent_input ( cell_groups , pfile ) betti_file = run_perseus ( pfile ) bettis = [ ] f_time = [ ] try :          with open ( betti_file , <str> ) as bf :              for bf_line in bf :                  if len ( bf_line ) < 2 :                      continue  betti_data = bf_line . split ( ) filtration_time = int ( betti_data [ 0 ] ) betti_numbers = list ( map ( int , betti_data [ 1 : ] ) ) bettis . append ( [ filtration_time , betti_numbers ] )    except :          bettis . append ( [ - 1 , [ - 1 ] ] )  return bettis  def get_betti_savefile ( aid , apath , stim ) :      bs = aid + <str> . format ( stim ) + <str> bs = os . path . join ( apath , bs ) return bs  def get_bps ( aid , apath , stim ) :      bps = aid + <str> . format ( stim ) + <str> bps = os . path . join ( apath , bps ) return bps  def get_pfile_stem ( aid , apath , stim ) :      pfile_stem = aid + <str> . format ( stim ) pfile_stem = os . path . join ( apath , pfile_stem ) return pfile_stem  def get_analysis_paths ( aid , apath , stim ) :      bs = get_betti_savefile ( aid , apath , stim ) bps = get_bps ( aid , apath , stim ) pfs = get_pfile_stem ( aid , apath , stim ) return ( bs , bps , pfs )  def get_pfile_name ( pfile_stem , ** kwargs ) :      for key , val in kwargs . items ( ) :          pfile_stem = pfile_stem + <str> % ( str ( key ) , int ( val ) )  pfile = pfile_stem + <str> return pfile  def lin2ind ( shp , t ) :      inds = [ ] l = t for k in range ( len ( shp ) - 1 ) :          a = int ( np . product ( shp [ ( 1 + k ) : ] ) ) w = int ( l ) / a l = np . mod ( t , a ) inds . append ( w )  inds . append ( l ) return inds  def prep_paths ( analysis_id , binned_data_file , block_path , shuffle , nperms ) :      bdf_name , ext = os . path . splitext ( os . path . basename ( binned_data_file ) ) analysis_path = os . path . join ( block_path , <str> . format ( analysis_id ) ) if not os . path . exists ( analysis_path ) :          os . makedirs ( analysis_path )  if shuffle :          analysis_id = analysis_id + <str>  if nperms :          analysis_id = analysis_id + <str> . format ( nperms )  return ( analysis_id , analysis_path )  def calc_CI_bettis_tensor_old ( analysis_id , binned_data_file , block_path , thresh , shuffle = False , nperms = 0 , ncellsperm = 1 , clusters = None , ) :      ( analysis_id , analysis_path ) = prep_paths ( analysis_id , binned_data_file , block_path , shuffle , nperms ) with h5py . File ( binned_data_file , <str> ) as bdf :          stims = bdf . keys ( ) bpd_withstim = dict ( ) for stim in stims :              binned_clusters = np . array ( bdf [ stim ] [ <str> ] ) stim_trials = bdf [ stim ] ( bs , bps , pfs ) = get_analysis_paths ( analysis_id , analysis_path , stim ) bpd = dict ( ) poptens = np . array ( stim_trials [ <str> ] ) clusters = np . array ( stim_trials [ <str> ] ) bpd = do_compute_betti ( poptens , clusters , pfs , thresh , shuffle , nperms , ncellsperm ) bpd_withstim [ stim ] = bpd with open ( bps , <str> ) as bpfile :                  pickle . dump ( bpd , bpfile )   bpdws_sfn = os . path . join ( analysis_path , analysis_id + <str> ) with open ( bpdws_sfn , <str> ) as bpdwsfile :              pickle . dump ( bpd_withstim , bpdwsfile )  return ( bpdws_sfn , bpd_withstim )   def calc_CI_bettis_tensor ( analysis_id , binned_data_file , block_path , thresh , shuffle = False , nperms = 0 , ncellsperm = 1 , clusters = None , ** kwargs ) :      ( analysis_id , analysis_path ) = prep_paths ( analysis_id , binned_data_file , block_path , shuffle , nperms ) poptens_list = [ ] clusters_list = [ ] with h5py . File ( binned_data_file , <str> ) as bdf :          stims = bdf . keys ( ) bpd_withstim = dict ( ) for stim in stims :              binned_clusters = np . array ( bdf [ stim ] [ <str> ] ) stim_trials = bdf [ stim ] poptens = np . array ( stim_trials [ <str> ] ) clusters = np . array ( stim_trials [ <str> ] ) poptens_list . append ( poptens ) clusters_list . append ( clusters )  if <str> in kwargs :              assert callable ( kwargs [ <str> ] ) shuff_func = kwargs [ <str> ] poptens_list = shuff_func ( poptens_list )  for ind , stim in enumerate ( stims ) :              ( bs , bps , pfs ) = get_analysis_paths ( analysis_id , analysis_path , stim ) bpd = dict ( ) poptens = poptens_list [ ind ] clusters = clusters_list [ ind ] bpd = do_compute_betti ( poptens , clusters , pfs , thresh , shuffle , nperms , ncellsperm ) bpd_withstim [ stim ] = bpd with open ( bps , <str> ) as bpfile :                  pickle . dump ( bpd , bpfile )   bpdws_sfn = os . path . join ( analysis_path , analysis_id + <str> ) with open ( bpdws_sfn , <str> ) as bpdwsfile :              pickle . dump ( bpd_withstim , bpdwsfile )  return ( bpdws_sfn , bpd_withstim )   def calc_CI_bettis_tensor_trialavg ( analysis_id , binned_data_file , block_path , thresh , shuffle = False , nperms = 0 , ncellsperm = 1 , clusters = None , ) :      ( analysis_id , analysis_path ) = prep_paths ( analysis_id , binned_data_file , block_path , shuffle , nperms ) with h5py . File ( binned_data_file , <str> ) as bdf :          stims = bdf . keys ( ) bpd_withstim = dict ( ) for stim in stims :              binned_clusters = np . array ( bdf [ stim ] [ <str> ] ) stim_trials = bdf [ stim ] ( bs , bps , pfs ) = get_analysis_paths ( analysis_id , analysis_path , stim ) bpd = dict ( ) poptens = np . array ( stim_trials [ <str> ] ) clusters = np . array ( stim_trials [ <str> ] ) poptens = np . mean ( poptens , axis = 2 ) bpd = do_compute_betti ( poptens [ : , : , np . newaxis ] , clusters , pfs , thresh , shuffle , nperms , ncellsperm , ) bpd_withstim [ stim ] = bpd with open ( bps , <str> ) as bpfile :                  pickle . dump ( bpd , bpfile )   bpdws_sfn = os . path . join ( analysis_path , analysis_id + <str> ) with open ( bpdws_sfn , <str> ) as bpdwsfile :              pickle . dump ( bpd_withstim , bpdwsfile )  return ( bpdws_sfn , bpd_withstim )   def do_compute_betti ( poptens , clusters , pfile_stem , thresh , shuffle , nperms , ncellsperm ) :      data_tensor = np . array ( poptens ) clusters = np . array ( clusters ) levels = ( data_tensor . shape ) [ 2 : ] assert len ( levels ) == 1 , <str> if shuffle == True :          data_tensor = shuffle_tensor_within_cell ( data_tensor )  if callable ( shuffle ) :          data_tensor = shuffle ( data_tensor )  ntrials = levels [ 0 ] bettidict = { } for trial in range ( ntrials ) :          pfile = pfile_stem + <str> % trial pfile = get_pfile_name ( pfile_stem , rep = trial ) data_mat = data_tensor [ : , : , trial ] if nperms :              bettipermdict = { } ( new_tensor , perm_cells ) = get_perms ( data_mat , nperms , ncellsperm ) for perm in range ( nperms ) :                  pfile = get_pfile_name ( pfile_stem , rep = trial , perm = perm ) nmat = new_tensor [ : , : , perm ] perm_clus = clusters [ perm_cells [ : , perm ] ] bettis = calc_bettis ( nmat , perm_clus , pfile , thresh ) bettipermdict [ str ( perm ) ] = { <str> : bettis }  bettidict [ str ( trial ) ] = bettipermdict  else :              if shuffle :                  pfile = get_pfile_name ( pfile_stem , rep = trial , shuffled = 1 )  bettis = calc_bettis ( data_mat , clusters , pfile , thresh ) bettidict [ str ( trial ) ] = { <str> : { <str> : bettis } }   return bettidict  def get_shuffle ( data_mat ) :      ( cells , wins ) = data_mat . shape for cell in range ( cells ) :          np . random . shuffle ( data_mat [ cell , : ] )  return data_mat  def shuffle_tensor_within_cell ( poptens ) :      ( cells , wins , trials ) = poptens . shape for trial in range ( trials ) :          for cell in range ( cells ) :              np . random . shuffle ( poptens [ cell , : , trial ] )   return poptens  def shuffle_tensor_across_trials ( poptens ) :      ( cells , wins , trials ) = poptens . shape for win in range ( wins ) :          for cell in range ( cells ) :              np . random . shuffle ( poptens [ cell , win , : ] )   return poptens  def shuffle_spiketrains_across_trials ( poptens ) :      ( cells , wins , trials ) = poptens . shape for cell in range ( cells ) :          np . random . shuffle ( poptens [ cell , : , : ] . T )  return poptens  def shuffle_across_trials_across_stims ( poptens_list ) :      ntrials_list = [ x . shape [ 2 ] for x in poptens_list ] assert len ( np . unique ( ntrials_list ) ) == 1 ntrials = np . unique ( ntrials_list ) [ 0 ] nstims = len ( poptens_list ) poptens_concat = np . concatenate ( poptens_list , axis = 2 ) poptens_concat = shuffle_tensor_across_trials ( poptens_concat ) poptens_list_out = np . array_split ( poptens_concat , nstims , axis = 2 ) return poptens_list_out  def shuffle_whole_spiketrains_across_stims ( poptens_list ) :      ntrials_list = [ x . shape [ 2 ] for x in poptens_list ] assert len ( np . unique ( ntrials_list ) ) == 1 ntrials = np . unique ( ntrials_list ) [ 0 ] nstims = len ( poptens_list ) poptens_concat = np . concatenate ( poptens_list , axis = 2 ) poptens_concat = shuffle_spiketrains_across_trials ( poptens_concat ) poptens_list_out = np . array_split ( poptens_concat , nstims , axis = 2 ) return poptens_list_out  def get_shuffle_mask ( ncells , nwin ) :      wins = np . arange ( nwin , dtype = np . int64 ) mask = np . zeros ( ( ncells , nwin ) , dtype = np . int64 ) for cell in range ( ncells ) :          mask [ cell , : ] = np . random . permutation ( wins )  return mask  def apply_shuffle_mask ( poptens , shuffle_mask ) :      ncells , nwins , ntrials = poptens . shape poptens_out = np . zeros ( poptens . shape ) for trial in range ( ntrials ) :          for cell in range ( ncells ) :              poptens_out [ cell , : , trial ] = poptens [ cell , shuffle_mask [ cell , : ] , trial ]   return poptens_out  def shuffle_mask_within_stims ( poptens_list ) :      ncells = np . unique ( [ x . shape [ 0 ] for x in poptens_list ] ) [ 0 ] nwin = np . unique ( [ x . shape [ 1 ] for x in poptens_list ] ) [ 0 ] ntrials = np . unique ( [ x . shape [ 2 ] for x in poptens_list ] ) [ 0 ] poptens_list_out = [ ] for x in poptens_list :          shuffle_mask = get_shuffle_mask ( ncells , nwin ) poptens_list_out . append ( apply_shuffle_mask ( x , shuffle_mask ) )  return poptens_list_out  def shuffle_mask_across_stims ( poptens_list ) :      ncells = np . unique ( [ x . shape [ 0 ] for x in poptens_list ] ) [ 0 ] nwin = np . unique ( [ x . shape [ 1 ] for x in poptens_list ] ) [ 0 ] ntrials = np . unique ( [ x . shape [ 2 ] for x in poptens_list ] ) [ 0 ] shuffle_mask = get_shuffle_mask ( ncells , nwin ) poptens_list_out = [ apply_shuffle_mask ( x , shuffle_mask ) for x in poptens_list ] return poptens_list_out  def get_perms ( data_mat , nperms , ncellsperm ) :      ( cells , wins ) = data_mat . shape if ncellsperm > cells :          ncellsperm = cells  new_tensor = np . zeros ( ( ncellsperm , wins , nperms ) ) perm_cells = np . zeros ( ( ncellsperm , nperms ) ) . astype ( int ) for perm in range ( nperms ) :          celllist = np . random . permutation ( cells ) [ : ncellsperm ] new_tensor [ : , : , perm ] = data_mat [ celllist , : ] perm_cells [ : , perm ] = celllist  return ( new_tensor , perm_cells )  def build_binned_file_quick ( spikes , trials , clusters , win_size , fs , cluster_group , segment_info , popvec_fname , dt_overlap = 0.0 , ) :      with h5py . File ( popvec_fname , <str> ) as popvec_f :          if cluster_group != None :              mask = np . ones ( len ( clusters . index ) ) < 0 for grp in cluster_group :                  mask = np . logical_or ( mask , clusters [ <str> ] == grp )   clusters_to_use = clusters [ mask ] clusters_list = clusters_to_use [ <str> ] . unique ( ) nclus = len ( clusters_to_use . index ) spikes = spikes [ spikes [ <str> ] . isin ( list ( clusters_list ) ) ] popvec_f . attrs [ <str> ] = win_size popvec_f . attrs [ <str> ] = fs popvec_f . attrs [ <str> ] = nclus stims = trials [ <str> ] . unique ( ) for stim in stims :              if str ( stim ) == <str> :                  continue  stimgrp = popvec_f . create_group ( stim ) stim_trials = trials [ trials [ <str> ] == stim ] nreps = len ( stim_trials . index ) stim_recs = stim_trials [ <str> ] . values trial_len = ( stim_trials [ <str> ] - stim_trials [ <str> ] ) . unique ( ) [ 0 ] subwin_len = int ( np . round ( win_size / 1000.0 * fs ) ) noverlap = int ( np . round ( dt_overlap / 1000.0 * fs ) ) segment = get_segment ( [ 0 , trial_len ] , fs , segment_info ) poptens = build_activity_tensor_quick ( stim_trials , spikes , clusters_list , nclus , win_size , subwin_len , noverlap , segment , ) poptens_dset = stimgrp . create_dataset ( <str> , data = poptens ) stimgrp . create_dataset ( <str> , data = clusters_list ) poptens_dset . attrs [ <str> ] = fs poptens_dset . attrs [ <str> ] = win_size    def build_activity_tensor_quick ( stim_trials , spikes , clusters_list , nclus , win_size , subwin_len , noverlap , segment ) :      nreps = len ( stim_trials . index ) stim_recs = stim_trials [ <str> ] . values skip = subwin_len - noverlap dur = segment [ 1 ] - segment [ 0 ] if dur <= 0 :          print ( <str> ) return [ ]  nwins = int ( np . round ( float ( dur ) / float ( skip ) ) ) print ( <str> . format ( nreps ) ) print ( <str> . format ( skip ) ) print ( <str> . format ( dur ) ) print ( <str> . format ( nwins ) ) poptens = np . zeros ( ( nclus , nwins , nreps ) ) for rep in range ( nreps ) :          trial_start = stim_trials . iloc [ rep ] [ <str> ] trial_end = stim_trials . iloc [ rep ] [ <str> ] samp_period = ( trial_start + segment [ 0 ] , trial_start + segment [ 1 ] ) rec = stim_recs [ rep ] stim_rec_spikes = get_spikes_in_window ( spikes , samp_period , rec ) sptimes = stim_rec_spikes [ <str> ] . values clusters = stim_rec_spikes [ <str> ] . values for sp , clu in zip ( sptimes , clusters ) :              wins = get_windows_for_spike ( sp , subwin_len , noverlap , samp_period ) poptens [ clusters_list == clu , wins , rep ] += 1   poptens /= win_size / 1000.0 return poptens  def build_activity_matrix ( spike_times , spike_IDs , n_IDs , win_len , fs , pct_overlap , s_start , s_stop ) :      win_len_samples = np . round ( win_len * fs / 1000.0 ) n_overlap = int ( np . round ( pct_overlap * win_len_samples ) ) skip = int ( np . round ( ( 1 - pct_overlap ) * win_len_samples ) ) duration = s_stop - s_start n_wins = int ( np . round ( float ( duration ) / float ( skip ) ) ) mat = np . zeros ( ( n_IDs , n_wins ) ) ID_list = np . arange ( n_IDs ) for sp_t , sp_i in zip ( spike_times , spike_IDs ) :          wins = get_windows_for_spike ( sp_t , win_len_samples , n_overlap , ( s_start , s_stop ) ) mat [ ID_list == sp_i , wins ] += 1  mat /= ( win_len / 1000.0 ) return mat  def build_poptens_given_windows ( stim_trials , spikes , windows , clusters_list , segment ) :      nreps = len ( stim_trials . index ) nclus = len ( clusters_list ) stim_recs = stim_trials [ <str> ] . values nwins = len ( windows ) poptens = np . zeros ( ( nclus , nwins , nreps ) ) for rep in range ( nreps ) :          trial_start = stim_trials . iloc [ rep ] [ <str> ] trial_end = stim_trials . iloc [ rep ] [ <str> ] samp_period = ( trial_start + segment [ 0 ] , trial_start + segment [ 1 ] ) rec = stim_recs [ rep ] stim_rec_spikes = get_spikes_in_window ( spikes , samp_period , rec ) clusters = stim_rec_spikes [ <str> ] . values sptimes = stim_rec_spikes [ <str> ] . values - samp_period [ 0 ] clusters = stim_rec_spikes [ <str> ] . values sptclur = np . tile ( sptimes [ : , np . newaxis ] , ( 1 , nwins ) ) swin = np . tile ( windows [ np . newaxis , : ] , ( len ( sptimes ) , 1 ) ) upper = ( sptclur <= swin ) [ : , 1 : ] lower = ( sptclur > swin ) [ : , 0 : - 1 ] binss = np . logical_and ( upper , lower ) for clu in clusters_list :              poptens [ clusters_list == clu , 1 : , rep ] = np . sum ( binss [ clusters == clu , : ] , axis = 0 )   return poptens  def scramble ( a , axis = - 1 ) :      b = np . random . random ( a . shape ) idx = np . argsort ( b , axis = axis ) shuffled = a [ np . arange ( a . shape [ 0 ] ) [ : , None ] , idx ] return shuffled  def build_shuffled_data_tensor ( data_tens , nshuffs ) :      ncells , nwin , ntrial = data_tens . shape shuff_tens = np . zeros ( ( ncells , nwin , ntrial , nshuffs ) ) for shuff in range ( nshuffs ) :          for trial in range ( ntrial ) :              shuff_tens [ : , : , trial , shuff ] = scramble ( data_tens [ : , : , trial ] )   return shuff_tens  def build_permuted_data_tensor ( data_tens , ncellsperm , nperms ) :      ncells , nwin , ntrial = data_tens . shape perm_tens = np . zeros ( ( ncellsperm , nwin , ntrial , nperms ) ) for trial in range ( ntrial ) :          perm_tens [ : , : , trial , : ] = get_perms ( data_tens [ : , : , trial ] , nperms , ncellsperm ) [ 0 ]  return perm_tens  def extract_population_tensors ( binned_datafile , shuffle = False , clusters = None ) :      with h5py . File ( binned_datafile , <str> ) as bdf :          stims = bdf . keys ( ) print ( stims ) stim_tensors = dict ( ) for ind , stim in enumerate ( stims ) :              binned_clusters = np . array ( bdf [ stim ] [ <str> ] ) poptens = np . array ( bdf [ stim ] [ <str> ] ) print ( <str> . format ( stim , str ( clusters ) ) ) try :                  if clusters is not None :                      poptens = poptens [ np . in1d ( binned_clusters , clusters ) , : , : ] print ( <str> + str ( np . shape ( poptens ) ) )  ( ncell , nwin , ntrial ) = np . shape ( poptens )  except ( ValueError , IndexError ) :                  print ( <str> ) continue  if shuffle :                  poptens = build_shuffled_data_tensor ( poptens , 1 ) poptens = poptens [ : , : , : , 0 ]  if nwin == 0 :                  continue  stim_tensors [ stim ] = poptens   return stim_tensors  def extract_population_tensor ( binned_data_file , stim , shuffle = False , clusters = None ) :      print ( <str> ) with h5py . File ( binned_data_file , <str> ) as bdf :          binned_clusters = np . array ( bdf [ stim ] [ <str> ] ) poptens = np . array ( bdf [ stim ] [ <str> ] ) print ( <str> . format ( stim , str ( clusters ) ) ) try :              if clusters is not None :                  poptens = poptens [ np . in1d ( binned_clusters , clusters ) , : , : ] print ( <str> + str ( np . shape ( poptens ) ) )  ( ncell , nwin , ntrial ) = np . shape ( poptens )  except ( ValueError , IndexError ) :              print ( <str> ) return [ ]  if shuffle :              poptens = tp2 . build_shuffled_data_tensor ( poptens , 1 ) poptens = poptens [ : , : , : , 0 ]  if nwin == 0 :              return [ ]   return poptens  def num_trials ( poptens ) :      ( ncells , nwin , ntrials ) = np . shape ( poptens ) return ntrials  def num_win ( poptens ) :      ( ncells , nwin , ntrials ) = np . shape ( poptens ) return nwin  def num_cells ( poptens ) :      ( ncells , nwin , ntrials ) = np . shape ( poptens ) return ncells  def rejection_sampling ( command , seed = 0 ) :      proc = subprocess . run ( command , stdout = subprocess . PIPE ) facet_list = [ ] for line in proc . stdout . decode ( ) . split ( <str> ) [ 1 : - 1 ] :          if line . find ( <str> ) == 0 :              yield facet_list facet_list = [ ]  else :              facet_list . append ( [ int ( x ) for x in line . strip ( ) . split ( ) ] )   yield facet_list  def prepare_scm_initial_condition ( binmat , ** kwargs ) :      facets = sc . binarytomaxsimplex ( binmat , rDup = True , ** kwargs ) with tempfile . NamedTemporaryFile ( mode = <str> , delete = False ) as f :          fname = f . name for facet in facets :              fstr = str ( facet ) fstr = fstr . replace ( <str> , <str> ) fstr = fstr . replace ( <str> , <str> ) fstr = fstr . replace ( <str> , <str> ) f . write ( fstr + <str> )   return fname  def prepare_scm_command ( facet_file , nsamps ) :      command = [ SCM_EXECUTABLE , facet_file , <str> , str ( nsamps ) ] return command  def calc_scm_betti_distribution ( poptens , thresh , trial , nsamples ) :      popmat = poptens [ : , : , trial ] popmat_bin = sc . binnedtobinary ( popmat , thresh ) fname = prepare_scm_initial_condition ( popmat_bin ) cmd = prepare_scm_command ( fname , nsamples ) samples = rejection_sampling ( cmd ) sample_bettis = [ ] for sample in tqdm . tqdm ( samples ) :          bettis = [ ] cgs = [ [ 1 , x ] for x in sample ] build_perseus_input ( cgs , <str> ) betti_file = run_perseus ( <str> ) try :              with open ( betti_file , <str> ) as bf :                  for bf_line in bf :                      betti_numbers_arr = np . zeros ( 10 ) if len ( bf_line ) < 2 :                          continue  betti_data = bf_line . split ( ) filtration_time = int ( betti_data [ 0 ] ) betti_numbers = np . array ( list ( map ( int , betti_data [ 1 : ] ) ) ) betti_numbers_arr [ 0 : len ( betti_numbers ) ] = betti_numbers bettis . append ( np . array ( betti_numbers_arr ) )    except :              bettis . append ( - 1 * np . ones ( 10 ) )  sample_bettis . append ( bettis )  return np . array ( sample_bettis )  def get_scg_at_time ( binmat , t ) :      ( ncells , nwins ) = binmat . shape subpopmat = binmat [ : , 0 : t ] scg = sc . binarytomaxsimplex ( binmat , rDup = True ) return scg  def betti_dict_to_betti_curves ( betti_dict , dims , twin , windt , dtovr ) :      stim_betticurves = { } for stim in betti_dict . keys ( ) :          betticurve_save = np . empty ( ( len ( dims ) , len ( twin ) , 0 ) ) trials = betti_dict [ stim ] for trial in trials . keys ( ) :              perms = trials [ trial ] for perm in perms . keys ( ) :                  dat = perms [ perm ] [ <str> ] t = np . array ( [ int ( x [ 0 ] ) for x in dat ] ) t_milliseconds = t * ( ( windt - dtovr ) ) + windt / 2.0 t_vals = np . round ( ( twin - windt / 2 ) / ( windt - dtovr ) ) t_vals_milliseconds = twin b = [ x [ 1 ] for x in dat ] b = [ np . pad ( np . array ( x ) , ( 0 , 10 ) , <str> , constant_values = 0 ) for x in b ] betticurve_save_alldims = np . empty ( ( 0 , len ( twin ) ) ) for dim in dims :                      b_val = np . array ( [ x [ dim ] for x in b ] ) b_func = interp1d ( t , b_val , kind = <str> , bounds_error = False , fill_value = ( b_val [ 0 ] , b_val [ - 1 ] ) , ) betti_curve_dim = b_func ( t_vals ) betticurve_save_alldims = np . vstack ( ( betticurve_save_alldims , betti_curve_dim ) )  betticurve_save = np . concatenate ( ( betticurve_save , betticurve_save_alldims [ : , : , np . newaxis ] ) , axis = 2 )   stim_betticurves [ stim ] = np . array ( betticurve_save )  return ( stim_betticurves , t_vals , t_vals_milliseconds )  def interpolate_betti ( betti_result , t_out , dims , win_len , pct_overlap ) :      t = np . array ( [ int ( x [ 0 ] ) for x in dat ] ) t_ms = t * win_len * ( 1 - pct_overlap ) + win_len / 2.0 t_vals = np . round ( ( t_out - win_len / 2.0 ) / ( win_len * ( 1 - pct_overlap ) ) ) t_vals_ms = t_out b = [ x [ 1 ] for x in dat ] b = [ np . pad ( np . array ( x ) , ( 0 , 10 ) , <str> , constant_values = 0 ) for x in b ] betti_curves_all_dims = np . empty ( ( 0 , len ( t_out ) ) ) for dim in dims :          b_val = np . array ( [ x [ dim ] for x in b ] ) b_func = interp1d ( t , b_val , kind = <str> , bounds_error = False , fill_value = ( b_val [ 0 ] , b_val [ - 1 ] ) ) betti_curve_dim = b_func ( t_vals ) betti_curves_all_dims = np . vstack ( ( betti_curves_all_dims , betti_curve_dim ) )  return ( betti_curves_all_dims , t_vals , t_vals_ms )  def compute_betti_curves ( analysis_id , block_path , bdf , thresh , nperms , ncellsperm , dims , twin , windt , dtovr , shuffle = False , ** kwargs ) :      ( resf , betti_dict ) = calc_CI_bettis_tensor ( analysis_id , bdf , block_path , thresh , shuffle = shuffle , nperms = nperms , ncellsperm = ncellsperm , ** kwargs ) return betti_dict_to_betti_curves ( betti_dict , dims , twin , windt , dtovr )  def compute_trialaverage_betti_curves ( analysis_id , block_path , bdf , thresh , nperms , ncellsperm , dims , twin , windt , dtovr , shuffle = False , ) :      ( resf , betti_dict ) = calc_CI_bettis_tensor_trialavg ( analysis_id , bdf , block_path , thresh , shuffle = shuffle , nperms = nperms , ncellsperm = ncellsperm , ) return betti_dict_to_betti_curves ( betti_dict , dims , twin , windt , dtovr )  def compute_mean_stderr_betti_curves ( betti_curves ) :      stims = betti_curves . keys ( ) bc_plot_dict = { } for ind , stim in enumerate ( stims ) :          dat = betti_curves [ stim ] avg = np . mean ( dat , axis = 2 ) std = np . std ( dat , axis = 2 ) stderr = std / np . sqrt ( np . shape ( dat ) [ 2 ] ) bc_plot_dict [ stim ] = ( avg , stderr )  return bc_plot_dict  def compute_stimulus_specificity ( betti_curves , stimulus_files ) :      pass  def db_load_data ( block_path ) :      spikes = core . load_spikes ( block_path ) trials = events . load_trials ( block_path ) fs = core . load_fs ( block_path ) clusters = core . load_clusters ( block_path ) return ( spikes , trials , clusters , fs )  def bin_data ( block_path , winsize , segment_info , ** kwargs ) :      ( spikes , trials , clusters , fs ) = db_load_data ( block_path ) bfdict = do_dag_bin_lazy ( block_path , spikes , trials , clusters , fs , winsize , segment_info , ** kwargs ) return bfdict  def dag_bin ( block_path , winsize , segment_info , ** kwargs ) :      ( spikes , trials , clusters , fs ) = db_load_data ( block_path ) bfdict = do_dag_bin_lazy ( block_path , spikes , trials , clusters , fs , winsize , segment_info , ** kwargs ) return bfdict  def do_dag_bin_lazy ( block_path , spikes , trials , clusters , fs , winsize , segment_info , cluster_group = [ <str> , <str> ] , dt_overlap = 0.0 , comment = <str> , ) :      block_path = os . path . abspath ( block_path ) analysis_id = datetime . datetime . utcnow ( ) . strftime ( <str> ) raw_binned_fname = analysis_id + <str> . format ( winsize , dt_overlap ) analysis_id_forward = analysis_id + <str> . format ( winsize , dt_overlap ) bfdict = { <str> : analysis_id_forward } seg_string = <str> . join ( map ( str , segment_info ) ) if comment :          seg_string = seg_string + <str> + comment  bin_string = <str> . format ( winsize , dt_overlap , seg_string ) binned_folder = os . path . join ( block_path , bin_string ) if not os . path . exists ( binned_folder ) :          os . makedirs ( binned_folder )  existing_binned = glob . glob ( os . path . join ( binned_folder , <str> ) ) if len ( existing_binned ) == 0 :          print ( <str> ) raw_binned_f = os . path . join ( binned_folder , raw_binned_fname ) build_binned_file_quick ( spikes , trials , clusters , winsize , fs , cluster_group , segment_info , raw_binned_f , dt_overlap , )  else :          raw_binned_f = existing_binned [ 0 ]  bfdict [ <str> ] = binned_folder return bfdict  def dag_topology ( block_path , thresh , bfdict , raw = True , shuffle = False , shuffleperm = False , nperms = 0 , ncellsperm = 1 , ** kwargs ) :      aid = bfdict [ <str> ] analysis_dict = dict ( ) raw_folder = bfdict [ <str> ] if <str> in bfdict . keys ( ) and raw :          tpid_raw = aid + <str> . format ( thresh ) raw_data_files = glob . glob ( os . path . join ( raw_folder , <str> ) ) for rdf in raw_data_files :              res_f = calc_CI_bettis_tensor ( tpid_raw , rdf , block_path , thresh , ** kwargs ) [ 0 ]  with open ( res_f , <str> ) as f :              res = pickle . load ( f ) analysis_dict [ <str> ] = res   if shuffle :          tpid_raw = aid + <str> . format ( thresh ) raw_data_files = glob . glob ( os . path . join ( raw_folder , <str> ) ) for rdf in raw_data_files :              res_f = calc_CI_bettis_tensor ( tpid_raw , rdf , block_path , thresh , shuffle = True , ** kwargs ) [ 0 ]  with open ( res_f , <str> ) as f :              res = pickle . load ( f ) analysis_dict [ <str> ] = res   if nperms :          tpid_raw = aid + <str> . format ( thresh , nperms , ncellsperm ) raw_data_files = glob . glob ( os . path . join ( raw_folder , <str> ) ) for rdf in raw_data_files :              res_f = calc_CI_bettis_tensor ( tpid_raw , rdf , block_path , thresh , nperms = nperms , ncellsperm = ncellsperm , ** kwargs ) [ 0 ]  with open ( res_f , <str> ) as f :              res = pickle . load ( f ) analysis_dict [ <str> ] = res   if shuffleperm :          tpid_raw = aid + <str> . format ( thresh , nperms , ncellsperm ) raw_data_files = glob . glob ( os . path . join ( raw_folder , <str> ) ) for rdf in raw_data_files :              res_f = calc_CI_bettis_tensor ( tpid_raw , rdf , block_path , thresh , shuffle = True , nperms = nperms , ncellsperm = ncellsperm , ** kwargs ) [ 0 ]  with open ( res_f , <str> ) as f :              res = pickle . load ( f ) analysis_dict [ <str> ] = res   if <str> in bfdict . keys ( ) :          at_folder = bfdict [ <str> ] tpid_at = aid + <str> . format ( thresh ) atDataFiles = glob . glob ( os . path . join ( at_folder , <str> ) ) for atdf in atDataFiles :              res_f = calc_CI_bettis_all_trials ( tpid_at , atdf , block_path , thresh ) [ 0 ]  with open ( res_f , <str> ) as f :              res = pickle . load ( f ) analysis_dict [ <str> ] = res   master_fname = aid for key , val in kwargs . iteritems ( ) :          master_fname = master_fname + <str> . format ( key , val )  master_fname = master_fname + <str> . format ( thresh ) master_fname = os . path . join ( block_path , master_fname ) with open ( master_fname , <str> ) as master_f :          pickle . dump ( analysis_dict , master_f )  return master_f   