import itertools import time from abc import ABC , abstractmethod from asyncio import Lock from collections import defaultdict import attr from aiorpcx import TaskGroup , run_in_thread , sleep from electrumx . lib . hash import hash_to_hex_str , hex_str_to_hash from electrumx . lib . util import class_logger , chunks from electrumx . server . db import UTXO @ attr . s ( slots = True ) class MemPoolTx ( object ) :      prevouts = attr . ib ( ) in_pairs = attr . ib ( ) out_pairs = attr . ib ( ) fee = attr . ib ( ) size = attr . ib ( )  @ attr . s ( slots = True ) class MemPoolTxSummary ( object ) :      hash = attr . ib ( ) fee = attr . ib ( ) has_unconfirmed_inputs = attr . ib ( )  class DBSyncError ( Exception ) :      pass  class MemPoolAPI ( ABC ) :      @ abstractmethod async def height ( self ) :           @ abstractmethod def cached_height ( self ) :           @ abstractmethod def db_height ( self ) :           @ abstractmethod async def mempool_hashes ( self ) :           @ abstractmethod async def raw_transactions ( self , hex_hashes ) :           @ abstractmethod async def lookup_utxos ( self , prevouts ) :           @ abstractmethod async def on_mempool ( self , touched , height ) :            class MemPool ( object ) :      def __init__ ( self , coin , api , refresh_secs = 5.0 , log_status_secs = 60.0 ) :          assert isinstance ( api , MemPoolAPI ) self . coin = coin self . api = api self . logger = class_logger ( __name__ , self . __class__ . __name__ ) self . txs = { } self . hashXs = defaultdict ( set ) self . cached_compact_histogram = [ ] self . refresh_secs = refresh_secs self . log_status_secs = log_status_secs self . lock = Lock ( )  async def _logging ( self , synchronized_event ) :          self . logger . info ( <str> <str> ) start = time . time ( ) await synchronized_event . wait ( ) elapsed = time . time ( ) - start self . logger . info ( <str> ) while True :              mempool_size = sum ( tx . size for tx in self . txs . values ( ) ) / 1_000_000 self . logger . info ( <str> <str> ) await sleep ( self . log_status_secs ) await synchronized_event . wait ( )   async def _refresh_histogram ( self , synchronized_event ) :          while True :              await synchronized_event . wait ( ) async with self . lock :                  await run_in_thread ( self . _update_histogram , 100_000 )  await sleep ( self . coin . MEMPOOL_HISTOGRAM_REFRESH_SECS )   def _update_histogram ( self , bin_size ) :          histogram = defaultdict ( int ) for tx in self . txs . values ( ) :              histogram [ tx . fee // tx . size ] += tx . size  compact = [ ] cum_size = 0 r = 0 for fee_rate , size in sorted ( histogram . items ( ) , reverse = True ) :              cum_size += size if cum_size + r > bin_size :                  compact . append ( ( fee_rate , cum_size ) ) r += cum_size - bin_size cum_size = 0 bin_size *= 1.1   self . logger . info ( <str> ) self . cached_compact_histogram = compact  def _accept_transactions ( self , tx_map , utxo_map , touched ) :          hashXs = self . hashXs txs = self . txs deferred = { } unspent = set ( utxo_map ) for hash , tx in tx_map . items ( ) :              in_pairs = [ ] try :                  for prevout in tx . prevouts :                      utxo = utxo_map . get ( prevout ) if not utxo :                          prev_hash , prev_index = prevout utxo = txs [ prev_hash ] . out_pairs [ prev_index ]  in_pairs . append ( utxo )   except KeyError :                  deferred [ hash ] = tx continue  unspent . difference_update ( tx . prevouts ) tx . in_pairs = tuple ( in_pairs ) tx . fee = max ( 0 , ( sum ( v for _ , v in tx . in_pairs ) - sum ( v for _ , v in tx . out_pairs ) ) ) txs [ hash ] = tx for hashX , _value in itertools . chain ( tx . in_pairs , tx . out_pairs ) :                  touched . add ( hashX ) hashXs [ hashX ] . add ( hash )   return deferred , { prevout : utxo_map [ prevout ] for prevout in unspent }  async def _refresh_hashes ( self , synchronized_event ) :          touched = set ( ) while True :              height = self . api . cached_height ( ) hex_hashes = await self . api . mempool_hashes ( ) if height != await self . api . height ( ) :                  continue  hashes = set ( hex_str_to_hash ( hh ) for hh in hex_hashes ) try :                  async with self . lock :                      await self . _process_mempool ( hashes , touched , height )   except DBSyncError :                  self . logger . debug ( <str> )  else :                  synchronized_event . set ( ) synchronized_event . clear ( ) await self . api . on_mempool ( touched , height ) touched = set ( )  await sleep ( self . refresh_secs )   async def _process_mempool ( self , all_hashes , touched , mempool_height ) :          txs = self . txs hashXs = self . hashXs if mempool_height != self . api . db_height ( ) :              raise DBSyncError  for tx_hash in set ( txs ) . difference ( all_hashes ) :              tx = txs . pop ( tx_hash ) tx_hashXs = set ( hashX for hashX , value in tx . in_pairs ) tx_hashXs . update ( hashX for hashX , value in tx . out_pairs ) for hashX in tx_hashXs :                  hashXs [ hashX ] . remove ( tx_hash ) if not hashXs [ hashX ] :                      del hashXs [ hashX ]   touched . update ( tx_hashXs )  new_hashes = list ( all_hashes . difference ( txs ) ) if new_hashes :              group = TaskGroup ( ) for hashes in chunks ( new_hashes , 200 ) :                  coro = self . _fetch_and_accept ( hashes , all_hashes , touched ) await group . spawn ( coro )  if mempool_height != self . api . db_height ( ) :                  raise DBSyncError  tx_map = { } utxo_map = { } async for task in group :                  deferred , unspent = task . result ( ) tx_map . update ( deferred ) utxo_map . update ( unspent )  prior_count = 0 while tx_map and len ( tx_map ) != prior_count :                  prior_count = len ( tx_map ) tx_map , utxo_map = self . _accept_transactions ( tx_map , utxo_map , touched )  if tx_map :                  self . logger . error ( <str> )   return touched  async def _fetch_and_accept ( self , hashes , all_hashes , touched ) :          hex_hashes_iter = ( hash_to_hex_str ( hash ) for hash in hashes ) raw_txs = await self . api . raw_transactions ( hex_hashes_iter ) def deserialize_txs ( ) :              to_hashX = self . coin . hashX_from_script deserializer = self . coin . DESERIALIZER txs = { } for hash , raw_tx in zip ( hashes , raw_txs ) :                  if not raw_tx :                      continue  tx , tx_size = deserializer ( raw_tx ) . read_tx_and_vsize ( ) txin_pairs = tuple ( ( txin . prev_hash , txin . prev_idx ) for txin in tx . inputs if not txin . is_generation ( ) ) txout_pairs = tuple ( ( to_hashX ( txout . pk_script ) , txout . value ) for txout in tx . outputs ) txs [ hash ] = MemPoolTx ( txin_pairs , None , txout_pairs , 0 , tx_size )  return txs  tx_map = await run_in_thread ( deserialize_txs ) prevouts = tuple ( prevout for tx in tx_map . values ( ) for prevout in tx . prevouts if prevout [ 0 ] not in all_hashes ) utxos = await self . api . lookup_utxos ( prevouts ) utxo_map = { prevout : utxo for prevout , utxo in zip ( prevouts , utxos ) } return self . _accept_transactions ( tx_map , utxo_map , touched )  async def keep_synchronized ( self , synchronized_event ) :          async with TaskGroup ( ) as group :              await group . spawn ( self . _refresh_hashes ( synchronized_event ) ) await group . spawn ( self . _refresh_histogram ( synchronized_event ) ) await group . spawn ( self . _logging ( synchronized_event ) )   async def balance_delta ( self , hashX ) :          value = 0 if hashX in self . hashXs :              for hash in self . hashXs [ hashX ] :                  tx = self . txs [ hash ] value -= sum ( v for h168 , v in tx . in_pairs if h168 == hashX ) value += sum ( v for h168 , v in tx . out_pairs if h168 == hashX )   return value  async def compact_fee_histogram ( self ) :          return self . cached_compact_histogram  async def potential_spends ( self , hashX ) :          result = set ( ) for tx_hash in self . hashXs . get ( hashX , ( ) ) :              tx = self . txs [ tx_hash ] result . update ( tx . prevouts )  return result  async def transaction_summaries ( self , hashX ) :          result = [ ] for tx_hash in self . hashXs . get ( hashX , ( ) ) :              tx = self . txs [ tx_hash ] has_ui = any ( hash in self . txs for hash , idx in tx . prevouts ) result . append ( MemPoolTxSummary ( tx_hash , tx . fee , has_ui ) )  return result  async def unordered_UTXOs ( self , hashX ) :          utxos = [ ] for tx_hash in self . hashXs . get ( hashX , ( ) ) :              tx = self . txs . get ( tx_hash ) for pos , ( hX , value ) in enumerate ( tx . out_pairs ) :                  if hX == hashX :                      utxos . append ( UTXO ( - 1 , pos , tx_hash , 0 , value ) )    return utxos    