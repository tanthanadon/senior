import codecs import datetime import itertools import json import math import os import ssl import time from collections import defaultdict from functools import partial from ipaddress import IPv4Address , IPv6Address import attr from aiorpcx import ( RPCSession , JSONRPCAutoDetect , JSONRPCConnection , serve_rs , serve_ws , TaskGroup , handler_invocation , RPCError , Request , sleep , Event , ReplyAndDisconnect ) import pylru import electrumx from electrumx . lib . merkle import MerkleCache from electrumx . lib . text import sessions_lines import electrumx . lib . util as util from electrumx . lib . hash import ( sha256 , hash_to_hex_str , hex_str_to_hash , HASHX_LEN , Base58Error ) from electrumx . server . daemon import DaemonError from electrumx . server . peers import PeerManager BAD_REQUEST = 1 DAEMON_ERROR = 2 def scripthash_to_hashX ( scripthash ) :      try :          bin_hash = hex_str_to_hash ( scripthash ) if len ( bin_hash ) == 32 :              return bin_hash [ : HASHX_LEN ]   except ( ValueError , TypeError ) :          pass  raise RPCError ( BAD_REQUEST , <str> )  def non_negative_integer ( value ) :      try :          value = int ( value ) if value >= 0 :              return value   except ( ValueError , TypeError ) :          pass  raise RPCError ( BAD_REQUEST , <str> )  def assert_boolean ( value ) :      if value in ( False , True ) :          return value  raise RPCError ( BAD_REQUEST , <str> )  def assert_tx_hash ( value ) :      try :          raw_hash = hex_str_to_hash ( value ) if len ( raw_hash ) == 32 :              return raw_hash   except ( ValueError , TypeError ) :          pass  raise RPCError ( BAD_REQUEST , <str> )  @ attr . s ( slots = True ) class SessionGroup :      name = attr . ib ( ) weight = attr . ib ( ) sessions = attr . ib ( ) retained_cost = attr . ib ( ) def session_cost ( self ) :          return sum ( session . cost for session in self . sessions )  def cost ( self ) :          return self . retained_cost + self . session_cost ( )   @ attr . s ( slots = True ) class SessionReferences :      sessions = attr . ib ( ) groups = attr . ib ( ) specials = attr . ib ( ) unknown = attr . ib ( )  class SessionManager :      def __init__ ( self , env , db , bp , daemon , mempool , shutdown_event ) :          env . max_send = max ( 350000 , env . max_send ) self . env = env self . db = db self . bp = bp self . daemon = daemon self . mempool = mempool self . peer_mgr = PeerManager ( env , db ) self . shutdown_event = shutdown_event self . logger = util . class_logger ( __name__ , self . __class__ . __name__ ) self . servers = { } self . sessions = { } self . session_groups = { } self . txs_sent = 0 self . start_time = time . time ( ) self . _method_counts = defaultdict ( int ) self . _history_cache = pylru . lrucache ( 1000 ) self . _history_lookups = 0 self . _history_hits = 0 self . _tx_hashes_cache = pylru . lrucache ( 1000 ) self . _tx_hashes_lookups = 0 self . _tx_hashes_hits = 0 self . _cache_counter = 0 self . _merkle_cache = pylru . lrucache ( 1000 ) self . _merkle_lookups = 0 self . _merkle_hits = 0 self . notified_height = None self . hsub_results = None self . _task_group = TaskGroup ( ) self . _sslc = None self . server_listening = Event ( ) self . session_event = Event ( ) cmds = ( <str> <str> . split ( ) ) LocalRPC . request_handlers = { cmd : getattr ( self , <str> + cmd ) for cmd in cmds }  def _ssl_context ( self ) :          if self . _sslc is None :              self . _sslc = ssl . SSLContext ( ssl . PROTOCOL_TLS ) self . _sslc . load_cert_chain ( self . env . ssl_certfile , keyfile = self . env . ssl_keyfile )  return self . _sslc  async def _start_servers ( self , services ) :          for service in services :              kind = service . protocol . upper ( ) if service . protocol in self . env . SSL_PROTOCOLS :                  sslc = self . _ssl_context ( )  else :                  sslc = None  if service . protocol == <str> :                  session_class = LocalRPC  else :                  session_class = self . env . coin . SESSIONCLS  if service . protocol in ( <str> , <str> ) :                  serve = serve_ws  else :                  serve = serve_rs  session_factory = partial ( session_class , self , self . db , self . mempool , self . peer_mgr , kind ) host = None if service . host == <str> else str ( service . host ) try :                  self . servers [ service ] = await serve ( session_factory , host , service . port , ssl = sslc )  except OSError as e :                  self . logger . error ( <str> )  else :                  self . logger . info ( <str> )    async def _start_external_servers ( self ) :          await self . _start_servers ( service for service in self . env . services if service . protocol != <str> ) self . server_listening . set ( )  async def _stop_servers ( self , services ) :          server_map = { service : self . servers . pop ( service ) for service in set ( services ) . intersection ( self . servers ) } for service , server in server_map . items ( ) :              self . logger . info ( <str> ) server . close ( )  for server in server_map . values ( ) :              await server . wait_closed ( )   async def _manage_servers ( self ) :          paused = False max_sessions = self . env . max_sessions low_watermark = max_sessions * 19 // 20 while True :              await self . session_event . wait ( ) self . session_event . clear ( ) if not paused and len ( self . sessions ) >= max_sessions :                  self . logger . info ( <str> <str> <str> ) await self . _stop_servers ( service for service in self . servers if service . protocol != <str> ) paused = True  if paused and len ( self . sessions ) <= low_watermark :                  self . logger . info ( <str> ) await self . _start_external_servers ( ) paused = False    async def _log_sessions ( self ) :          log_interval = self . env . log_sessions if log_interval :              while True :                  await sleep ( log_interval ) data = self . _session_data ( for_log = True ) for line in sessions_lines ( data ) :                      self . logger . info ( line )  self . logger . info ( json . dumps ( self . _get_info ( ) ) )    async def _disconnect_sessions ( self , sessions , reason , * , force_after = 1.0 ) :          if sessions :              session_ids = <str> . join ( str ( session . session_id ) for session in sessions ) self . logger . info ( <str> ) for session in sessions :                  await self . _task_group . spawn ( session . close ( force_after = force_after ) )    async def _clear_stale_sessions ( self ) :          while True :              await sleep ( 60 ) stale_cutoff = time . time ( ) - self . env . session_timeout stale_sessions = [ session for session in self . sessions if session . last_recv < stale_cutoff ] await self . _disconnect_sessions ( stale_sessions , <str> ) del stale_sessions   async def _recalc_concurrency ( self ) :          session_class = self . env . coin . SESSIONCLS period = 300 while True :              await sleep ( period ) hard_limit = session_class . cost_hard_limit refund = period * hard_limit / 5000 dead_groups = [ ] for group in self . session_groups . values ( ) :                  group . retained_cost = max ( 0.0 , group . retained_cost - refund ) if group . retained_cost == 0 and not group . sessions :                      dead_groups . append ( group )   for group in dead_groups :                  self . session_groups . pop ( group . name )  for session in self . sessions :                  session . cost_decay_per_sec = hard_limit / ( 10000 + 5 * session . sub_count ( ) ) session . recalc_concurrency ( )    def _get_info ( self ) :          cache_fmt = <str> sessions = self . sessions return { <str> : self . env . coin . __name__ , <str> : self . daemon . logged_url ( ) , <str> : self . daemon . cached_height ( ) , <str> : self . db . db_height , <str> : self . db . history . flush_count , <str> : len ( self . session_groups ) , <str> : cache_fmt . format ( self . _history_lookups , self . _history_hits , len ( self . _history_cache ) ) , <str> : cache_fmt . format ( self . _merkle_lookups , self . _merkle_hits , len ( self . _merkle_cache ) ) , <str> : os . getpid ( ) , <str> : self . peer_mgr . info ( ) , <str> : self . _method_counts , <str> : sum ( self . _method_counts . values ( ) ) , <str> : { <str> : len ( sessions ) , <str> : sum ( len ( getattr ( s , <str> , ( ) ) ) > 0 for s in sessions ) , <str> : sum ( s . errors for s in sessions ) , <str> : len ( [ s for s in sessions if s . log_me ] ) , <str> : sum ( s . unanswered_request_count ( ) for s in sessions ) , <str> : sum ( s . sub_count ( ) for s in sessions ) , } , <str> : cache_fmt . format ( self . _tx_hashes_lookups , self . _tx_hashes_hits , len ( self . _tx_hashes_cache ) ) , <str> : self . txs_sent , <str> : util . formatted_time ( time . time ( ) - self . start_time ) , <str> : electrumx . version , }  def _session_data ( self , for_log ) :          now = time . time ( ) sessions = sorted ( self . sessions , key = lambda s : s . start_time ) return [ ( session . session_id , session . flags ( ) , session . remote_address_string ( for_log = for_log ) , session . client , session . protocol_version_string ( ) , session . cost , session . extra_cost ( ) , session . unanswered_request_count ( ) , session . txs_sent , session . sub_count ( ) , session . recv_count , session . recv_size , session . send_count , session . send_size , now - session . start_time ) for session in sessions ]  def _group_data ( self ) :          result = [ ] for name , group in self . session_groups . items ( ) :              sessions = group . sessions result . append ( [ name , len ( sessions ) , group . session_cost ( ) , group . retained_cost , sum ( s . unanswered_request_count ( ) for s in sessions ) , sum ( s . txs_sent for s in sessions ) , sum ( s . sub_count ( ) for s in sessions ) , sum ( s . recv_count for s in sessions ) , sum ( s . recv_size for s in sessions ) , sum ( s . send_count for s in sessions ) , sum ( s . send_size for s in sessions ) , ] )  return result  async def _refresh_hsub_results ( self , height ) :          height = min ( height , self . db . db_height ) raw = await self . raw_header ( height ) self . hsub_results = { <str> : raw . hex ( ) , <str> : height } self . notified_height = height  def _session_references ( self , items , special_strings ) :          if not isinstance ( items , list ) or not all ( isinstance ( item , str ) for item in items ) :              raise RPCError ( BAD_REQUEST , <str> )  sessions_by_id = { session . session_id : session for session in self . sessions } groups_by_name = self . session_groups sessions = set ( ) groups = set ( ) specials = set ( ) unknown = set ( ) for item in items :              if item . isdigit ( ) :                  session = sessions_by_id . get ( int ( item ) ) if session :                      sessions . add ( session )  else :                      unknown . add ( item )   else :                  lc_item = item . lower ( ) if lc_item in special_strings :                      specials . add ( lc_item )  else :                      if lc_item in groups_by_name :                          groups . add ( lc_item )  else :                          unknown . add ( item )     groups = [ groups_by_name [ group ] for group in groups ] return SessionReferences ( sessions , groups , specials , unknown )  async def rpc_add_peer ( self , real_name ) :          await self . peer_mgr . add_localRPC_peer ( real_name ) return <str> . format ( real_name )  async def rpc_disconnect ( self , session_ids ) :          refs = self . _session_references ( session_ids , { <str> } ) result = [ ] if <str> in refs . specials :              sessions = self . sessions result . append ( <str> )  else :              sessions = refs . sessions result . extend ( <str> for session in sessions ) for group in refs . groups :                  result . append ( <str> ) sessions . update ( group . sessions )   result . extend ( <str> for item in refs . unknown ) await self . _disconnect_sessions ( sessions , <str> ) return result  async def rpc_log ( self , session_ids ) :          refs = self . _session_references ( session_ids , { <str> , <str> , <str> } ) result = [ ] def add_result ( text , value ) :              result . append ( <str> if value else <str> )  if <str> in refs . specials :              for session in self . sessions :                  session . log_me = True  SessionBase . log_new = True result . append ( <str> )  if <str> in refs . specials :              for session in self . sessions :                  session . log_me = False  SessionBase . log_new = False result . append ( <str> )  if <str> in refs . specials :              SessionBase . log_new = not SessionBase . log_new add_result ( <str> , SessionBase . log_new )  sessions = refs . sessions for session in sessions :              session . log_me = not session . log_me add_result ( <str> , session . log_me )  for group in refs . groups :              for session in group . sessions . difference ( sessions ) :                  sessions . add ( session ) session . log_me = not session . log_me add_result ( <str> , session . log_me )   result . extend ( <str> for item in refs . unknown ) return result  async def rpc_daemon_url ( self , daemon_url ) :          daemon_url = daemon_url or self . env . daemon_url try :              self . daemon . set_url ( daemon_url )  except Exception as e :              raise RPCError ( BAD_REQUEST , <str> )  return <str>  async def rpc_stop ( self ) :          self . shutdown_event . set ( ) return <str>  async def rpc_getinfo ( self ) :          return self . _get_info ( )  async def rpc_groups ( self ) :          return self . _group_data ( )  async def rpc_peers ( self ) :          return self . peer_mgr . rpc_data ( )  async def rpc_query ( self , items , limit ) :          coin = self . env . coin db = self . db lines = [ ] def arg_to_hashX ( arg ) :              try :                  script = bytes . fromhex ( arg ) lines . append ( <str> ) return coin . hashX_from_script ( script )  except ValueError :                  pass  try :                  hashX = coin . address_to_hashX ( arg ) lines . append ( <str> ) return hashX  except Base58Error :                  pass  try :                  script = coin . build_name_index_script ( arg . encode ( <str> ) ) hashX = coin . name_hashX_from_script ( script ) lines . append ( <str> ) return hashX  except ( AttributeError , UnicodeEncodeError ) :                  pass  return None  for arg in items :              hashX = arg_to_hashX ( arg ) if not hashX :                  continue  n = None history = await db . limited_history ( hashX , limit = limit ) for n , ( tx_hash , height ) in enumerate ( history ) :                  lines . append ( <str> <str> )  if n is None :                  lines . append ( <str> )  n = None utxos = await db . all_utxos ( hashX ) for n , utxo in enumerate ( utxos , start = 1 ) :                  lines . append ( <str> <str> <str> <str> ) if n == limit :                      break   if n is None :                  lines . append ( <str> )  balance = sum ( utxo . value for utxo in utxos ) lines . append ( <str> <str> )  return lines  async def rpc_sessions ( self ) :          return self . _session_data ( for_log = False )  async def rpc_reorg ( self , count ) :          count = non_negative_integer ( count ) if not self . bp . force_chain_reorg ( count ) :              raise RPCError ( BAD_REQUEST , <str> )  return <str>  async def serve ( self , notifications , event ) :          try :              await self . _start_servers ( service for service in self . env . services if service . protocol == <str> ) await event . wait ( ) session_class = self . env . coin . SESSIONCLS session_class . cost_soft_limit = self . env . cost_soft_limit session_class . cost_hard_limit = self . env . cost_hard_limit session_class . cost_decay_per_sec = session_class . cost_hard_limit / 10000 session_class . bw_cost_per_byte = 1.0 / self . env . bw_unit_cost session_class . cost_sleep = self . env . request_sleep / 1000 session_class . initial_concurrent = self . env . initial_concurrent session_class . processing_timeout = self . env . request_timeout self . logger . info ( <str> ) self . logger . info ( <str> ) self . logger . info ( <str> ) self . logger . info ( <str> ) self . logger . info ( <str> ) self . logger . info ( <str> ) self . logger . info ( <str> ) self . logger . info ( <str> ) self . logger . info ( <str> ) if self . env . drop_client is not None :                  self . logger . info ( <str> . format ( self . env . drop_client . pattern ) )  for service in self . env . report_services :                  self . logger . info ( <str> )  await notifications . start ( self . db . db_height , self . _notify_sessions ) await self . _start_external_servers ( ) async with self . _task_group as group :                  await group . spawn ( self . peer_mgr . discover_peers ( ) ) await group . spawn ( self . _clear_stale_sessions ( ) ) await group . spawn ( self . _recalc_concurrency ( ) ) await group . spawn ( self . _log_sessions ( ) ) await group . spawn ( self . _manage_servers ( ) )   finally :              await self . _stop_servers ( self . servers . keys ( ) ) async with TaskGroup ( ) as group :                  for session in list ( self . sessions ) :                      await group . spawn ( session . close ( force_after = 1 ) )     def extra_cost ( self , session ) :          groups = self . sessions . get ( session ) if groups is None :              return 0  return sum ( ( group . cost ( ) - session . cost ) * group . weight for group in groups )  async def _merkle_branch ( self , height , tx_hashes , tx_pos , cache_counter ) :          tx_hash_count = len ( tx_hashes ) cost = tx_hash_count if tx_hash_count >= 200 :              self . _merkle_lookups += 1 merkle_cache = self . _merkle_cache . get ( height ) if merkle_cache :                  self . _merkle_hits += 1 cost = 10 * math . sqrt ( tx_hash_count )  else :                  async def tx_hashes_func ( start , count ) :                      return tx_hashes [ start : start + count ]  merkle_cache = MerkleCache ( self . db . merkle , tx_hashes_func ) if cache_counter == self . _cache_counter :                      self . _merkle_cache [ height ] = merkle_cache  await merkle_cache . initialize ( len ( tx_hashes ) )  branch , _root = await merkle_cache . branch_and_root ( tx_hash_count , tx_pos )  else :              branch , _root = self . db . merkle . branch_and_root ( tx_hashes , tx_pos )  branch = [ hash_to_hex_str ( hash ) for hash in branch ] return branch , cost / 2500  async def merkle_branch_for_tx_hash ( self , height , tx_hash ) :          tx_hashes , tx_hashes_cost , cache_counter = await self . tx_hashes_at_blockheight ( height ) try :              tx_pos = tx_hashes . index ( tx_hash )  except ValueError :              raise RPCError ( BAD_REQUEST , <str> )  branch , merkle_cost = await self . _merkle_branch ( height , tx_hashes , tx_pos , cache_counter ) return branch , tx_pos , tx_hashes_cost + merkle_cost  async def merkle_branch_for_tx_pos ( self , height , tx_pos ) :          tx_hashes , tx_hashes_cost , cache_counter = await self . tx_hashes_at_blockheight ( height ) try :              tx_hash = tx_hashes [ tx_pos ]  except IndexError :              raise RPCError ( BAD_REQUEST , <str> )  branch , merkle_cost = await self . _merkle_branch ( height , tx_hashes , tx_pos , cache_counter ) return branch , hash_to_hex_str ( tx_hash ) , tx_hashes_cost + merkle_cost  async def tx_hashes_at_blockheight ( self , height ) :          cache_counter = self . _cache_counter self . _tx_hashes_lookups += 1 tx_hashes = self . _tx_hashes_cache . get ( height ) if tx_hashes :              self . _tx_hashes_hits += 1 return tx_hashes , 0.1 , cache_counter  try :              tx_hashes = await self . db . tx_hashes_at_blockheight ( height )  except self . db . DBError as e :              raise RPCError ( BAD_REQUEST , <str> )  if cache_counter == self . _cache_counter :              self . _tx_hashes_cache [ height ] = tx_hashes  return tx_hashes , 0.25 + len ( tx_hashes ) * 0.0001 , cache_counter  def session_count ( self ) :          return len ( self . sessions )  async def daemon_request ( self , method , * args ) :          try :              return await getattr ( self . daemon , method ) ( * args )  except DaemonError as e :              raise RPCError ( DAEMON_ERROR , <str> ) from None   async def raw_header ( self , height ) :          try :              return await self . db . raw_header ( height )  except IndexError :              raise RPCError ( BAD_REQUEST , <str> <str> ) from None   async def broadcast_transaction ( self , raw_tx ) :          hex_hash = await self . daemon . broadcast_transaction ( raw_tx ) self . txs_sent += 1 return hex_hash  async def limited_history ( self , hashX ) :          limit = self . env . max_send // 99 cost = 0.1 self . _history_lookups += 1 try :              result = self . _history_cache [ hashX ] self . _history_hits += 1  except KeyError :              result = await self . db . limited_history ( hashX , limit = limit ) cost += 0.1 + len ( result ) * 0.001 if len ( result ) >= limit :                  result = RPCError ( BAD_REQUEST , <str> , cost = cost )  self . _history_cache [ hashX ] = result  if isinstance ( result , Exception ) :              raise result  return result , cost  async def _notify_sessions ( self , height , touched ) :          self . _cache_counter += 1 for cache in ( self . _tx_hashes_cache , self . _merkle_cache ) :              for key in range ( height , self . db . db_height + 1 ) :                  if key in cache :                      del cache [ key ]    height_changed = height != self . notified_height if height_changed :              await self . _refresh_hsub_results ( height ) cache = self . _history_cache for hashX in set ( cache ) . intersection ( touched ) :                  del cache [ hashX ]   for session in self . sessions :              await self . _task_group . spawn ( session . notify , touched , height_changed )   def _ip_addr_group_name ( self , session ) :          host = session . remote_address ( ) . host if isinstance ( host , IPv4Address ) :              return <str> . join ( str ( host ) . split ( <str> ) [ : 3 ] )  if isinstance ( host , IPv6Address ) :              return <str> . join ( host . exploded . split ( <str> ) [ : 3 ] )  return <str>  def _timeslice_name ( self , session ) :          return <str>  def _session_group ( self , name , weight ) :          group = self . session_groups . get ( name ) if not group :              group = SessionGroup ( name , weight , set ( ) , 0 ) self . session_groups [ name ] = group  return group  def add_session ( self , session ) :          self . session_event . set ( ) groups = ( self . _session_group ( self . _timeslice_name ( session ) , 0.03 ) , self . _session_group ( self . _ip_addr_group_name ( session ) , 1.0 ) , ) self . sessions [ session ] = groups for group in groups :              group . sessions . add ( session )   def remove_session ( self , session ) :          self . session_event . set ( ) groups = self . sessions . pop ( session ) for group in groups :              group . retained_cost += session . cost group . sessions . remove ( session )    class SessionBase ( RPCSession ) :      MAX_CHUNK_SIZE = 2016 session_counter = itertools . count ( ) log_new = False def __init__ ( self , session_mgr , db , mempool , peer_mgr , kind , transport ) :          connection = JSONRPCConnection ( JSONRPCAutoDetect ) super ( ) . __init__ ( transport , connection = connection ) self . session_mgr = session_mgr self . db = db self . mempool = mempool self . peer_mgr = peer_mgr self . kind = kind self . env = session_mgr . env self . coin = self . env . coin self . client = <str> self . anon_logs = self . env . anon_logs self . txs_sent = 0 self . log_me = SessionBase . log_new self . session_id = None self . daemon_request = self . session_mgr . daemon_request self . session_id = next ( self . session_counter ) context = { <str> : <str> } logger = util . class_logger ( __name__ , self . __class__ . __name__ ) self . logger = util . ConnectionLogger ( logger , context ) self . logger . info ( <str> <str> ) self . recalc_concurrency ( ) self . session_mgr . add_session ( self )  async def notify ( self , touched , height_changed ) :          pass  def remote_address_string ( self , * , for_log = True ) :          if for_log and self . anon_logs :              return <str>  return str ( self . remote_address ( ) )  def flags ( self ) :          status = self . kind [ 0 ] if self . is_closing ( ) :              status += <str>  if self . log_me :              status += <str>  status += str ( self . _incoming_concurrency . max_concurrent ) return status  async def connection_lost ( self ) :          await super ( ) . connection_lost ( ) self . session_mgr . remove_session ( self ) msg = <str> if self . _incoming_concurrency . max_concurrent < self . initial_concurrent * 0.8 :              msg += <str>  if self . send_size >= 1_000_000 :              msg += <str>  if msg :              msg = <str> + msg self . logger . info ( msg )   def sub_count ( self ) :          return 0  async def handle_request ( self , request ) :          if isinstance ( request , Request ) :              handler = self . request_handlers . get ( request . method )  else :              handler = None  method = <str> if handler is None else request . method self . session_mgr . _method_counts [ method ] += 1 coro = handler_invocation ( handler , request ) ( ) return await coro   class ElectrumX ( SessionBase ) :      PROTOCOL_MIN = ( 1 , 4 ) PROTOCOL_MAX = ( 1 , 4 , 2 ) def __init__ ( self , * args , ** kwargs ) :          super ( ) . __init__ ( * args , ** kwargs ) self . subscribe_headers = False self . connection . max_response_size = self . env . max_send self . hashX_subs = { } self . sv_seen = False self . mempool_statuses = { } self . set_request_handlers ( self . PROTOCOL_MIN ) self . is_peer = False self . cost = 5.0  @ classmethod def protocol_min_max_strings ( cls ) :          return [ util . version_string ( ver ) for ver in ( cls . PROTOCOL_MIN , cls . PROTOCOL_MAX ) ]  @ classmethod def server_features ( cls , env ) :          hosts_dict = { } for service in env . report_services :              port_dict = hosts_dict . setdefault ( str ( service . host ) , { } ) if service . protocol not in port_dict :                  port_dict [ <str> ] = service . port   min_str , max_str = cls . protocol_min_max_strings ( ) return { <str> : hosts_dict , <str> : None , <str> : electrumx . version , <str> : min_str , <str> : max_str , <str> : env . coin . GENESIS_HASH , <str> : <str> , <str> : [ str ( service ) for service in env . report_services ] , }  async def server_features_async ( self ) :          self . bump_cost ( 0.2 ) return self . server_features ( self . env )  @ classmethod def server_version_args ( cls ) :          return [ electrumx . version , cls . protocol_min_max_strings ( ) ]  def protocol_version_string ( self ) :          return util . version_string ( self . protocol_tuple )  def extra_cost ( self ) :          return self . session_mgr . extra_cost ( self )  def sub_count ( self ) :          return len ( self . hashX_subs )  def unsubscribe_hashX ( self , hashX ) :          self . mempool_statuses . pop ( hashX , None ) return self . hashX_subs . pop ( hashX , None )  async def notify ( self , touched , height_changed ) :          if height_changed and self . subscribe_headers :              args = ( await self . subscribe_headers_result ( ) , ) await self . send_notification ( <str> , args )  touched = touched . intersection ( self . hashX_subs ) if touched or ( height_changed and self . mempool_statuses ) :              changed = { } for hashX in touched :                  alias = self . hashX_subs . get ( hashX ) if alias :                      status = await self . subscription_address_status ( hashX ) changed [ alias ] = status   mempool_statuses = self . mempool_statuses . copy ( ) for hashX , old_status in mempool_statuses . items ( ) :                  alias = self . hashX_subs . get ( hashX ) if alias :                      status = await self . subscription_address_status ( hashX ) if status != old_status :                          changed [ alias ] = status    method = <str> for alias , status in changed . items ( ) :                  await self . send_notification ( method , ( alias , status ) )  if changed :                  es = <str> if len ( changed ) == 1 else <str> self . logger . info ( <str> )    async def subscribe_headers_result ( self ) :          return self . session_mgr . hsub_results  async def headers_subscribe ( self ) :          self . subscribe_headers = True self . bump_cost ( 0.25 ) return await self . subscribe_headers_result ( )  async def add_peer ( self , features ) :          self . is_peer = True self . bump_cost ( 100.0 ) return await self . peer_mgr . on_add_peer ( features , self . remote_address ( ) )  async def peers_subscribe ( self ) :          self . bump_cost ( 1.0 ) return self . peer_mgr . on_peers_subscribe ( self . is_tor ( ) )  async def address_status ( self , hashX ) :          db_history , cost = await self . session_mgr . limited_history ( hashX ) mempool = await self . mempool . transaction_summaries ( hashX ) status = <str> . join ( <str> <str> for tx_hash , height in db_history ) status += <str> . join ( <str> <str> for tx in mempool ) self . bump_cost ( cost + 0.1 + len ( status ) * 0.00002 ) if status :              status = sha256 ( status . encode ( ) ) . hex ( )  else :              status = None  if mempool :              self . mempool_statuses [ hashX ] = status  else :              self . mempool_statuses . pop ( hashX , None )  return status  async def subscription_address_status ( self , hashX ) :          try :              return await self . address_status ( hashX )  except RPCError :              self . unsubscribe_hashX ( hashX ) return None   async def hashX_listunspent ( self , hashX ) :          utxos = await self . db . all_utxos ( hashX ) utxos = sorted ( utxos ) utxos . extend ( await self . mempool . unordered_UTXOs ( hashX ) ) self . bump_cost ( 1.0 + len ( utxos ) / 50 ) spends = await self . mempool . potential_spends ( hashX ) return [ { <str> : hash_to_hex_str ( utxo . tx_hash ) , <str> : utxo . tx_pos , <str> : utxo . height , <str> : utxo . value } for utxo in utxos if ( utxo . tx_hash , utxo . tx_pos ) not in spends ]  async def hashX_subscribe ( self , hashX , alias ) :          result = await self . address_status ( hashX ) self . hashX_subs [ hashX ] = alias return result  async def get_balance ( self , hashX ) :          utxos = await self . db . all_utxos ( hashX ) confirmed = sum ( utxo . value for utxo in utxos ) unconfirmed = await self . mempool . balance_delta ( hashX ) self . bump_cost ( 1.0 + len ( utxos ) / 50 ) return { <str> : confirmed , <str> : unconfirmed }  async def scripthash_get_balance ( self , scripthash ) :          hashX = scripthash_to_hashX ( scripthash ) return await self . get_balance ( hashX )  async def unconfirmed_history ( self , hashX ) :          result = [ { <str> : hash_to_hex_str ( tx . hash ) , <str> : - tx . has_unconfirmed_inputs , <str> : tx . fee } for tx in await self . mempool . transaction_summaries ( hashX ) ] self . bump_cost ( 0.25 + len ( result ) / 50 ) return result  async def confirmed_and_unconfirmed_history ( self , hashX ) :          history , cost = await self . session_mgr . limited_history ( hashX ) self . bump_cost ( cost ) conf = [ { <str> : hash_to_hex_str ( tx_hash ) , <str> : height } for tx_hash , height in history ] return conf + await self . unconfirmed_history ( hashX )  async def scripthash_get_history ( self , scripthash ) :          hashX = scripthash_to_hashX ( scripthash ) return await self . confirmed_and_unconfirmed_history ( hashX )  async def scripthash_get_mempool ( self , scripthash ) :          hashX = scripthash_to_hashX ( scripthash ) return await self . unconfirmed_history ( hashX )  async def scripthash_listunspent ( self , scripthash ) :          hashX = scripthash_to_hashX ( scripthash ) return await self . hashX_listunspent ( hashX )  async def scripthash_subscribe ( self , scripthash ) :          hashX = scripthash_to_hashX ( scripthash ) return await self . hashX_subscribe ( hashX , scripthash )  async def scripthash_unsubscribe ( self , scripthash ) :          self . bump_cost ( 0.1 ) hashX = scripthash_to_hashX ( scripthash ) return self . unsubscribe_hashX ( hashX ) is not None  async def _merkle_proof ( self , cp_height , height ) :          max_height = self . db . db_height if not height <= cp_height <= max_height :              raise RPCError ( BAD_REQUEST , <str> <str> <str> )  branch , root = await self . db . header_branch_and_root ( cp_height + 1 , height ) return { <str> : [ hash_to_hex_str ( elt ) for elt in branch ] , <str> : hash_to_hex_str ( root ) , }  async def block_header ( self , height , cp_height = 0 ) :          height = non_negative_integer ( height ) cp_height = non_negative_integer ( cp_height ) raw_header_hex = ( await self . session_mgr . raw_header ( height ) ) . hex ( ) self . bump_cost ( 1.25 - ( cp_height == 0 ) ) if cp_height == 0 :              return raw_header_hex  result = { <str> : raw_header_hex } result . update ( await self . _merkle_proof ( cp_height , height ) ) return result  async def block_headers ( self , start_height , count , cp_height = 0 ) :          start_height = non_negative_integer ( start_height ) count = non_negative_integer ( count ) cp_height = non_negative_integer ( cp_height ) cost = count / 50 max_size = self . MAX_CHUNK_SIZE count = min ( count , max_size ) headers , count = await self . db . read_headers ( start_height , count ) result = { <str> : headers . hex ( ) , <str> : count , <str> : max_size } if count and cp_height :              cost += 1.0 last_height = start_height + count - 1 result . update ( await self . _merkle_proof ( cp_height , last_height ) )  self . bump_cost ( cost ) return result  def is_tor ( self ) :          proxy_address = self . peer_mgr . proxy_address ( ) if not proxy_address :              return False  return self . remote_address ( ) . host == proxy_address . host  async def replaced_banner ( self , banner ) :          network_info = await self . daemon_request ( <str> ) ni_version = network_info [ <str> ] major , minor = divmod ( ni_version , 1000000 ) minor , revision = divmod ( minor , 10000 ) revision //= 100 daemon_version = <str> . format ( major , minor , revision ) for pair in [ ( <str> , electrumx . version_short ) , ( <str> , electrumx . version ) , ( <str> , daemon_version ) , ( <str> , network_info [ <str> ] ) , ( <str> , self . env . donation_address ) , ] :              banner = banner . replace ( * pair )  return banner  async def donation_address ( self ) :          self . bump_cost ( 0.1 ) return self . env . donation_address  async def banner ( self ) :          banner = <str> self . bump_cost ( 0.5 ) if self . is_tor ( ) :              banner_file = self . env . tor_banner_file  else :              banner_file = self . env . banner_file  if banner_file :              try :                  with codecs . open ( banner_file , <str> , <str> ) as f :                      banner = f . read ( )   except ( OSError , UnicodeDecodeError ) as e :                  self . logger . error ( <str> )  else :                  banner = await self . replaced_banner ( banner )   return banner  async def relayfee ( self ) :          self . bump_cost ( 1.0 ) return await self . daemon_request ( <str> )  async def estimatefee ( self , number ) :          number = non_negative_integer ( number ) self . bump_cost ( 2.0 ) return await self . daemon_request ( <str> , number )  async def ping ( self ) :          self . bump_cost ( 0.1 ) return None  async def server_version ( self , client_name = <str> , protocol_version = None ) :          self . bump_cost ( 0.5 ) if self . sv_seen :              raise RPCError ( BAD_REQUEST , <str> )  self . sv_seen = True if client_name :              client_name = str ( client_name ) if self . env . drop_client is not None and self . env . drop_client . match ( client_name ) :                  raise ReplyAndDisconnect ( RPCError ( BAD_REQUEST , <str> ) )  self . client = client_name [ : 17 ]  ptuple , client_min = util . protocol_version ( protocol_version , self . PROTOCOL_MIN , self . PROTOCOL_MAX ) await self . crash_old_client ( ptuple , self . env . coin . CRASH_CLIENT_VER ) if ptuple is None :              if client_min > self . PROTOCOL_MIN :                  self . logger . info ( <str> <str> <str> )  raise ReplyAndDisconnect ( RPCError ( BAD_REQUEST , <str> ) )  self . set_request_handlers ( ptuple ) return ( electrumx . version , self . protocol_version_string ( ) )  async def crash_old_client ( self , ptuple , crash_client_ver ) :          if crash_client_ver :              client_ver = util . protocol_tuple ( self . client ) is_old_protocol = ptuple is None or ptuple <= ( 1 , 2 ) is_old_client = client_ver != ( 0 , ) and client_ver <= crash_client_ver if is_old_protocol and is_old_client :                  self . logger . info ( <str> ) await self . send_notification ( <str> , ( ) ) await self . send_notification ( <str> , ( ) )    async def transaction_broadcast ( self , raw_tx ) :          self . bump_cost ( 0.25 + len ( raw_tx ) / 5000 ) try :              hex_hash = await self . session_mgr . broadcast_transaction ( raw_tx )  except DaemonError as e :              error , = e . args message = error [ <str> ] self . logger . info ( <str> ) raise RPCError ( BAD_REQUEST , <str> <str> )  else :              self . txs_sent += 1 client_ver = util . protocol_tuple ( self . client ) if client_ver != ( 0 , ) :                  msg = self . coin . warn_old_client_on_tx_broadcast ( client_ver ) if msg :                      self . logger . info ( <str> <str> ) return msg   self . logger . info ( <str> ) return hex_hash   async def transaction_get ( self , tx_hash , verbose = False ) :          assert_tx_hash ( tx_hash ) if verbose not in ( True , False ) :              raise RPCError ( BAD_REQUEST , <str> )  self . bump_cost ( 1.0 ) return await self . daemon_request ( <str> , tx_hash , verbose )  async def transaction_merkle ( self , tx_hash , height ) :          tx_hash = assert_tx_hash ( tx_hash ) height = non_negative_integer ( height ) branch , tx_pos , cost = await self . session_mgr . merkle_branch_for_tx_hash ( height , tx_hash ) self . bump_cost ( cost ) return { <str> : height , <str> : branch , <str> : tx_pos }  async def transaction_id_from_pos ( self , height , tx_pos , merkle = False ) :          tx_pos = non_negative_integer ( tx_pos ) height = non_negative_integer ( height ) if merkle not in ( True , False ) :              raise RPCError ( BAD_REQUEST , <str> )  if merkle :              branch , tx_hash , cost = await self . session_mgr . merkle_branch_for_tx_pos ( height , tx_pos ) self . bump_cost ( cost ) return { <str> : tx_hash , <str> : branch }  else :              tx_hashes , cost , _ = await self . session_mgr . tx_hashes_at_blockheight ( height ) try :                  tx_hash = tx_hashes [ tx_pos ]  except IndexError :                  raise RPCError ( BAD_REQUEST , <str> )  self . bump_cost ( cost ) return hash_to_hex_str ( tx_hash )   async def compact_fee_histogram ( self ) :          self . bump_cost ( 1.0 ) return await self . mempool . compact_fee_histogram ( )  def set_request_handlers ( self , ptuple ) :          self . protocol_tuple = ptuple handlers = { <str> : self . block_header , <str> : self . block_headers , <str> : self . estimatefee , <str> : self . headers_subscribe , <str> : self . relayfee , <str> : self . scripthash_get_balance , <str> : self . scripthash_get_history , <str> : self . scripthash_get_mempool , <str> : self . scripthash_listunspent , <str> : self . scripthash_subscribe , <str> : self . transaction_broadcast , <str> : self . transaction_get , <str> : self . transaction_merkle , <str> : self . transaction_id_from_pos , <str> : self . mempool . compact_fee_histogram , <str> : self . add_peer , <str> : self . banner , <str> : self . donation_address , <str> : self . server_features_async , <str> : self . peers_subscribe , <str> : self . ping , <str> : self . server_version , } if ptuple >= ( 1 , 4 , 2 ) :              handlers [ <str> ] = self . scripthash_unsubscribe  self . request_handlers = handlers   class LocalRPC ( SessionBase ) :      def __init__ ( self , * args , ** kwargs ) :          super ( ) . __init__ ( * args , ** kwargs ) self . client = <str> self . connection . max_response_size = 0  def protocol_version_string ( self ) :          return <str>   class DashElectrumX ( ElectrumX ) :      def __init__ ( self , * args , ** kwargs ) :          super ( ) . __init__ ( * args , ** kwargs ) self . mns = set ( ) self . mn_cache_height = 0 self . mn_cache = [ ]  def set_request_handlers ( self , ptuple ) :          super ( ) . set_request_handlers ( ptuple ) self . request_handlers . update ( { <str> : self . masternode_announce_broadcast , <str> : self . masternode_subscribe , <str> : self . masternode_list , <str> : self . protx_diff , <str> : self . protx_info , } )  async def notify ( self , touched , height_changed ) :          await super ( ) . notify ( touched , height_changed ) for mn in self . mns . copy ( ) :              status = await self . daemon_request ( <str> , [ <str> , mn ] ) await self . send_notification ( <str> , [ mn , status . get ( mn ) ] )   async def masternode_announce_broadcast ( self , signmnb ) :          try :              return await self . daemon_request ( <str> , [ <str> , signmnb ] )  except DaemonError as e :              error , = e . args message = error [ <str> ] self . logger . info ( <str> ) raise RPCError ( BAD_REQUEST , <str> <str> )   async def masternode_subscribe ( self , collateral ) :          result = await self . daemon_request ( <str> , [ <str> , collateral ] ) if result is not None :              self . mns . add ( collateral ) return result . get ( collateral )  return None  async def masternode_list ( self , payees ) :          if not isinstance ( payees , list ) :              raise RPCError ( BAD_REQUEST , <str> )  def get_masternode_payment_queue ( mns ) :              now = int ( datetime . datetime . utcnow ( ) . strftime ( <str> ) ) mn_queue = [ ] for line in mns :                  mnstat = mns [ line ] . split ( ) if mnstat [ 0 ] == <str> :                      if int ( mnstat [ 5 ] ) == 0 :                          mnstat . append ( int ( mnstat [ 4 ] ) )  else :                          delta = now - int ( mnstat [ 5 ] ) if delta >= int ( mnstat [ 4 ] ) :                              mnstat . append ( int ( mnstat [ 4 ] ) )  else :                              mnstat . append ( delta )   mn_queue . append ( mnstat )   mn_queue = sorted ( mn_queue , key = lambda x : x [ 8 ] , reverse = True ) return mn_queue  def get_payment_position ( payment_queue , address ) :              position = - 1 for pos , mn in enumerate ( payment_queue , start = 1 ) :                  if mn [ 2 ] == address :                      position = pos break   return position  cache = self . session_mgr . mn_cache if not cache or self . session_mgr . mn_cache_height != self . db . db_height :              full_mn_list = await self . daemon_request ( <str> , [ <str> ] ) mn_payment_queue = get_masternode_payment_queue ( full_mn_list ) mn_payment_count = len ( mn_payment_queue ) mn_list = [ ] for key , value in full_mn_list . items ( ) :                  mn_data = value . split ( ) mn_info = { } mn_info [ <str> ] = key mn_info [ <str> ] = mn_data [ 0 ] mn_info [ <str> ] = mn_data [ 1 ] mn_info [ <str> ] = mn_data [ 2 ] mn_info [ <str> ] = mn_data [ 3 ] mn_info [ <str> ] = mn_data [ 4 ] mn_info [ <str> ] = mn_data [ 5 ] mn_info [ <str> ] = mn_data [ 6 ] mn_info [ <str> ] = mn_data [ 7 ] mn_info [ <str> ] = get_payment_position ( mn_payment_queue , mn_info [ <str> ] ) mn_info [ <str> ] = ( mn_info [ <str> ] < mn_payment_count // 10 ) hashX = self . coin . address_to_hashX ( mn_info [ <str> ] ) balance = await self . get_balance ( hashX ) mn_info [ <str> ] = ( sum ( balance . values ( ) ) / self . coin . VALUE_PER_COIN ) mn_list . append ( mn_info )  cache . clear ( ) cache . extend ( mn_list ) self . session_mgr . mn_cache_height = self . db . db_height  if payees :              return [ mn for mn in cache if mn [ <str> ] in payees ]  else :              return cache   async def protx_diff ( self , base_height , height ) :          if not isinstance ( base_height , int ) or not isinstance ( height , int ) :              raise RPCError ( BAD_REQUEST , <str> )  max_height = self . db . db_height if ( not 1 <= base_height <= max_height or not base_height <= height <= max_height ) :              raise RPCError ( BAD_REQUEST , <str> <str> <str> )  return await self . daemon_request ( <str> , ( <str> , base_height , height ) )  async def protx_info ( self , protx_hash ) :          if not isinstance ( protx_hash , str ) :              raise RPCError ( BAD_REQUEST , <str> )  res = await self . daemon_request ( <str> , ( <str> , protx_hash ) ) if <str> in res :              del res [ <str> ]  return res   class SmartCashElectrumX ( DashElectrumX ) :      def set_request_handlers ( self , ptuple ) :          super ( ) . set_request_handlers ( ptuple ) self . request_handlers . update ( { <str> : self . smartrewards_current , <str> : self . smartrewards_check } )  async def smartrewards_current ( self ) :          result = await self . daemon_request ( <str> , [ <str> ] ) if result is not None :              return result  return None  async def smartrewards_check ( self , addr ) :          result = await self . daemon_request ( <str> , [ <str> , addr ] ) if result is not None :              return result  return None   class AuxPoWElectrumX ( ElectrumX ) :      async def block_header ( self , height , cp_height = 0 ) :          result = await super ( ) . block_header ( height , cp_height ) if self . protocol_tuple < ( 1 , 4 , 1 ) :              return result  if cp_height == 0 :              return result  result [ <str> ] = self . truncate_auxpow ( result [ <str> ] , height ) return result  async def block_headers ( self , start_height , count , cp_height = 0 ) :          result = await super ( ) . block_headers ( start_height , count , cp_height ) if self . protocol_tuple < ( 1 , 4 , 1 ) :              return result  if cp_height == 0 :              return result  result [ <str> ] = self . truncate_auxpow ( result [ <str> ] , start_height ) return result  def truncate_auxpow ( self , headers_full_hex , start_height ) :          height = start_height headers_full = util . hex_to_bytes ( headers_full_hex ) cursor = 0 headers = bytearray ( ) while cursor < len ( headers_full ) :              headers . extend ( headers_full [ cursor : cursor + self . coin . TRUNCATED_HEADER_SIZE ] ) cursor += self . db . dynamic_header_len ( height ) height += 1  return headers . hex ( )    