import asyncio from ipaddress import IPv4Address , IPv6Address import json import random import socket import ssl import time from collections import defaultdict , Counter import aiohttp from aiorpcx import ( connect_rs , RPCSession , SOCKSProxy , Notification , handler_invocation , SOCKSError , RPCError , TaskTimeout , TaskGroup , Event , sleep , ignore_after ) from electrumx . lib . peer import Peer from electrumx . lib . util import class_logger PEER_GOOD , PEER_STALE , PEER_NEVER , PEER_BAD = range ( 4 ) STALE_SECS = 3 * 3600 WAKEUP_SECS = 300 PEER_ADD_PAUSE = 600 class BadPeerError ( Exception ) :      pass  def assert_good ( message , result , instance ) :      if not isinstance ( result , instance ) :          raise BadPeerError ( <str> <str> )   class PeerSession ( RPCSession ) :      async def handle_request ( self , request ) :          if ( isinstance ( request , Notification ) and request . method == <str> ) :              pass  else :              await handler_invocation ( None , request )    class PeerManager :      def __init__ ( self , env , db ) :          self . logger = class_logger ( __name__ , self . __class__ . __name__ ) Peer . DEFAULT_PORTS = env . coin . PEER_DEFAULT_PORTS self . env = env self . db = db sclass = env . coin . SESSIONCLS self . myselves = [ Peer ( str ( service . host ) , sclass . server_features ( env ) , <str> ) for service in env . report_services ] self . server_version_args = sclass . server_version_args ( ) self . peers = set ( ) self . permit_onion_peer_time = time . time ( ) self . proxy = None self . group = TaskGroup ( ) self . recent_peer_adds = { } self . blacklist = set ( )  def _my_clearnet_peer ( self ) :          clearnet = [ peer for peer in self . myselves if not peer . is_tor ] return clearnet [ 0 ] if clearnet else None  def _set_peer_statuses ( self ) :          cutoff = time . time ( ) - STALE_SECS for peer in self . peers :              if peer . bad :                  peer . status = PEER_BAD  elif peer . last_good > cutoff :                  peer . status = PEER_GOOD  elif peer . last_good :                  peer . status = PEER_STALE  else :                  peer . status = PEER_NEVER    def _features_to_register ( self , peer , remote_peers ) :          if not self . env . peer_announce or peer in self . myselves :              return None  my = self . _my_clearnet_peer ( ) if not my or not my . is_public :              return None  for peer in my . matches ( remote_peers ) :              if peer . tcp_port == my . tcp_port and peer . ssl_port == my . ssl_port :                  return None   return my . features  def _permit_new_onion_peer ( self , now ) :          if now < self . permit_onion_peer_time :              return False  self . permit_onion_peer_time = now + random . randrange ( 0 , 1200 ) return True  async def _import_peers ( self ) :          imported_peers = self . myselves . copy ( ) if self . env . peer_discovery != self . env . PD_SELF :              imported_peers . extend ( Peer . from_real_name ( real_name , <str> ) for real_name in self . env . coin . PEERS )  await self . _note_peers ( imported_peers , limit = None )  async def _refresh_blacklist ( self ) :          url = self . env . blacklist_url if not url :              return  async def read_blacklist ( ) :              async with aiohttp . ClientSession ( ) as session :                  async with session . get ( url ) as response :                      text = await response . text ( )   return set ( entry . lower ( ) for entry in json . loads ( text ) )  while True :              try :                  self . blacklist = await read_blacklist ( )  except Exception as e :                  self . logger . error ( <str> )  else :                  self . logger . info ( <str> ) for peer in self . peers :                      if self . _is_blacklisted ( peer ) :                          peer . retry_event . set ( )    await sleep ( 600 )   def _is_blacklisted ( self , peer ) :          host = peer . host . lower ( ) second_level_domain = <str> + <str> . join ( host . split ( <str> ) [ - 2 : ] ) return any ( item in self . blacklist for item in ( host , second_level_domain , peer . ip_addr ) )  def _get_recent_good_peers ( self ) :          cutoff = time . time ( ) - STALE_SECS recent = [ peer for peer in self . peers if peer . last_good > cutoff and not peer . bad and peer . is_public ] recent = [ peer for peer in recent if not self . _is_blacklisted ( peer ) ] return recent  async def _detect_proxy ( self ) :          host = self . env . tor_proxy_host if self . env . tor_proxy_port is None :              ports = [ 9050 , 9150 , 1080 ]  else :              ports = [ self . env . tor_proxy_port ]  while True :              self . logger . info ( <str> <str> ) proxy = await SOCKSProxy . auto_detect_at_host ( host , ports , None ) if proxy :                  self . proxy = proxy self . logger . info ( <str> ) return  self . logger . info ( <str> ) await sleep ( 900 )   async def _note_peers ( self , peers , limit = 2 , check_ports = False , source = None ) :          new_peers = [ ] match_set = self . peers . copy ( ) for peer in peers :              if not peer . is_public or ( peer . is_tor and not self . proxy ) :                  continue  matches = peer . matches ( match_set ) if matches :                  if check_ports :                      for match in matches :                          if match . check_ports ( peer ) :                              self . logger . info ( <str> ) match . retry_event . set ( )     else :                  match_set . add ( peer ) new_peers . append ( peer )   if new_peers :              source = source or new_peers [ 0 ] . source if limit :                  random . shuffle ( new_peers ) use_peers = new_peers [ : limit ]  else :                  use_peers = new_peers  for peer in use_peers :                  self . logger . info ( <str> ) peer . retry_event = Event ( ) self . peers . add ( peer ) await self . group . spawn ( self . _monitor_peer ( peer ) )   return True  async def _monitor_peer ( self , peer ) :          while peer in self . peers :              if await self . _should_drop_peer ( peer ) :                  self . peers . discard ( peer ) break  if peer . try_count == 0 :                  pause = STALE_SECS - WAKEUP_SECS * 2  else :                  pause = WAKEUP_SECS * 2 ** peer . try_count  async with ignore_after ( pause ) :                  await peer . retry_event . wait ( ) peer . retry_event . clear ( )    async def _should_drop_peer ( self , peer ) :          peer . try_count += 1 is_good = False for kind , port , family in peer . connection_tuples ( ) :              peer . last_try = time . time ( ) kwargs = { <str> : family } if kind == <str> :                  kwargs [ <str> ] = ssl . SSLContext ( ssl . PROTOCOL_TLS )  if self . env . force_proxy or peer . is_tor :                  if not self . proxy :                      return  kwargs [ <str> ] = self . proxy kwargs [ <str> ] = not peer . is_tor  else :                  local_hosts = { service . host for service in self . env . services if isinstance ( service . host , ( IPv4Address , IPv6Address ) ) and service . protocol != <str> } if local_hosts :                      kwargs [ <str> ] = ( str ( local_hosts . pop ( ) ) , None )   peer_text = <str> try :                  async with connect_rs ( peer . host , port , session_factory = PeerSession , ** kwargs ) as session :                      session . sent_request_timeout = 120 if peer . is_tor else 30 await self . _verify_peer ( session , peer )  is_good = True break  except BadPeerError as e :                  self . logger . error ( <str> ) peer . mark_bad ( ) break  except RPCError as e :                  self . logger . error ( <str> <str> )  except ( OSError , SOCKSError , ConnectionError , TaskTimeout ) as e :                  self . logger . info ( <str> )   if is_good :              now = time . time ( ) elapsed = now - peer . last_try self . logger . info ( <str> ) peer . try_count = 0 peer . last_good = now peer . source = <str> matches = peer . matches ( self . peers ) for match in matches :                  if match . ip_address :                      if len ( matches ) > 1 :                          self . peers . remove ( match ) match . retry_event . set ( )   elif peer . host in match . features [ <str> ] :                      match . update_features_from_peer ( peer )   self . recent_peer_adds = { k : v for k , v in self . recent_peer_adds . items ( ) if v + PEER_ADD_PAUSE < now }  else :              if peer . last_good and not peer . bad :                  try_limit = 10  else :                  try_limit = 3  if peer . try_count >= try_limit :                  desc = <str> if peer . bad else <str> self . logger . info ( <str> ) return True   return False  async def _verify_peer ( self , session , peer ) :          if not peer . is_tor :              address = session . remote_address ( ) if isinstance ( address . host , ( IPv4Address , IPv6Address ) ) :                  peer . ip_addr = str ( address . host )   if self . _is_blacklisted ( peer ) :              raise BadPeerError ( <str> )  recent_peers = self . _get_recent_good_peers ( ) if peer in recent_peers :              recent_peers . remove ( peer )  onion_peers = [ ] buckets = defaultdict ( list ) for other_peer in recent_peers :              if other_peer . is_tor :                  onion_peers . append ( other_peer )  else :                  buckets [ other_peer . bucket_for_internal_purposes ( ) ] . append ( other_peer )   if peer . is_tor :              if len ( onion_peers ) > len ( recent_peers ) // 2 >= 100 :                  raise BadPeerError ( <str> )   else :              bucket = peer . bucket_for_internal_purposes ( ) if buckets [ bucket ] :                  raise BadPeerError ( <str> )   message = <str> result = await session . send_request ( message , self . server_version_args ) assert_good ( message , result , list ) if len ( result ) != 2 or not all ( isinstance ( x , str ) for x in result ) :              raise BadPeerError ( <str> )  server_version , _protocol_version = result peer . server_version = server_version peer . features [ <str> ] = server_version async with TaskGroup ( ) as g :              await g . spawn ( self . _send_headers_subscribe ( session ) ) await g . spawn ( self . _send_server_features ( session , peer ) ) peers_task = await g . spawn ( self . _send_peers_subscribe ( session , peer ) )  peers = peers_task . result ( ) await self . _note_peers ( peers ) features = self . _features_to_register ( peer , peers ) if features :              self . logger . info ( <str> ) await session . send_request ( <str> , [ features ] )   async def _send_headers_subscribe ( self , session ) :          message = <str> result = await session . send_request ( message ) assert_good ( message , result , dict ) our_height = self . db . db_height their_height = result . get ( <str> ) if not isinstance ( their_height , int ) :              raise BadPeerError ( <str> )  if abs ( our_height - their_height ) > 5 :              raise BadPeerError ( <str> <str> )  check_height = min ( our_height , their_height ) raw_header = await self . db . raw_header ( check_height ) ours = raw_header . hex ( ) message = <str> theirs = await session . send_request ( message , [ check_height ] ) assert_good ( message , theirs , str ) if ours != theirs :              raise BadPeerError ( <str> <str> )   async def _send_server_features ( self , session , peer ) :          message = <str> features = await session . send_request ( message ) assert_good ( message , features , dict ) hosts = [ host . lower ( ) for host in features . get ( <str> , { } ) ] if self . env . coin . GENESIS_HASH != features . get ( <str> ) :              raise BadPeerError ( <str> )  if peer . host . lower ( ) in hosts :              peer . update_features ( features )  else :              raise BadPeerError ( <str> )   async def _send_peers_subscribe ( self , session , peer ) :          message = <str> raw_peers = await session . send_request ( message ) assert_good ( message , raw_peers , list ) try :              real_names = [ <str> . join ( [ u [ 1 ] ] + u [ 2 ] ) for u in raw_peers ] return [ Peer . from_real_name ( real_name , str ( peer ) ) for real_name in real_names ]  except Exception :              raise BadPeerError ( <str> )   async def discover_peers ( self ) :          self . logger . info ( <str> ) if self . env . peer_discovery != self . env . PD_ON :              self . logger . info ( <str> ) return  self . logger . info ( <str> ) self . logger . info ( <str> ) self . logger . info ( <str> ) self . logger . info ( <str> ) async with self . group as group :              await group . spawn ( self . _refresh_blacklist ( ) ) await group . spawn ( self . _detect_proxy ( ) ) await group . spawn ( self . _import_peers ( ) )   def info ( self ) :          self . _set_peer_statuses ( ) counter = Counter ( peer . status for peer in self . peers ) return { <str> : counter [ PEER_BAD ] , <str> : counter [ PEER_GOOD ] , <str> : counter [ PEER_NEVER ] , <str> : counter [ PEER_STALE ] , <str> : len ( self . peers ) , }  async def add_localRPC_peer ( self , real_name ) :          await self . _note_peers ( [ Peer . from_real_name ( real_name , <str> ) ] )  async def on_add_peer ( self , features , source_addr ) :          if self . env . peer_discovery != self . env . PD_ON :              return False  if not source_addr :              self . logger . info ( <str> ) return False  source = str ( source_addr . host ) peers = Peer . peers_from_features ( features , source ) if not peers :              self . logger . info ( <str> ) return False  peer = peers [ 0 ] host = peer . host now = time . time ( ) if peer . ip_address is not None :              bucket = <str>  else :              bucket = <str> . join ( host . lower ( ) . split ( <str> ) [ - 2 : ] )  last = self . recent_peer_adds . get ( bucket , 0 ) self . recent_peer_adds [ bucket ] = now if last + PEER_ADD_PAUSE >= now :              return False  if peer . is_tor :              permit = self . _permit_new_onion_peer ( now ) reason = <str>  else :              getaddrinfo = asyncio . get_event_loop ( ) . getaddrinfo try :                  infos = await getaddrinfo ( host , 80 , type = socket . SOCK_STREAM )  except socket . gaierror :                  permit = False reason = <str>  else :                  permit = any ( source == info [ - 1 ] [ 0 ] for info in infos ) reason = <str>   if permit :              self . logger . info ( <str> ) await self . _note_peers ( [ peer ] , check_ports = True )  else :              self . logger . warning ( <str> <str> )  return permit  def on_peers_subscribe ( self , is_tor ) :          recent = self . _get_recent_good_peers ( ) cutoff = time . time ( ) - STALE_SECS peers = set ( myself for myself in self . myselves if myself . last_good > cutoff ) onion_peers = [ ] buckets = defaultdict ( list ) for peer in recent :              if peer . is_tor :                  onion_peers . append ( peer )  else :                  buckets [ peer . bucket_for_external_interface ( ) ] . append ( peer )   for bucket_peers in buckets . values ( ) :              random . shuffle ( bucket_peers ) peers . update ( bucket_peers [ : 2 ] )  random . shuffle ( onion_peers ) max_onion = 50 if is_tor else max ( 10 , len ( peers ) // 4 ) peers . update ( onion_peers [ : max_onion ] ) return [ peer . to_tuple ( ) for peer in peers ]  def proxy_address ( self ) :          return self . proxy . address if self . proxy else None  def rpc_data ( self ) :          self . _set_peer_statuses ( ) descs = [ <str> , <str> , <str> , <str> ] def peer_data ( peer ) :              data = peer . serialize ( ) data [ <str> ] = descs [ peer . status ] return data  def peer_key ( peer ) :              return ( peer . bad , - peer . last_good )  return [ peer_data ( peer ) for peer in sorted ( self . peers , key = peer_key ) ]    